{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Felix","text":""},{"location":"#low-latency-quic-based-pubsub-and-distributed-cache","title":"Low-Latency QUIC-Based Pub/Sub and Distributed Cache","text":"<p>Felix is a sovereign-first, low-latency distributed data backend that unifies event streaming, message-oriented middleware, and distributed caching over a single QUIC-based transport layer.</p> <p>Early Development</p> <p>Felix is in early active development. The design and implementation are evolving quickly. This documentation reflects the current state and planned architecture.</p>"},{"location":"#why-felix","title":"Why Felix?","text":""},{"location":"#low-tail-latency","title":"\ud83d\ude80 Low Tail Latency","text":"<p>Designed for predictable p99/p999 latency under load, not just aggregate throughput. QUIC transport provides multiplexed streams without head-of-line blocking, and explicit backpressure prevents cascade failures.</p>"},{"location":"#sovereignty-by-default","title":"\ud83d\udd12 Sovereignty by Default","text":"<p>Each Felix cluster represents a single sovereign region. Data is isolated by default and cannot leave the region unless an explicit bridge is configured\u2014enforced in routing, metadata, and encryption boundaries.</p>"},{"location":"#unified-primitives","title":"\ud83c\udfaf Unified Primitives","text":"<p>A single core log abstraction supports multiple semantics:</p> <ul> <li>Streams (Pub/Sub): fanout cursors per subscription</li> <li>Queues: shared consumer-group cursors with acknowledgements  </li> <li>Cache: key \u2192 value with TTL, backed by the same log</li> </ul> <p>This drastically reduces operational complexity compared to running Kafka, Redis, and a queueing system side-by-side.</p>"},{"location":"#quic-transport","title":"\u26a1 QUIC Transport","text":"<p>Built on QUIC from the ground up:</p> <ul> <li>Encrypted by default (TLS 1.3)</li> <li>Multiplexed streams per connection</li> <li>Built-in flow control and congestion awareness</li> <li>Resistant to head-of-line blocking</li> </ul>"},{"location":"#tunable-performance","title":"\ud83c\udf9b\ufe0f Tunable Performance","text":"<p>Extensive configuration knobs for latency/throughput trade-offs:</p> <ul> <li>Connection pooling and stream multiplexing</li> <li>Configurable batching with time and count bounds</li> <li>Flow control window sizing</li> <li>Optional telemetry for detailed performance insights</li> </ul>"},{"location":"#how-it-works","title":"How It Works","text":"<p>Felix uses a framed protocol (<code>felix-wire</code>) over QUIC streams to unify event streaming and request/response caching, with explicit control over multiplexing, batching, and flow control.</p> <pre><code>flowchart LR\n    subgraph C[\"Client (felix-client)\"]\n        API[\"Publish / Subscribe / Cache APIs\"]\n\n        subgraph EVC[\"Event connections (pooled)\"]\n            Ctrl[\"Control stream (bi)&lt;br/&gt;(per conn: pub/sub, acks, control)\"]\n            API --&gt; Ctrl\n        end\n\n        subgraph SUBS[\"Subscriptions\"]\n            SubU[\"Per-subscription event stream (uni)&lt;br/&gt;(broker \u2192 client)\"]\n        end\n        API --&gt; SubU\n\n        subgraph CCP[\"Cache conn pool (N)\"]\n            SW[\"Stream workers (M)&lt;br/&gt;per connection\"]\n            CacheS[\"Cache streams (bi)&lt;br/&gt;request_id request/response mux\"]\n            API --&gt; SW\n            SW --&gt; CacheS\n        end\n    end\n\n    subgraph B[\"Broker (services/broker + felix-broker)\"]\n        Ingress[\"QUIC accept + stream registry&lt;br/&gt;felix-wire framing + stream-type routing\"]\n        PS[\"Pub/Sub core&lt;br/&gt;enqueue + batching + fanout\"]\n        Cache[\"Cache core&lt;br/&gt;lookup/insert + TTL\"]\n\n        Ingress --&gt; PS\n        Ingress --&gt; Cache\n    end\n\n    Ctrl &lt;--&gt; Ingress\n    Ingress --&gt; SubU\n    CacheS &lt;--&gt; Ingress</code></pre>"},{"location":"#pubsub-data-flow","title":"Pub/Sub Data Flow","text":"<ol> <li>Client opens a bidirectional control stream to publish/subscribe and receive acknowledgements</li> <li>Broker validates scope, enqueues publish jobs, and fans out to subscribers</li> <li>Each subscription has a dedicated unidirectional event stream for delivery</li> <li>Events are sent as single frames or binary batches with configurable batching</li> </ol>"},{"location":"#cache-data-flow","title":"Cache Data Flow","text":"<ol> <li>Client maintains a cache connection pool with long-lived stream workers</li> <li>Cache requests carry a <code>request_id</code> and are multiplexed over these streams</li> <li>Broker processes request frames in a read loop and replies on the same stream</li> <li>This avoids per-request stream setup costs and improves tail latency under concurrency</li> </ol>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>QUIC Transport: Modern, multiplexed, encrypted transport layer</li> <li>High Fanout: Efficient event delivery to many subscribers with isolation</li> <li>Connection Pooling: Reusable connections and streams for optimal performance</li> <li>Batch Processing: Time and count-bounded batching for throughput optimization</li> <li>TTL Support: Time-to-live for cache entries with lazy expiration</li> <li>Backpressure: Explicit flow control to prevent cascade failures</li> <li>Metrics: Prometheus-compatible metrics endpoint (planned)</li> <li>Observability: Structured logging with optional per-stage telemetry</li> </ul>"},{"location":"#use-cases","title":"Use Cases","text":"<p>\u2705 Real-time streaming with high fanout and tunable latency/throughput trade-offs \u2705 Event pipelines with batch publishing and batch delivery for efficient fanout \u2705 Low-latency caching over QUIC with predictable tail latency under load \u2705 Microservice communication with unified pub/sub and cache semantics \u2705 Edge-to-cloud data pipelines with explicit regional isolation  </p>"},{"location":"#current-status","title":"Current Status","text":"<p>The current implementation provides a single-node MVP with:</p> <ul> <li>\u2705 Single-node broker</li> <li>\u2705 In-process pub/sub with fanout</li> <li>\u2705 Ephemeral cache with TTL</li> <li>\u2705 Stable wire envelope (v1)</li> <li>\u2705 Basic observability (structured logs)</li> <li>\u2705 Comprehensive test coverage</li> </ul>"},{"location":"#roadmap","title":"Roadmap","text":"<ul> <li>\ud83d\udea7 Durable log and retention policies</li> <li>\ud83d\udea7 Metadata and control plane with RAFT consensus</li> <li>\ud83d\udea7 Multi-node clustering with shard placement</li> <li>\ud83d\udea7 Cross-region bridges with explicit data movement</li> <li>\ud83d\udea7 Security hardening (mTLS, RBAC, end-to-end encryption)</li> <li>\ud83d\udea7 Additional language clients (Python, Go)</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Get started with Felix in minutes:</p> <pre><code># Clone the repository\ngit clone https://github.com/gabloe/felix.git\ncd felix\n\n# Build the workspace\ncargo build --workspace --release\n\n# Run the broker\ncargo run --release -p broker\n\n# Run a demo\ncargo run --release -p broker --bin pubsubdemo\n</code></pre> <p>See the Quickstart Guide for detailed instructions.</p>"},{"location":"#community-support","title":"Community &amp; Support","text":"<ul> <li>GitHub: gabloe/felix</li> <li>Issues: Report bugs or request features</li> <li>License: Apache 2.0</li> </ul> <p>Ready to dive in? Start with the Overview or jump straight to the Quickstart Guide.</p>"},{"location":"api/broker-api/","title":"Broker API Reference","text":"<p>The Felix broker exposes a QUIC-based data plane API for publish/subscribe and cache operations. This document provides a comprehensive reference for interacting with the broker, including operation semantics, parameters, error handling, and usage examples.</p>"},{"location":"api/broker-api/#connection-model","title":"Connection Model","text":""},{"location":"api/broker-api/#quic-connection-lifecycle","title":"QUIC Connection Lifecycle","text":"<p>Clients establish QUIC connections to the broker over TLS 1.3:</p> <pre><code>sequenceDiagram\n    participant C as Client\n    participant B as Broker\n\n    C-&gt;&gt;B: QUIC ClientHello\n    B--&gt;&gt;C: QUIC ServerHello + TLS Certificate\n    C-&gt;&gt;B: TLS Finished\n    Note over C,B: Connection established\n    C-&gt;&gt;B: Open streams for operations</code></pre> <p>Default broker endpoint: <code>0.0.0.0:5000</code> (configurable via <code>quic_bind</code>)</p> <p>TLS requirements: - TLS 1.3 minimum - Certificate validation (can be disabled for development) - SNI supported for virtual hosting (future)</p>"},{"location":"api/broker-api/#connection-pooling","title":"Connection Pooling","text":"<p>For optimal performance, clients should maintain connection pools:</p> <pre><code>// Rust client example\nlet config = ClientConfig {\n    event_conn_pool: 8,      // Pool for pub/sub operations\n    cache_conn_pool: 8,      // Pool for cache operations\n    ..Default::default()\n};\n\nlet client = Client::connect(\"https://broker:5000\", config).await?;\n</code></pre> <p>Pool sizing guidance: - Event pool: 4-8 connections for typical workloads - Cache pool: 8-16 connections for high-concurrency cache access - Publish pool: 2-4 connections for publisher applications</p> <p>Connection Reuse</p> <p>Establishing QUIC connections has significant overhead (TLS handshake, key exchange). Reuse connections aggressively by maintaining long-lived pools.</p>"},{"location":"api/broker-api/#publish-operations","title":"Publish Operations","text":""},{"location":"api/broker-api/#single-message-publish","title":"Single Message Publish","text":"<p>Publish a single message to a stream.</p> <p>Request:</p> <pre><code>{\n  \"type\": \"publish\",\n  \"tenant_id\": \"string\",\n  \"namespace\": \"string\",\n  \"stream\": \"string\",\n  \"payload\": \"base64-encoded-bytes\",\n  \"ack\": \"none\" | \"per_message\"\n}\n</code></pre> <p>Parameters:</p> Parameter Type Required Description <code>tenant_id</code> string Yes Tenant identifier (must exist in broker) <code>namespace</code> string Yes Namespace within tenant <code>stream</code> string Yes Target stream name <code>payload</code> base64 Yes Message payload (base64-encoded binary) <code>ack</code> enum No Acknowledgement mode (default: <code>none</code>) <p>Acknowledgement modes:</p> <ul> <li><code>none</code>: Fire-and-forget, no broker acknowledgement</li> <li><code>per_message</code>: Broker sends <code>ok</code> after enqueuing message</li> </ul> <p>Response (if <code>ack</code> != <code>none</code>):</p> <pre><code>{\n  \"type\": \"ok\",\n  \"request_id\": \"string\"\n}\n</code></pre> <p>Errors:</p> <pre><code>{\n  \"type\": \"error\",\n  \"request_id\": \"string\",\n  \"message\": \"Unknown tenant: acme-corp\"\n}\n</code></pre> <p>Example usage:</p> <pre><code>use felix_client::Client;\n\nlet client = Client::connect(\"https://broker:5000\", config).await?;\n\n// Fire-and-forget publish\nclient.publish(\"acme\", \"prod\", \"events\", b\"Hello Felix\").await?;\n\n// With acknowledgement\nclient.publish_with_ack(\"acme\", \"prod\", \"events\", b\"Important message\").await?;\n</code></pre> <p>Performance characteristics:</p> <ul> <li>Latency: ~100-500 \u00b5s for ack mode (localhost)</li> <li>Throughput: ~50-100k messages/sec per connection (single message publishes)</li> <li>Bottleneck: JSON serialization and per-message framing overhead</li> </ul> <p>When to Use Single Publish</p> <p>Use single publish for: - Low-rate event streams (&lt; 1000 msg/sec) - Interactive request/response patterns - Simplicity over throughput</p> <p>For high-throughput workloads, use batch publish instead.</p>"},{"location":"api/broker-api/#batch-publish","title":"Batch Publish","text":"<p>Publish multiple messages in a single operation.</p> <p>Request:</p> <pre><code>{\n  \"type\": \"publish_batch\",\n  \"tenant_id\": \"string\",\n  \"namespace\": \"string\",\n  \"stream\": \"string\",\n  \"payloads\": [\"base64-1\", \"base64-2\", \"base64-n\"],\n  \"ack\": \"none\" | \"per_batch\"\n}\n</code></pre> <p>Parameters:</p> Parameter Type Required Description <code>tenant_id</code> string Yes Tenant identifier <code>namespace</code> string Yes Namespace within tenant <code>stream</code> string Yes Target stream name <code>payloads</code> array Yes Array of base64-encoded payloads <code>ack</code> enum No Acknowledgement mode (default: <code>none</code>) <p>Response (if <code>ack</code> == <code>per_batch</code>):</p> <pre><code>{\n  \"type\": \"ok\",\n  \"request_id\": \"string\"\n}\n</code></pre> <p>Example usage:</p> <pre><code>let messages = vec![\n    b\"Event 1\".to_vec(),\n    b\"Event 2\".to_vec(),\n    b\"Event 3\".to_vec(),\n];\n\nclient.publish_batch(\"acme\", \"prod\", \"events\", messages).await?;\n</code></pre> <p>Performance characteristics:</p> <ul> <li>Latency: ~200-1000 \u00b5s for batch of 64 (includes fanout)</li> <li>Throughput: ~150-250k messages/sec per connection (batch=64)</li> <li>Optimal batch size: 32-128 messages</li> </ul> <p>Batch size tuning:</p> <pre><code>// Small batches: lower latency, lower throughput\nlet small_batch = collect_messages(timeout_ms: 10, max_count: 8);\nclient.publish_batch(\"acme\", \"prod\", \"stream\", small_batch).await?;\n\n// Large batches: higher latency, higher throughput\nlet large_batch = collect_messages(timeout_ms: 100, max_count: 128);\nclient.publish_batch(\"acme\", \"prod\", \"stream\", large_batch).await?;\n</code></pre>"},{"location":"api/broker-api/#binary-batch-publish","title":"Binary Batch Publish","text":"<p>For maximum throughput, use binary encoding.</p> <p>Frame flags: Set bit 0 (<code>flags | 0x0001</code>)</p> <p>Binary format:</p> <pre><code>[tenant_len: u16][tenant_id: bytes]\n[namespace_len: u16][namespace: bytes]\n[stream_len: u16][stream: bytes]\n[count: u32]\n[payload_1_len: u32][payload_1: bytes]\n[payload_2_len: u32][payload_2: bytes]\n...\n</code></pre> <p>Example (Rust client handles encoding automatically):</p> <pre><code>// Client automatically uses binary mode for large batches when enabled\nlet config = ClientConfig {\n    binary_mode_enabled: true,\n    binary_mode_threshold_bytes: 512,\n    ..Default::default()\n};\n\n// Large batch automatically encoded as binary\nlet messages = vec![large_payload_1, large_payload_2, ...];\nclient.publish_batch(\"acme\", \"prod\", \"stream\", messages).await?;\n</code></pre> <p>Performance improvement:</p> <ul> <li>30-40% higher throughput vs JSON for large batches</li> <li>Lower CPU usage (no JSON parsing)</li> <li>Best for: payload &gt; 512 bytes, batch &gt; 32 messages</li> </ul>"},{"location":"api/broker-api/#publish-pipeline-configuration","title":"Publish Pipeline Configuration","text":"<p>Broker-side tuning for publish pipeline:</p> <pre><code># Broker config.yml\npub_workers_per_conn: 4        # Workers per connection\npub_queue_depth: 1024           # Publish queue bound\npublish_queue_wait_timeout_ms: 2000  # Queue full timeout\npublish_chunk_bytes: 16384      # Large payload chunking\n</code></pre> <p>Worker sizing:</p> <pre><code>pub_workers_per_conn \u2264 active_publish_streams\n</code></pre> <p>Over-sizing workers creates contention without benefit.</p>"},{"location":"api/broker-api/#subscribe-operations","title":"Subscribe Operations","text":""},{"location":"api/broker-api/#creating-a-subscription","title":"Creating a Subscription","text":"<p>Subscribe to a stream to receive events.</p> <p>Request:</p> <pre><code>{\n  \"type\": \"subscribe\",\n  \"tenant_id\": \"string\",\n  \"namespace\": \"string\",\n  \"stream\": \"string\"\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"type\": \"ok\",\n  \"request_id\": \"string\"\n}\n</code></pre> <p>Broker behavior:</p> <ol> <li>Broker validates tenant/namespace/stream</li> <li>Broker sends <code>ok</code> on control stream</li> <li>Broker opens new unidirectional stream for events</li> <li>Broker sends <code>event_stream_hello</code> as first frame on event stream</li> <li>Broker begins streaming events</li> </ol> <p>Example usage:</p> <pre><code>let mut subscription = client.subscribe(\"acme\", \"prod\", \"events\").await?;\n\n// Receive events\nwhile let Some(event) = subscription.next().await {\n    println!(\"Received: {:?}\", event.payload);\n}\n</code></pre>"},{"location":"api/broker-api/#receiving-events","title":"Receiving Events","text":"<p>Events arrive on a dedicated unidirectional stream per subscription.</p> <p>Event frame:</p> <pre><code>{\n  \"type\": \"event\",\n  \"tenant_id\": \"acme\",\n  \"namespace\": \"prod\",\n  \"stream\": \"events\",\n  \"payload\": \"base64-encoded-bytes\"\n}\n</code></pre> <p>Event batch frame:</p> <pre><code>{\n  \"type\": \"event_batch\",\n  \"tenant_id\": \"acme\",\n  \"namespace\": \"prod\",\n  \"stream\": \"events\",\n  \"payloads\": [\"base64-1\", \"base64-2\", \"base64-n\"]\n}\n</code></pre> <p>Event stream lifecycle:</p> <pre><code>sequenceDiagram\n    participant C as Client\n    participant B as Broker\n\n    C-&gt;&gt;B: subscribe\n    B--&gt;&gt;C: ok\n    Note over B: Open event stream\n    B-&gt;&gt;C: event_stream_hello\n    loop Event delivery\n        B-&gt;&gt;C: event or event_batch\n    end\n    Note over C: Client closes connection\n    Note over B: Broker closes event stream</code></pre>"},{"location":"api/broker-api/#subscription-configuration","title":"Subscription Configuration","text":"<p>Client-side configuration:</p> <pre><code>let config = ClientConfig {\n    event_conn_pool: 8,              // Connection pool size\n    event_buffer_size: 1024,         // Client-side buffer per subscription\n    ..Default::default()\n};\n</code></pre> <p>Broker-side configuration:</p> <pre><code>event_queue_depth: 1024              # Per-subscription buffer\nevent_batch_max_events: 64           # Max events per batch\nevent_batch_max_bytes: 262144        # Max batch size (256 KB)\nevent_batch_max_delay_us: 250        # Max batching delay (250 \u00b5s)\n</code></pre> <p>Batching trade-offs:</p> Parameter Effect on Latency Effect on Throughput Increase <code>max_events</code> Higher Higher Increase <code>max_delay_us</code> Higher Higher Decrease <code>max_events</code> Lower Lower Decrease <code>max_delay_us</code> Lower Lower"},{"location":"api/broker-api/#multiple-subscriptions","title":"Multiple Subscriptions","text":"<p>Clients can maintain multiple concurrent subscriptions:</p> <pre><code>// Subscribe to multiple streams\nlet mut sub1 = client.subscribe(\"acme\", \"prod\", \"orders\").await?;\nlet mut sub2 = client.subscribe(\"acme\", \"prod\", \"inventory\").await?;\nlet mut sub3 = client.subscribe(\"acme\", \"staging\", \"logs\").await?;\n\n// Process events from all subscriptions concurrently\ntokio::select! {\n    Some(event) = sub1.next() =&gt; handle_order(event),\n    Some(event) = sub2.next() =&gt; handle_inventory(event),\n    Some(event) = sub3.next() =&gt; handle_log(event),\n}\n</code></pre> <p>Each subscription gets: - Independent event stream - Independent buffer - Independent flow control</p>"},{"location":"api/broker-api/#subscription-isolation","title":"Subscription Isolation","text":"<p>Slow subscribers don't affect fast subscribers:</p> <pre><code>// Fast subscriber\nlet mut fast_sub = client.subscribe(\"acme\", \"prod\", \"stream\").await?;\ntokio::spawn(async move {\n    while let Some(event) = fast_sub.next().await {\n        process_quickly(event).await;  // ~1ms processing\n    }\n});\n\n// Slow subscriber\nlet mut slow_sub = client.subscribe(\"acme\", \"prod\", \"stream\").await?;\ntokio::spawn(async move {\n    while let Some(event) = slow_sub.next().await {\n        process_slowly(event).await;  // ~100ms processing\n    }\n});\n\n// Fast subscriber continues at full rate even if slow subscriber falls behind\n</code></pre>"},{"location":"api/broker-api/#cache-operations","title":"Cache Operations","text":""},{"location":"api/broker-api/#cache-put","title":"Cache Put","text":"<p>Store a key-value pair with optional TTL.</p> <p>Request:</p> <pre><code>{\n  \"type\": \"cache_put\",\n  \"request_id\": \"unique-id\",\n  \"key\": \"string\",\n  \"value\": \"base64-encoded-bytes\",\n  \"ttl_ms\": number | null\n}\n</code></pre> <p>Parameters:</p> Parameter Type Required Description <code>request_id</code> string Yes Client-provided correlation ID <code>key</code> string Yes Cache key <code>value</code> base64 Yes Value to store (base64-encoded) <code>ttl_ms</code> number No Time-to-live in milliseconds (null = no expiration) <p>Response:</p> <pre><code>{\n  \"type\": \"ok\",\n  \"request_id\": \"unique-id\"\n}\n</code></pre> <p>Example usage:</p> <pre><code>// Store session with 1-hour TTL\nclient.cache_put(\"sessions\", session_id, session_data, Some(3600_000)).await?;\n\n// Store config without expiration\nclient.cache_put(\"config\", \"app-settings\", config_data, None).await?;\n</code></pre> <p>Performance:</p> <ul> <li>p50 latency: 160-260 \u00b5s (varies with payload size)</li> <li>p99 latency: 350-450 \u00b5s</li> <li>Throughput: 125-185k ops/sec (concurrency=32)</li> </ul>"},{"location":"api/broker-api/#cache-get","title":"Cache Get","text":"<p>Retrieve a value from the cache.</p> <p>Request:</p> <pre><code>{\n  \"type\": \"cache_get\",\n  \"request_id\": \"unique-id\",\n  \"key\": \"string\"\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"type\": \"cache_value\",\n  \"request_id\": \"unique-id\",\n  \"key\": \"string\",\n  \"value\": \"base64-encoded-bytes\" | null\n}\n</code></pre> <p>Value is null when: - Key doesn't exist - Key has expired (TTL elapsed) - Key was evicted under memory pressure</p> <p>Example usage:</p> <pre><code>match client.cache_get(\"sessions\", session_id).await? {\n    Some(session_data) =&gt; {\n        // Session found\n        validate_session(session_data)?;\n    }\n    None =&gt; {\n        // Session expired or doesn't exist\n        return Err(\"Invalid session\");\n    }\n}\n</code></pre>"},{"location":"api/broker-api/#cache-request-pipelining","title":"Cache Request Pipelining","text":"<p>Cache streams support pipelining multiple requests:</p> <pre><code>// Send multiple requests without waiting\nlet req1 = client.cache_get_async(\"config\", \"key1\");\nlet req2 = client.cache_get_async(\"config\", \"key2\");\nlet req3 = client.cache_get_async(\"config\", \"key3\");\n\n// Await responses\nlet (val1, val2, val3) = tokio::join!(req1, req2, req3);\n</code></pre> <p>Benefits: - Amortize network round-trip latency - Improve throughput under concurrency - Reduce overall request completion time</p> <p>Request_id requirement:</p> <p>Each request must have a unique <code>request_id</code> within a stream. The broker may respond out of order; clients use <code>request_id</code> to correlate responses.</p>"},{"location":"api/broker-api/#cache-stream-pooling","title":"Cache Stream Pooling","text":"<p>For high-concurrency cache workloads, use stream pooling:</p> <pre><code># Client config\ncache_conn_pool: 8                # Number of connections\ncache_streams_per_conn: 4         # Streams per connection\n# Total concurrent cache operations: 8 \u00d7 4 = 32\n</code></pre> <p>Performance impact:</p> Config p50 (\u00b5s) p99 (\u00b5s) Throughput (k ops/s) 1 conn, 1 stream 175 850 45 4 conn, 2 streams 168 420 125 8 conn, 4 streams 165 360 180"},{"location":"api/broker-api/#cache-configuration","title":"Cache Configuration","text":"<p>Broker-side cache tuning:</p> <pre><code>cache_conn_recv_window: 268435456    # 256 MiB per connection\ncache_stream_recv_window: 67108864   # 64 MiB per stream\ncache_send_window: 268435456         # 256 MiB send window\n</code></pre>"},{"location":"api/broker-api/#error-handling","title":"Error Handling","text":""},{"location":"api/broker-api/#error-response-format","title":"Error Response Format","text":"<pre><code>{\n  \"type\": \"error\",\n  \"request_id\": \"string\",\n  \"message\": \"Descriptive error message\"\n}\n</code></pre>"},{"location":"api/broker-api/#common-errors","title":"Common Errors","text":"<p>Unknown tenant/namespace/stream:</p> <pre><code>{\n  \"type\": \"error\",\n  \"message\": \"Unknown tenant: acme-corp\"\n}\n</code></pre> <p>Resolution: Ensure tenant/namespace exists in broker metadata.</p> <p>Malformed request:</p> <pre><code>{\n  \"type\": \"error\",\n  \"message\": \"Invalid JSON payload\"\n}\n</code></pre> <p>Resolution: Validate request JSON schema.</p> <p>Timeout:</p> <pre><code>{\n  \"type\": \"error\",\n  \"message\": \"Publish queue timeout after 2000ms\"\n}\n</code></pre> <p>Resolution: Broker is overloaded. Reduce publish rate or increase <code>pub_workers_per_conn</code>.</p> <p>Authorization failure (future):</p> <pre><code>{\n  \"type\": \"error\",\n  \"message\": \"Unauthorized: insufficient permissions for stream 'events'\"\n}\n</code></pre>"},{"location":"api/broker-api/#connection-errors","title":"Connection Errors","text":"<p>QUIC connection errors are surfaced as connection-level failures:</p> <ul> <li>Certificate validation failure: TLS handshake error</li> <li>Connection timeout: No response within QUIC idle timeout</li> <li>Connection reset: Broker restart or network issue</li> </ul> <p>Retry logic:</p> <pre><code>async fn publish_with_retry(client: &amp;Client, retries: u32) -&gt; Result&lt;()&gt; {\n    for attempt in 0..retries {\n        match client.publish(\"acme\", \"prod\", \"events\", data).await {\n            Ok(_) =&gt; return Ok(()),\n            Err(e) if e.is_retriable() =&gt; {\n                tokio::time::sleep(Duration::from_millis(100 * 2u64.pow(attempt))).await;\n                continue;\n            }\n            Err(e) =&gt; return Err(e),\n        }\n    }\n    Err(\"Max retries exceeded\")\n}\n</code></pre>"},{"location":"api/broker-api/#performance-tuning","title":"Performance Tuning","text":""},{"location":"api/broker-api/#publish-performance","title":"Publish Performance","text":"<p>Maximize throughput:</p> <pre><code># Broker config\npub_workers_per_conn: 8\npub_queue_depth: 4096\nevent_batch_max_events: 256\nevent_batch_max_delay_us: 2000\n</code></pre> <pre><code>// Client: use large batches and binary mode\nlet config = ClientConfig {\n    binary_mode_enabled: true,\n    publish_batch_size: 128,\n    ..Default::default()\n};\n</code></pre> <p>Minimize latency:</p> <pre><code># Broker config\npub_workers_per_conn: 2\nevent_batch_max_events: 8\nevent_batch_max_delay_us: 100\n</code></pre> <pre><code>// Client: publish immediately\nclient.publish_with_ack(\"acme\", \"prod\", \"events\", data).await?;\n</code></pre>"},{"location":"api/broker-api/#subscribe-performance","title":"Subscribe Performance","text":"<p>High fanout tuning:</p> <pre><code>event_queue_depth: 4096           # Larger buffer for burst tolerance\nfanout_batch_size: 128            # Batch fanout operations\nevent_batch_max_events: 128       # Larger event batches\n</code></pre> <p>Low latency tuning:</p> <pre><code>event_queue_depth: 512\nevent_batch_max_events: 8\nevent_batch_max_delay_us: 100\n</code></pre>"},{"location":"api/broker-api/#cache-performance","title":"Cache Performance","text":"<p>High concurrency:</p> <pre><code>cache_conn_pool: 16\ncache_streams_per_conn: 8\n# Total: 128 concurrent operations\n</code></pre> <p>Low latency:</p> <pre><code>cache_conn_pool: 4\ncache_streams_per_conn: 2\ncache_conn_recv_window: 134217728  # Smaller windows for lower memory\n</code></pre>"},{"location":"api/broker-api/#best-practices","title":"Best Practices","text":""},{"location":"api/broker-api/#connection-management","title":"Connection Management","text":"<ol> <li>Pool connections: Don't create per-request connections</li> <li>Reuse streams: Keep streams alive for multiple operations</li> <li>Handle disconnections: Implement automatic reconnection</li> <li>Monitor health: Track connection failures and latency</li> </ol>"},{"location":"api/broker-api/#publish-patterns","title":"Publish Patterns","text":"<ol> <li>Batch when possible: 10-100x throughput improvement</li> <li>Use binary mode for large payloads: 30-40% improvement</li> <li>Don't block on acks for high throughput: Use <code>ack: none</code></li> <li>Spread across connections: Use connection pooling for parallelism</li> </ol>"},{"location":"api/broker-api/#subscribe-patterns","title":"Subscribe Patterns","text":"<ol> <li>Process events quickly: Avoid blocking subscription loop</li> <li>Use async processing: Spawn tasks for slow operations</li> <li>Monitor lag: Track processing delays</li> <li>Handle reconnection: Re-subscribe on connection loss</li> </ol>"},{"location":"api/broker-api/#cache-patterns","title":"Cache Patterns","text":"<ol> <li>Pipeline requests: Send multiple requests concurrently</li> <li>Use appropriate TTLs: Match data staleness tolerance</li> <li>Handle misses gracefully: Cache is best-effort</li> <li>Don't cache huge values: Keep values &lt; 1 MB</li> </ol> <p>Profile Your Workload</p> <p>Use broker telemetry and client metrics to identify bottlenecks. Common issues: - Too few workers \u2192 high queue depth - Too many workers \u2192 contention - Small buffers \u2192 dropped events - Large buffers \u2192 high memory usage</p>"},{"location":"api/client-sdk/","title":"Rust Client SDK","text":"<p>The Felix Rust client SDK (<code>felix-client</code>) provides ergonomic, high-performance APIs for publishing, subscribing, and caching over QUIC. This document covers installation, configuration, and usage patterns for building applications with Felix.</p>"},{"location":"api/client-sdk/#installation","title":"Installation","text":"<p>Add Felix client to your <code>Cargo.toml</code>:</p> <pre><code>[dependencies]\nfelix-client = \"0.1\"\nfelix-common = \"0.1\"  # For error types and shared utilities\n</code></pre> <p>Optional features:</p> <pre><code>[dependencies]\nfelix-client = { version = \"0.1\", features = [\"telemetry\"] }\n</code></pre> <p>Features:</p> <ul> <li><code>telemetry</code>: Enable per-operation timing and frame counters (adds overhead)</li> </ul>"},{"location":"api/client-sdk/#quick-start","title":"Quick Start","text":""},{"location":"api/client-sdk/#basic-publishsubscribe","title":"Basic Publish/Subscribe","text":"<pre><code>use felix_client::{Client, ClientConfig};\nuse anyhow::Result;\n\n#[tokio::main]\nasync fn main() -&gt; Result&lt;()&gt; {\n    // Connect to broker\n    let client = Client::connect(\n        \"https://localhost:5000\",\n        ClientConfig::default()\n    ).await?;\n\n    // Publish a message\n    client.publish(\n        \"acme\",           // tenant_id\n        \"prod\",           // namespace\n        \"events\",         // stream\n        b\"Hello Felix\"    // payload\n    ).await?;\n\n    // Subscribe to stream\n    let mut subscription = client.subscribe(\n        \"acme\",\n        \"prod\",\n        \"events\"\n    ).await?;\n\n    // Receive events\n    while let Some(event) = subscription.next().await {\n        println!(\"Received: {:?}\", event.payload);\n    }\n\n    Ok(())\n}\n</code></pre>"},{"location":"api/client-sdk/#basic-cache-operations","title":"Basic Cache Operations","text":"<pre><code>// Store value with 60-second TTL\nclient.cache_put(\n    \"sessions\",\n    \"user-123\",\n    b\"session-data\",\n    Some(60_000)  // TTL in milliseconds\n).await?;\n\n// Retrieve value\nmatch client.cache_get(\"sessions\", \"user-123\").await? {\n    Some(value) =&gt; println!(\"Found: {:?}\", value),\n    None =&gt; println!(\"Not found or expired\"),\n}\n</code></pre>"},{"location":"api/client-sdk/#client-configuration","title":"Client Configuration","text":""},{"location":"api/client-sdk/#clientconfig","title":"ClientConfig","text":"<pre><code>use felix_client::ClientConfig;\n\nlet config = ClientConfig {\n    // Connection pools\n    event_conn_pool: 8,              // Connections for pub/sub\n    cache_conn_pool: 8,              // Connections for cache\n    publish_conn_pool: 4,            // Connections for publishing\n\n    // Streams per connection\n    publish_streams_per_conn: 2,     // Publish streams per conn\n    cache_streams_per_conn: 4,       // Cache streams per conn\n\n    // Buffering\n    event_buffer_size: 1024,         // Client-side event buffer\n    publish_queue_size: 1024,        // Publish queue bound\n    cache_queue_size: 1024,          // Cache request queue\n\n    // Binary mode\n    binary_mode_enabled: true,       // Enable binary batches\n    binary_mode_threshold_bytes: 512, // Min size for binary\n\n    // TLS\n    tls_skip_verify: false,          // Skip cert validation (dev only!)\n    tls_ca_cert_path: None,          // Custom CA cert\n\n    // Timeouts\n    connect_timeout_ms: 5000,\n    idle_timeout_ms: 30000,\n\n    ..Default::default()\n};\n\nlet client = Client::connect(\"https://broker:5000\", config).await?;\n</code></pre>"},{"location":"api/client-sdk/#configuration-tuning","title":"Configuration Tuning","text":"<p>Low-latency configuration:</p> <pre><code>let config = ClientConfig {\n    event_conn_pool: 4,\n    cache_conn_pool: 4,\n    publish_streams_per_conn: 1,\n    cache_streams_per_conn: 2,\n    event_buffer_size: 512,\n    binary_mode_enabled: false,  // JSON for simplicity\n    ..Default::default()\n};\n</code></pre> <p>High-throughput configuration:</p> <pre><code>let config = ClientConfig {\n    event_conn_pool: 16,\n    cache_conn_pool: 16,\n    publish_streams_per_conn: 4,\n    cache_streams_per_conn: 8,\n    event_buffer_size: 4096,\n    publish_queue_size: 4096,\n    binary_mode_enabled: true,\n    binary_mode_threshold_bytes: 256,\n    ..Default::default()\n};\n</code></pre>"},{"location":"api/client-sdk/#publishing","title":"Publishing","text":""},{"location":"api/client-sdk/#single-message-publish","title":"Single Message Publish","text":"<pre><code>// Fire-and-forget (no ack)\nclient.publish(\"acme\", \"prod\", \"events\", b\"message\").await?;\n\n// With acknowledgement\nclient.publish_with_ack(\"acme\", \"prod\", \"events\", b\"important\").await?;\n</code></pre>"},{"location":"api/client-sdk/#batch-publishing","title":"Batch Publishing","text":"<p>Publish multiple messages efficiently:</p> <pre><code>let messages = vec![\n    b\"message 1\".to_vec(),\n    b\"message 2\".to_vec(),\n    b\"message 3\".to_vec(),\n];\n\nclient.publish_batch(\n    \"acme\",\n    \"prod\",\n    \"events\",\n    messages\n).await?;\n</code></pre>"},{"location":"api/client-sdk/#publisher-api","title":"Publisher API","text":"<p>For high-throughput publishing, use the <code>Publisher</code> API:</p> <pre><code>use felix_client::Publisher;\n\n// Create publisher with custom config\nlet publisher = client.create_publisher(\n    \"acme\",\n    \"prod\",\n    \"events\",\n    PublisherConfig {\n        sharding: PublishSharding::HashStream,  // or RoundRobin\n        ack_mode: AckMode::None,\n        binary_enabled: true,\n        ..Default::default()\n    }\n).await?;\n\n// Publish with automatic batching\nfor i in 0..10000 {\n    let payload = format!(\"Event {}\", i);\n    publisher.publish(payload.as_bytes()).await?;\n}\n\n// Flush any pending batches\npublisher.flush().await?;\n</code></pre>"},{"location":"api/client-sdk/#publisher-sharding","title":"Publisher Sharding","text":"<p>Control load distribution across worker streams:</p> <pre><code>use felix_client::PublishSharding;\n\n// Round-robin: distribute evenly across workers\nPublishSharding::RoundRobin\n\n// Hash-based: consistent hashing by stream name\nPublishSharding::HashStream\n</code></pre> <p>When to use each:</p> <ul> <li>RoundRobin: Default, good for single stream, evenly distributes load</li> <li>HashStream: Publishing to multiple streams, keeps stream-specific ordering</li> </ul>"},{"location":"api/client-sdk/#error-handling","title":"Error Handling","text":"<pre><code>use felix_common::Error;\n\nmatch client.publish(\"acme\", \"prod\", \"events\", b\"data\").await {\n    Ok(()) =&gt; println!(\"Published successfully\"),\n    Err(Error::UnknownStream { .. }) =&gt; {\n        eprintln!(\"Stream doesn't exist\");\n    }\n    Err(Error::Timeout { .. }) =&gt; {\n        eprintln!(\"Publish timed out, broker overloaded\");\n    }\n    Err(Error::ConnectionLost) =&gt; {\n        eprintln!(\"Connection lost, reconnecting...\");\n        // Implement retry logic\n    }\n    Err(e) =&gt; eprintln!(\"Other error: {:?}\", e),\n}\n</code></pre>"},{"location":"api/client-sdk/#subscribing","title":"Subscribing","text":""},{"location":"api/client-sdk/#creating-subscriptions","title":"Creating Subscriptions","text":"<pre><code>let mut subscription = client.subscribe(\"acme\", \"prod\", \"events\").await?;\n\n// Process events\nwhile let Some(event) = subscription.next().await {\n    process_event(event).await?;\n}\n</code></pre>"},{"location":"api/client-sdk/#event-structure","title":"Event Structure","text":"<pre><code>pub struct Event {\n    pub tenant_id: String,\n    pub namespace: String,\n    pub stream: String,\n    pub payload: Vec&lt;u8&gt;,\n}\n</code></pre>"},{"location":"api/client-sdk/#multiple-subscriptions","title":"Multiple Subscriptions","text":"<p>Handle multiple streams concurrently:</p> <pre><code>use tokio::select;\n\nlet mut sub1 = client.subscribe(\"acme\", \"prod\", \"orders\").await?;\nlet mut sub2 = client.subscribe(\"acme\", \"prod\", \"inventory\").await?;\nlet mut sub3 = client.subscribe(\"acme\", \"staging\", \"logs\").await?;\n\nloop {\n    select! {\n        Some(event) = sub1.next() =&gt; handle_order(event).await?,\n        Some(event) = sub2.next() =&gt; handle_inventory(event).await?,\n        Some(event) = sub3.next() =&gt; handle_log(event).await?,\n        else =&gt; break,\n    }\n}\n</code></pre>"},{"location":"api/client-sdk/#async-event-processing","title":"Async Event Processing","text":"<p>Avoid blocking the subscription loop:</p> <pre><code>// Bad: blocks subscription loop\nwhile let Some(event) = subscription.next().await {\n    expensive_processing(event).await?;  // Blocks next event\n}\n\n// Good: spawn task for processing\nwhile let Some(event) = subscription.next().await {\n    tokio::spawn(async move {\n        expensive_processing(event).await.ok();\n    });\n}\n\n// Better: use bounded channel for backpressure\nlet (tx, mut rx) = mpsc::channel(100);\n\ntokio::spawn(async move {\n    while let Some(event) = rx.recv().await {\n        expensive_processing(event).await.ok();\n    }\n});\n\nwhile let Some(event) = subscription.next().await {\n    tx.send(event).await.ok();\n}\n</code></pre>"},{"location":"api/client-sdk/#subscription-lifecycle","title":"Subscription Lifecycle","text":"<pre><code>// Subscribe\nlet mut sub = client.subscribe(\"acme\", \"prod\", \"events\").await?;\n\n// Process events\nfor _ in 0..100 {\n    if let Some(event) = sub.next().await {\n        process(event);\n    }\n}\n\n// Explicitly close (or drop to auto-close)\nsub.close().await?;\n</code></pre>"},{"location":"api/client-sdk/#cache-operations","title":"Cache Operations","text":""},{"location":"api/client-sdk/#put-and-get","title":"Put and Get","text":"<pre><code>// Put with TTL\nclient.cache_put(\n    \"sessions\",           // cache namespace\n    \"user-abc\",           // key\n    session_data,         // value\n    Some(3600_000)        // 1 hour TTL\n).await?;\n\n// Get\nmatch client.cache_get(\"sessions\", \"user-abc\").await? {\n    Some(data) =&gt; {\n        let session: Session = deserialize(&amp;data)?;\n        // Use session\n    }\n    None =&gt; {\n        // Session expired or doesn't exist\n        return Err(\"Invalid session\");\n    }\n}\n</code></pre>"},{"location":"api/client-sdk/#without-ttl","title":"Without TTL","text":"<pre><code>// Store permanently (until evicted or restart)\nclient.cache_put(\"config\", \"app-settings\", config_data, None).await?;\n</code></pre>"},{"location":"api/client-sdk/#concurrent-cache-operations","title":"Concurrent Cache Operations","text":"<p>Pipeline multiple cache operations:</p> <pre><code>use futures::future::join_all;\n\n// Issue multiple requests concurrently\nlet futures = (0..10).map(|i| {\n    let key = format!(\"key-{}\", i);\n    client.cache_get(\"data\", &amp;key)\n});\n\nlet results = join_all(futures).await;\n\nfor result in results {\n    if let Ok(Some(value)) = result {\n        process(value);\n    }\n}\n</code></pre>"},{"location":"api/client-sdk/#cache-namespacing","title":"Cache Namespacing","text":"<p>Cache keys are scoped to prevent collisions:</p> <pre><code>// These are independent entries\nclient.cache_put(\"sessions\", \"user-123\", data1, ttl).await?;\nclient.cache_put(\"profiles\", \"user-123\", data2, ttl).await?;\nclient.cache_put(\"temp\", \"user-123\", data3, ttl).await?;\n</code></pre>"},{"location":"api/client-sdk/#in-process-client","title":"In-Process Client","text":"<p>For testing and embedded scenarios, use the in-process client:</p> <pre><code>use felix_client::InProcessClient;\nuse felix_broker::Broker;\n\n// Create embedded broker\nlet broker = Broker::new(broker_config).await?;\n\n// Create in-process client (no network)\nlet client = InProcessClient::new(broker.clone());\n\n// Same API as network client\nclient.publish(\"acme\", \"prod\", \"test\", b\"data\").await?;\nlet mut sub = client.subscribe(\"acme\", \"prod\", \"test\").await?;\n</code></pre> <p>Use cases:</p> <ul> <li>Unit tests</li> <li>Integration tests</li> <li>Embedded applications</li> <li>Benchmarking without network overhead</li> </ul>"},{"location":"api/client-sdk/#connection-management","title":"Connection Management","text":""},{"location":"api/client-sdk/#automatic-reconnection","title":"Automatic Reconnection","text":"<p>Clients should implement reconnection logic:</p> <pre><code>async fn connect_with_retry(\n    url: &amp;str,\n    config: ClientConfig,\n    max_retries: u32\n) -&gt; Result&lt;Client&gt; {\n    for attempt in 0..max_retries {\n        match Client::connect(url, config.clone()).await {\n            Ok(client) =&gt; return Ok(client),\n            Err(e) if attempt &lt; max_retries - 1 =&gt; {\n                let delay = Duration::from_millis(100 * 2u64.pow(attempt));\n                eprintln!(\"Connection failed, retrying in {:?}: {}\", delay, e);\n                tokio::time::sleep(delay).await;\n            }\n            Err(e) =&gt; return Err(e),\n        }\n    }\n    unreachable!()\n}\n</code></pre>"},{"location":"api/client-sdk/#health-monitoring","title":"Health Monitoring","text":"<p>Check connection health:</p> <pre><code>async fn monitor_connection(client: &amp;Client) -&gt; Result&lt;()&gt; {\n    loop {\n        match client.health_check().await {\n            Ok(()) =&gt; {\n                // Connection healthy\n            }\n            Err(e) =&gt; {\n                eprintln!(\"Health check failed: {:?}\", e);\n                // Implement reconnection\n            }\n        }\n        tokio::time::sleep(Duration::from_secs(5)).await;\n    }\n}\n</code></pre>"},{"location":"api/client-sdk/#telemetry","title":"Telemetry","text":""},{"location":"api/client-sdk/#enabling-telemetry","title":"Enabling Telemetry","text":"<p>Compile with telemetry feature:</p> <pre><code>[dependencies]\nfelix-client = { version = \"0.1\", features = [\"telemetry\"] }\n</code></pre>"},{"location":"api/client-sdk/#collecting-metrics","title":"Collecting Metrics","text":"<pre><code>use felix_client::{frame_counters_snapshot, reset_frame_counters};\n\n// Get current frame counters\nlet counters = frame_counters_snapshot();\nprintln!(\"Publish frames: {}\", counters.publish_frames);\nprintln!(\"Event frames: {}\", counters.event_frames);\nprintln!(\"Cache put frames: {}\", counters.cache_put_frames);\nprintln!(\"Cache get frames: {}\", counters.cache_get_frames);\n\n// Reset counters\nreset_frame_counters();\n</code></pre>"},{"location":"api/client-sdk/#timing-measurements","title":"Timing Measurements","text":"<pre><code>use felix_client::timings;\n\n// Get timing snapshots\nlet publish_timings = timings::publish_timings_snapshot();\nprintln!(\"Publish p50: {:?}\", publish_timings.p50);\nprintln!(\"Publish p99: {:?}\", publish_timings.p99);\n\nlet subscribe_timings = timings::subscribe_timings_snapshot();\nprintln!(\"Event delivery p50: {:?}\", subscribe_timings.p50);\n</code></pre> <p>Telemetry Overhead</p> <p>Telemetry adds measurable overhead (5-15% in high-throughput workloads). Use only for debugging and profiling, not in production hot paths unless necessary.</p>"},{"location":"api/client-sdk/#best-practices","title":"Best Practices","text":""},{"location":"api/client-sdk/#connection-pooling","title":"Connection Pooling","text":"<pre><code>// Good: reuse client across application\nlazy_static! {\n    static ref FELIX_CLIENT: Client = {\n        let config = ClientConfig::default();\n        tokio::runtime::Runtime::new()\n            .unwrap()\n            .block_on(Client::connect(\"https://broker:5000\", config))\n            .unwrap()\n    };\n}\n\n// Use shared client\nFELIX_CLIENT.publish(\"acme\", \"prod\", \"events\", data).await?;\n</code></pre>"},{"location":"api/client-sdk/#error-recovery","title":"Error Recovery","text":"<pre><code>async fn publish_with_retry(\n    client: &amp;Client,\n    tenant: &amp;str,\n    namespace: &amp;str,\n    stream: &amp;str,\n    data: &amp;[u8],\n    max_retries: u32\n) -&gt; Result&lt;()&gt; {\n    for attempt in 0..max_retries {\n        match client.publish(tenant, namespace, stream, data).await {\n            Ok(()) =&gt; return Ok(()),\n            Err(e) if is_retriable(&amp;e) &amp;&amp; attempt &lt; max_retries - 1 =&gt; {\n                tokio::time::sleep(Duration::from_millis(100)).await;\n                continue;\n            }\n            Err(e) =&gt; return Err(e),\n        }\n    }\n    unreachable!()\n}\n\nfn is_retriable(error: &amp;felix_common::Error) -&gt; bool {\n    matches!(error,\n        felix_common::Error::Timeout { .. } |\n        felix_common::Error::ConnectionLost\n    )\n}\n</code></pre>"},{"location":"api/client-sdk/#resource-cleanup","title":"Resource Cleanup","text":"<pre><code>// Subscriptions are cleaned up on drop, but explicit close is better\n{\n    let mut sub = client.subscribe(\"acme\", \"prod\", \"events\").await?;\n    // Process events...\n    sub.close().await?;  // Explicit close\n}  // Or automatic close on drop\n</code></pre>"},{"location":"api/client-sdk/#batching-for-throughput","title":"Batching for Throughput","text":"<pre><code>use tokio::time::{interval, Duration};\n\nasync fn batching_publisher(client: &amp;Client) -&gt; Result&lt;()&gt; {\n    let mut batch = Vec::new();\n    let mut ticker = interval(Duration::from_millis(10));\n\n    loop {\n        select! {\n            _ = ticker.tick() =&gt; {\n                if !batch.is_empty() {\n                    client.publish_batch(\"acme\", \"prod\", \"events\", batch.clone()).await?;\n                    batch.clear();\n                }\n            }\n            msg = receive_message() =&gt; {\n                batch.push(msg);\n                if batch.len() &gt;= 64 {\n                    client.publish_batch(\"acme\", \"prod\", \"events\", batch.clone()).await?;\n                    batch.clear();\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"api/client-sdk/#testing","title":"Testing","text":""},{"location":"api/client-sdk/#unit-tests-with-in-process-client","title":"Unit Tests with In-Process Client","text":"<pre><code>#[tokio::test]\nasync fn test_publish_subscribe() {\n    let broker = Broker::new(BrokerConfig::default()).await.unwrap();\n    let client = InProcessClient::new(broker);\n\n    // Subscribe first\n    let mut sub = client.subscribe(\"test\", \"ns\", \"stream\").await.unwrap();\n\n    // Publish\n    client.publish(\"test\", \"ns\", \"stream\", b\"hello\").await.unwrap();\n\n    // Receive\n    let event = sub.next().await.unwrap();\n    assert_eq!(event.payload, b\"hello\");\n}\n</code></pre>"},{"location":"api/client-sdk/#integration-tests","title":"Integration Tests","text":"<pre><code>#[tokio::test]\nasync fn test_cache_ttl() {\n    let client = Client::connect(\"https://localhost:5000\", Default::default())\n        .await\n        .unwrap();\n\n    // Store with 100ms TTL\n    client.cache_put(\"test\", \"key\", b\"value\", Some(100)).await.unwrap();\n\n    // Immediately readable\n    assert_eq!(\n        client.cache_get(\"test\", \"key\").await.unwrap(),\n        Some(b\"value\".to_vec())\n    );\n\n    // Wait for expiration\n    tokio::time::sleep(Duration::from_millis(150)).await;\n\n    // Should be expired\n    assert_eq!(client.cache_get(\"test\", \"key\").await.unwrap(), None);\n}\n</code></pre>"},{"location":"api/client-sdk/#performance-tips","title":"Performance Tips","text":"<ol> <li>Use binary mode for payloads &gt; 512 bytes</li> <li>Batch publishes when latency permits (10-100x improvement)</li> <li>Pool connections appropriately for your workload</li> <li>Pipeline cache requests to amortize round-trip latency</li> <li>Don't block subscription loops with slow processing</li> <li>Size buffers to match variance in processing latency</li> <li>Enable telemetry only for debugging, not production</li> <li>Reuse clients across requests (connection pools are expensive to create)</li> </ol>"},{"location":"api/client-sdk/#api-reference-summary","title":"API Reference Summary","text":"Operation Method Use Case Single publish <code>publish()</code> Low-rate events Batch publish <code>publish_batch()</code> High-throughput Subscribe <code>subscribe()</code> Event consumption Cache put <code>cache_put()</code> Store with TTL Cache get <code>cache_get()</code> Retrieve value Publisher <code>create_publisher()</code> Streaming publish In-process <code>InProcessClient::new()</code> Testing, embedded <p>For complete API documentation, see the rustdoc.</p>"},{"location":"api/control-plane-api/","title":"Control Plane API","text":"<p>The Felix control plane manages cluster metadata, stream definitions, shard placement, and node membership. This document describes the control plane architecture, APIs, and operational patterns.</p> <p>Current Status</p> <p>The control plane is planned but not yet implemented in the MVP. This document describes the intended design and API surface. MVP brokers run standalone without control plane coordination.</p>"},{"location":"api/control-plane-api/#architecture-overview","title":"Architecture Overview","text":"<p>The control plane is a separate service that provides strongly consistent metadata management using RAFT consensus.</p> <pre><code>graph TB\n    subgraph CP[\"Control Plane (RAFT Cluster)\"]\n        CP1[\"controlplane-0&lt;br/&gt;(Leader)\"]\n        CP2[\"controlplane-1&lt;br/&gt;(Follower)\"]\n        CP3[\"controlplane-2&lt;br/&gt;(Follower)\"]\n\n        CP1 &lt;--&gt;|RAFT| CP2\n        CP2 &lt;--&gt;|RAFT| CP3\n        CP1 &lt;--&gt;|RAFT| CP3\n    end\n\n    subgraph Brokers[\"Broker Data Plane\"]\n        B1[Broker 1]\n        B2[Broker 2]\n        B3[Broker 3]\n    end\n\n    subgraph Clients[\"Administrative Clients\"]\n        Admin[Admin CLI]\n        Ops[Ops Dashboard]\n    end\n\n    CP1 --&gt;|metadata sync| Brokers\n    Clients --&gt;|Admin API| CP1\n\n    style CP1 fill:#ffeb3b\n    style CP2 fill:#e3f2fd\n    style CP3 fill:#e3f2fd\n    style Brokers fill:#c8e6c9</code></pre>"},{"location":"api/control-plane-api/#design-goals","title":"Design Goals","text":"<ol> <li>Strong consistency: Metadata changes are linearizable</li> <li>Off the hot path: Data plane never waits for control plane</li> <li>Simple propagation: Brokers consume metadata, don't participate in consensus</li> <li>Fast recovery: Snapshot-based catch-up for new/restarted brokers</li> <li>Kubernetes-native: Leverages K8s for node identity and discovery</li> </ol>"},{"location":"api/control-plane-api/#raft-scope","title":"RAFT Scope","text":"<p>The RAFT log stores: - Node membership: Broker registration and health status - Stream definitions: Tenant, namespace, stream, retention policies - Shard placement: Which broker owns which shards - Configuration: Cluster-wide settings and feature flags - ACLs: Authorization policies (future) - Quotas: Rate limits and resource quotas (future)</p> <p>The RAFT log does not store: - Stream payloads (handled by data plane) - Cache entries (ephemeral, local to brokers) - Client connections (transient state)</p>"},{"location":"api/control-plane-api/#core-data-model","title":"Core Data Model","text":""},{"location":"api/control-plane-api/#tenant","title":"Tenant","text":"<pre><code>apiVersion: felix.io/v1\nkind: Tenant\nmetadata:\n  name: acme-corp\nspec:\n  description: \"ACME Corporation production tenant\"\n  quotas:\n    max_streams: 1000\n    max_publish_rate: 100000  # msg/sec\n    max_storage: 1TB\n  encryption:\n    key_id: \"tenant-key-acme-v1\"\n    rotation_period: 90d\n</code></pre>"},{"location":"api/control-plane-api/#namespace","title":"Namespace","text":"<pre><code>apiVersion: felix.io/v1\nkind: Namespace\nmetadata:\n  name: production\n  tenant: acme-corp\nspec:\n  description: \"Production environment\"\n  quotas:\n    max_streams: 500\n    max_publish_rate: 50000\n</code></pre>"},{"location":"api/control-plane-api/#stream","title":"Stream","text":"<pre><code>apiVersion: felix.io/v1\nkind: Stream\nmetadata:\n  name: orders\n  namespace: production\n  tenant: acme-corp\nspec:\n  shards: 4\n  retention:\n    time: 7d\n    size: 100GB\n  durability: durable  # or ephemeral\n  replication_factor: 3\n  ack_policy: quorum  # or leader_only\n</code></pre>"},{"location":"api/control-plane-api/#shard-placement","title":"Shard Placement","text":"<pre><code>apiVersion: felix.io/v1\nkind: ShardPlacement\nmetadata:\n  stream: orders\n  namespace: production\n  tenant: acme-corp\nspec:\n  placements:\n    - shard_id: 0\n      leader: broker-1\n      replicas: [broker-2, broker-3]\n    - shard_id: 1\n      leader: broker-2\n      replicas: [broker-3, broker-1]\n    - shard_id: 2\n      leader: broker-3\n      replicas: [broker-1, broker-2]\n    - shard_id: 3\n      leader: broker-1\n      replicas: [broker-2, broker-3]\n</code></pre>"},{"location":"api/control-plane-api/#broker-registration","title":"Broker Registration","text":"<pre><code>apiVersion: felix.io/v1\nkind: Broker\nmetadata:\n  name: broker-1\nspec:\n  address: \"broker-1.felix.svc.cluster.local:5000\"\n  region: us-west-2\n  availability_zone: us-west-2a\n  capacity:\n    max_shards: 100\n    max_connections: 10000\n  status: active  # active, draining, down\n</code></pre>"},{"location":"api/control-plane-api/#admin-api","title":"Admin API","text":"<p>The control plane exposes a gRPC API for administrative operations.</p>"},{"location":"api/control-plane-api/#stream-management","title":"Stream Management","text":""},{"location":"api/control-plane-api/#createstream","title":"CreateStream","text":"<p>Create a new stream.</p> <p>Request:</p> <pre><code>message CreateStreamRequest {\n  string tenant_id = 1;\n  string namespace = 2;\n  string stream = 3;\n  StreamSpec spec = 4;\n}\n\nmessage StreamSpec {\n  uint32 shards = 1;\n  RetentionPolicy retention = 2;\n  Durability durability = 3;\n  uint32 replication_factor = 4;\n  AckPolicy ack_policy = 5;\n}\n</code></pre> <p>Response:</p> <pre><code>message CreateStreamResponse {\n  string stream_id = 1;\n  StreamStatus status = 2;\n}\n</code></pre> <p>Example (conceptual CLI):</p> <pre><code>felix-admin stream create \\\n  --tenant acme-corp \\\n  --namespace production \\\n  --stream orders \\\n  --shards 4 \\\n  --retention 7d \\\n  --durability durable \\\n  --replication 3\n</code></pre>"},{"location":"api/control-plane-api/#deletestream","title":"DeleteStream","text":"<p>Delete a stream and all its data.</p> <p>Request:</p> <pre><code>message DeleteStreamRequest {\n  string tenant_id = 1;\n  string namespace = 2;\n  string stream = 3;\n  bool force = 4;  // Skip safety checks\n}\n</code></pre> <p>Safety checks: - Stream has no active subscribers (unless force=true) - Confirm deletion of durable data - Grace period for accidental deletions</p>"},{"location":"api/control-plane-api/#liststreams","title":"ListStreams","text":"<p>List streams in a namespace.</p> <p>Request:</p> <pre><code>message ListStreamsRequest {\n  string tenant_id = 1;\n  string namespace = 2;\n  string filter = 3;  // Optional name filter\n  uint32 page_size = 4;\n  string page_token = 5;\n}\n</code></pre> <p>Response:</p> <pre><code>message ListStreamsResponse {\n  repeated StreamInfo streams = 1;\n  string next_page_token = 2;\n}\n\nmessage StreamInfo {\n  string name = 1;\n  StreamSpec spec = 2;\n  StreamMetrics metrics = 3;\n}\n</code></pre>"},{"location":"api/control-plane-api/#shard-management","title":"Shard Management","text":""},{"location":"api/control-plane-api/#rebalanceshards","title":"RebalanceShards","text":"<p>Trigger shard rebalancing across brokers.</p> <p>Request:</p> <pre><code>message RebalanceShardsRequest {\n  string tenant_id = 1;\n  string namespace = 2;\n  string stream = 3;\n  RebalanceStrategy strategy = 4;\n}\n\nenum RebalanceStrategy {\n  BALANCED = 0;      // Even distribution\n  MINIMIZE_MOVEMENT = 1;  // Least disruption\n  LOCALITY_AWARE = 2;     // Optimize for region/AZ\n}\n</code></pre> <p>Response:</p> <pre><code>message RebalanceShardsResponse {\n  repeated ShardMove moves = 1;\n  RebalanceStatus status = 2;\n}\n\nmessage ShardMove {\n  uint32 shard_id = 1;\n  string from_broker = 2;\n  string to_broker = 3;\n  MoveStatus status = 4;\n}\n</code></pre>"},{"location":"api/control-plane-api/#transfershardleadership","title":"TransferShardLeadership","text":"<p>Move shard leadership to another broker.</p> <p>Request:</p> <pre><code>message TransferShardLeadershipRequest {\n  string stream_id = 1;\n  uint32 shard_id = 2;\n  string target_broker = 3;\n}\n</code></pre> <p>Use cases: - Planned maintenance (drain broker) - Load balancing - Failure recovery</p>"},{"location":"api/control-plane-api/#broker-management","title":"Broker Management","text":""},{"location":"api/control-plane-api/#registerbroker","title":"RegisterBroker","text":"<p>Register a new broker node.</p> <p>Request:</p> <pre><code>message RegisterBrokerRequest {\n  string broker_id = 1;\n  string address = 2;\n  BrokerCapacity capacity = 3;\n  map&lt;string, string&gt; metadata = 4;\n}\n</code></pre> <p>Automatic registration:</p> <p>Brokers can auto-register on startup:</p> <pre><code># Broker startup config\nbroker_id: \"auto\"  # Generate from pod name\ncontrolplane_url: \"https://controlplane.felix.svc.cluster.local:9000\"\ncontrolplane_register_on_startup: true\n</code></pre>"},{"location":"api/control-plane-api/#reporthealth","title":"ReportHealth","text":"<p>Brokers periodically report health to control plane.</p> <p>Request:</p> <pre><code>message ReportHealthRequest {\n  string broker_id = 1;\n  HealthStatus status = 2;\n  BrokerMetrics metrics = 3;\n  repeated ShardStatus shard_status = 4;\n}\n\nmessage HealthStatus {\n  bool healthy = 1;\n  string message = 2;\n  int64 uptime_seconds = 3;\n}\n</code></pre> <p>Heartbeat interval: 5 seconds (configurable)</p> <p>Failure detection: Broker marked down after 3 missed heartbeats</p>"},{"location":"api/control-plane-api/#metadata-synchronization-api","title":"Metadata Synchronization API","text":"<p>Brokers consume metadata via watch streams.</p>"},{"location":"api/control-plane-api/#getsnapshot","title":"GetSnapshot","text":"<p>Get full metadata snapshot at a specific version.</p> <p>Request:</p> <pre><code>message GetSnapshotRequest {\n  uint64 version = 1;  // 0 = latest\n}\n</code></pre> <p>Response:</p> <pre><code>message GetSnapshotResponse {\n  uint64 version = 1;\n  Metadata metadata = 2;\n}\n\nmessage Metadata {\n  repeated Tenant tenants = 1;\n  repeated Namespace namespaces = 2;\n  repeated Stream streams = 3;\n  repeated ShardPlacement placements = 4;\n  repeated Broker brokers = 5;\n}\n</code></pre> <p>Usage:</p> <pre><code>// Broker startup: load full metadata snapshot\nlet snapshot = controlplane.get_snapshot(0).await?;\nbroker.apply_metadata(snapshot.metadata).await?;\n</code></pre>"},{"location":"api/control-plane-api/#watchupdates","title":"WatchUpdates","text":"<p>Stream incremental metadata updates.</p> <p>Request:</p> <pre><code>message WatchUpdatesRequest {\n  uint64 from_version = 1;\n}\n</code></pre> <p>Response stream:</p> <pre><code>message MetadataUpdate {\n  uint64 version = 1;\n  UpdateType type = 2;\n  oneof payload {\n    Tenant tenant = 3;\n    Namespace namespace = 4;\n    Stream stream = 5;\n    ShardPlacement placement = 6;\n    Broker broker = 7;\n  }\n}\n\nenum UpdateType {\n  CREATE = 0;\n  UPDATE = 1;\n  DELETE = 2;\n}\n</code></pre> <p>Usage:</p> <pre><code>// Broker: watch for metadata changes\nlet mut watch = controlplane.watch_updates(current_version).await?;\n\nwhile let Some(update) = watch.next().await {\n    match update.type {\n        UpdateType::CREATE =&gt; broker.apply_create(update).await?,\n        UpdateType::UPDATE =&gt; broker.apply_update(update).await?,\n        UpdateType::DELETE =&gt; broker.apply_delete(update).await?,\n    }\n    broker.set_metadata_version(update.version);\n}\n</code></pre>"},{"location":"api/control-plane-api/#broker-watch-lifecycle","title":"Broker Watch Lifecycle","text":"<pre><code>sequenceDiagram\n    participant B as Broker\n    participant CP as Control Plane\n\n    Note over B: Broker starts up\n    B-&gt;&gt;CP: GetSnapshot(version=0)\n    CP--&gt;&gt;B: Snapshot at version 42\n\n    Note over B: Apply snapshot\n    B-&gt;&gt;B: current_version = 42\n\n    B-&gt;&gt;CP: WatchUpdates(from_version=42)\n    Note over CP: Long-lived stream\n\n    loop Metadata changes\n        Note over CP: Stream CREATE at v43\n        CP-&gt;&gt;B: Update (version=43)\n        B-&gt;&gt;B: Apply update, current_version=43\n\n        Note over CP: Placement UPDATE at v44\n        CP-&gt;&gt;B: Update (version=44)\n        B-&gt;&gt;B: Apply update, current_version=44\n    end\n\n    Note over B,CP: Connection lost\n    Note over B: Reconnect\n    B-&gt;&gt;CP: WatchUpdates(from_version=44)\n    CP-&gt;&gt;B: Resume from v44</code></pre>"},{"location":"api/control-plane-api/#consistency-guarantees","title":"Consistency Guarantees","text":""},{"location":"api/control-plane-api/#linearizable-reads-and-writes","title":"Linearizable Reads and Writes","text":"<p>All control plane operations are linearizable:</p> <ul> <li>Writes: Only the RAFT leader accepts writes</li> <li>Reads: Leader reads are linearizable</li> <li>Follower reads: Stale by up to heartbeat interval (optional)</li> </ul>"},{"location":"api/control-plane-api/#broker-metadata-consistency","title":"Broker Metadata Consistency","text":"<p>Brokers operate with eventually consistent metadata:</p> <ul> <li>Brokers cache metadata locally</li> <li>Updates arrive via watch stream</li> <li>Lag is typically &lt; 100ms</li> <li>New streams may not be immediately available</li> </ul> <p>Staleness handling:</p> <pre><code>// Broker rejects operations for unknown streams\nmatch broker.lookup_stream(tenant, namespace, stream) {\n    Some(stream_info) =&gt; {\n        // Process operation\n    }\n    None =&gt; {\n        // Return error: \"Unknown stream\"\n        // Client should retry after brief delay\n    }\n}\n</code></pre>"},{"location":"api/control-plane-api/#failure-scenarios","title":"Failure Scenarios","text":""},{"location":"api/control-plane-api/#control-plane-leader-failure","title":"Control Plane Leader Failure","text":"<pre><code>sequenceDiagram\n    participant B as Broker\n    participant CP1 as CP Leader\n    participant CP2 as CP Follower\n\n    B-&gt;&gt;CP1: WatchUpdates\n    CP1-&gt;&gt;B: Updates stream\n\n    Note over CP1: Leader crashes\n    Note over B: Detect connection loss\n\n    Note over CP2: RAFT elects new leader\n\n    B-&gt;&gt;CP2: WatchUpdates(from_version=N)\n    CP2-&gt;&gt;B: Resume updates</code></pre> <p>Recovery time: &lt; 5 seconds (RAFT election + reconnect)</p> <p>Impact: No data plane disruption, admin API briefly unavailable</p>"},{"location":"api/control-plane-api/#broker-disconnection-from-control-plane","title":"Broker Disconnection from Control Plane","text":"<p>Broker continues operating with cached metadata:</p> <ul> <li>Existing streams continue serving</li> <li>New stream creation fails</li> <li>Shard placement updates delayed</li> <li>Broker reconciles on reconnection</li> </ul> <p>Acceptable downtime: Hours (for stable environments)</p>"},{"location":"api/control-plane-api/#control-plane-quorum-loss","title":"Control Plane Quorum Loss","text":"<p>If RAFT loses quorum (majority of nodes down):</p> <ul> <li>Read operations: Fail (no leader)</li> <li>Write operations: Fail (no quorum)</li> <li>Broker data plane: Continues operating normally</li> <li>Admin operations: Unavailable until quorum restored</li> </ul> <p>Prevention: Deploy 3 or 5 control plane nodes across availability zones</p>"},{"location":"api/control-plane-api/#planned-features","title":"Planned Features","text":""},{"location":"api/control-plane-api/#acl-management","title":"ACL Management","text":"<pre><code>message ACL {\n  string tenant_id = 1;\n  string namespace = 2;\n  string resource = 3;  // stream name or \"*\"\n  string principal = 4;  // service account or user\n  repeated Permission permissions = 5;\n}\n\nenum Permission {\n  PUBLISH = 0;\n  SUBSCRIBE = 1;\n  CACHE_READ = 2;\n  CACHE_WRITE = 3;\n  ADMIN = 4;\n}\n</code></pre>"},{"location":"api/control-plane-api/#quota-enforcement","title":"Quota Enforcement","text":"<pre><code>message Quota {\n  string tenant_id = 1;\n  string namespace = 2;\n  QuotaLimits limits = 3;\n}\n\nmessage QuotaLimits {\n  uint64 max_publish_rate = 1;  // msg/sec\n  uint64 max_subscribe_connections = 2;\n  uint64 max_storage_bytes = 3;\n  uint64 max_cache_memory = 4;\n}\n</code></pre>"},{"location":"api/control-plane-api/#audit-logging","title":"Audit Logging","text":"<p>All control plane operations are logged:</p> <pre><code>{\n  \"timestamp\": \"2026-01-15T10:30:00Z\",\n  \"operation\": \"DeleteStream\",\n  \"principal\": \"admin@acme.com\",\n  \"tenant\": \"acme-corp\",\n  \"namespace\": \"production\",\n  \"stream\": \"old-events\",\n  \"result\": \"success\"\n}\n</code></pre>"},{"location":"api/control-plane-api/#region-and-bridge-management","title":"Region and Bridge Management","text":"<pre><code>apiVersion: felix.io/v1\nkind: Bridge\nmetadata:\n  name: us-to-eu\nspec:\n  source_region: us-west-2\n  target_region: eu-central-1\n  streams:\n    - tenant: acme-corp\n      namespace: production\n      stream: replicated-events\n  encryption:\n    key_id: \"bridge-key-us-eu-v1\"\n</code></pre>"},{"location":"api/control-plane-api/#deployment-considerations","title":"Deployment Considerations","text":""},{"location":"api/control-plane-api/#kubernetes-statefulset","title":"Kubernetes StatefulSet","text":"<pre><code>apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: felix-controlplane\nspec:\n  replicas: 3\n  serviceName: felix-controlplane\n  template:\n    spec:\n      containers:\n      - name: controlplane\n        image: felix/controlplane:latest\n        volumeMounts:\n        - name: data\n          mountPath: /var/lib/felix/raft\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n    spec:\n      accessModes: [\"ReadWriteOnce\"]\n      resources:\n        requests:\n          storage: 10Gi\n</code></pre>"},{"location":"api/control-plane-api/#anti-affinity","title":"Anti-Affinity","text":"<p>Spread control plane pods across nodes/AZs:</p> <pre><code>affinity:\n  podAntiAffinity:\n    requiredDuringSchedulingIgnoredDuringExecution:\n    - labelSelector:\n        matchLabels:\n          app: felix-controlplane\n      topologyKey: kubernetes.io/hostname\n</code></pre>"},{"location":"api/control-plane-api/#resource-requirements","title":"Resource Requirements","text":"<p>Minimum: - CPU: 1 core - Memory: 2 GB - Disk: 10 GB SSD</p> <p>Recommended production: - CPU: 2-4 cores - Memory: 4-8 GB - Disk: 50 GB SSD with high IOPS</p>"},{"location":"api/control-plane-api/#monitoring","title":"Monitoring","text":"<p>Key metrics to monitor:</p> <ul> <li>RAFT leadership changes</li> <li>Commit latency</li> <li>Snapshot size and frequency</li> <li>Broker metadata sync lag</li> <li>Admin API request rate and latency</li> </ul>"},{"location":"api/control-plane-api/#best-practices","title":"Best Practices","text":"<ol> <li>Run 3 or 5 replicas: Odd numbers for quorum</li> <li>Use persistent volumes: Avoid data loss on pod restart</li> <li>Enable pod disruption budgets: Maintain quorum during upgrades</li> <li>Monitor RAFT health: Alert on leadership instability</li> <li>Automate backups: Snapshot RAFT state periodically</li> <li>Test failover: Practice control plane recovery procedures</li> <li>Separate from data plane: Don't co-locate with broker pods</li> <li>Use dedicated networking: Avoid noisy neighbors affecting consensus</li> </ol> <p>Control Plane Sizing</p> <p>Control plane workload is metadata-only. A 3-node cluster can manage 10,000+ streams and 100+ brokers without issue. Scale vertically (larger nodes) before scaling horizontally.</p>"},{"location":"architecture/components/","title":"Component Architecture","text":"<p>Felix is built as a modular, composable system with clear separation of concerns. Each component is designed to be independently testable, observable, and evolvable. This document provides a deep dive into each major component of the Felix architecture.</p>"},{"location":"architecture/components/#overview","title":"Overview","text":"<p>The Felix system is composed of six core components that work together to deliver low-latency pub/sub and caching capabilities:</p> <pre><code>graph TB\n    Client[felix-client]\n    Wire[felix-wire]\n    Transport[felix-transport]\n    Broker[felix-broker]\n    Storage[felix-storage]\n    CP[Control Plane]\n\n    Client --&gt;|uses| Wire\n    Client --&gt;|uses| Transport\n    Transport --&gt;|QUIC| Broker\n    Broker --&gt;|stores| Storage\n    Broker --&gt;|syncs| CP\n\n    style Client fill:#e1f5fe\n    style Broker fill:#fff3e0\n    style Storage fill:#f3e5f5\n    style CP fill:#e8f5e9</code></pre>"},{"location":"architecture/components/#felix-wire-protocol-layer","title":"felix-wire: Protocol Layer","text":"<p>The <code>felix-wire</code> crate defines the language-neutral wire protocol that all Felix clients and brokers must implement. It provides the foundation for interoperability and forward compatibility.</p>"},{"location":"architecture/components/#responsibilities","title":"Responsibilities","text":"<ul> <li>Frame encoding/decoding: Fixed header format with magic number, version, flags, and length</li> <li>Message serialization: JSON-based message payload with type discriminators</li> <li>Binary optimizations: Binary batch encoding for high-throughput publish operations</li> <li>Protocol versioning: Version negotiation and forward compatibility</li> <li>Conformance testing: Test vectors for validating implementations</li> </ul>"},{"location":"architecture/components/#frame-structure","title":"Frame Structure","text":"<p>Every Felix message is wrapped in a fixed 12-byte header:</p> <pre><code> 0                   1                   2                   3\n 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            magic              \u2502    version    \u2502     flags     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                           length                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <ul> <li>Magic: <code>0x464C5831</code> (\"FLX1\") for protocol identification</li> <li>Version: Protocol version (currently 1)</li> <li>Flags: Feature flags for compression, encryption, binary encoding</li> <li>Length: Payload size in bytes (up to 4 GB)</li> </ul>"},{"location":"architecture/components/#design-decisions","title":"Design Decisions","text":"<p>The wire protocol deliberately uses JSON for v1 messages to prioritize:</p> <ol> <li>Debuggability: Human-readable messages during development</li> <li>Ecosystem compatibility: Easy to implement in any language</li> <li>Schema evolution: Flexible field additions without breaking changes</li> <li>Binary escape hatch: Binary batch mode available when throughput matters</li> </ol> <p>Binary Mode Performance</p> <p>Binary publish batches eliminate JSON parsing overhead and can achieve 30-40% higher throughput for large batches. They're automatically used for high-throughput workloads when <code>event_single_binary_enabled</code> is configured.</p>"},{"location":"architecture/components/#felix-transport-quic-abstraction","title":"felix-transport: QUIC Abstraction","text":"<p>The transport layer provides a clean abstraction over QUIC, hiding the complexity of connection management, stream lifecycle, and flow control while exposing Felix-specific semantics.</p>"},{"location":"architecture/components/#core-abstractions","title":"Core Abstractions","text":""},{"location":"architecture/components/#connection-pooling","title":"Connection Pooling","text":"<p>Felix maintains pools of QUIC connections to achieve parallelism without contention:</p> <pre><code>// Simplified conceptual API\npub struct ConnectionPool {\n    endpoints: Vec&lt;Endpoint&gt;,\n    next_index: AtomicUsize,\n}\n\nimpl ConnectionPool {\n    pub async fn acquire(&amp;self) -&gt; Connection;\n    pub fn round_robin_next(&amp;self) -&gt; &amp;Endpoint;\n}\n</code></pre> <p>Connection pools are configured separately for different workload types: - Event connections: For pub/sub control streams and subscriptions - Cache connections: For cache request/response operations - Publish connections: For publishing operations</p>"},{"location":"architecture/components/#stream-management","title":"Stream Management","text":"<p>QUIC supports two stream types, each serving specific purposes in Felix:</p> <p>Bidirectional Streams: - Control plane operations (publish, subscribe, cache requests) - Request/response patterns - Multiplexed cache operations over pooled streams</p> <p>Unidirectional Streams: - Event delivery (broker \u2192 subscriber) - One stream per subscription for isolation - Enables independent flow control per subscriber</p>"},{"location":"architecture/components/#flow-control-architecture","title":"Flow Control Architecture","text":"<p>Felix leverages QUIC's built-in flow control at multiple levels:</p> <pre><code>graph TB\n    subgraph \"QUIC Flow Control Layers\"\n        Connection[Connection Window]\n        Stream[Stream Window]\n        Data[Application Data]\n    end\n\n    Connection --&gt;|credits| Stream\n    Stream --&gt;|credits| Data\n\n    style Connection fill:#ffebee\n    style Stream fill:#fff3e0\n    style Data fill:#e8f5e9</code></pre> <p>Configuration Parameters:</p> <ul> <li><code>FELIX_EVENT_CONN_RECV_WINDOW</code>: Per-connection receive window (default: 256 MiB)</li> <li><code>FELIX_EVENT_STREAM_RECV_WINDOW</code>: Per-stream receive window (default: 64 MiB)</li> <li><code>FELIX_EVENT_SEND_WINDOW</code>: Per-connection send window (default: 256 MiB)</li> </ul> <p>Memory Implications</p> <p>Window sizes multiply with pool sizes. An event connection pool of 8 with 256 MiB windows can commit up to 2 GiB of receive buffers under burst load. Tune carefully for your workload.</p>"},{"location":"architecture/components/#tls-and-security","title":"TLS and Security","text":"<p>The transport layer enforces encryption by default:</p> <ul> <li>TLS 1.3 for all connections</li> <li>mTLS for broker-to-broker communication (future)</li> <li>Certificate validation with configurable policies</li> <li>Cipher suite configuration for compliance requirements</li> </ul>"},{"location":"architecture/components/#felix-broker-core-logic","title":"felix-broker: Core Logic","text":"<p>The broker is the heart of Felix, implementing pub/sub fanout, cache operations, stream routing, and backpressure management.</p>"},{"location":"architecture/components/#architecture-layers","title":"Architecture Layers","text":"<pre><code>graph TB\n    subgraph Broker[\"felix-broker\"]\n        Ingress[Stream Router]\n        Publish[Publish Pipeline]\n        Subscribe[Subscription Registry]\n        Cache[Cache Engine]\n        Fanout[Fanout Coordinator]\n    end\n\n    Ingress --&gt; Publish\n    Ingress --&gt; Subscribe\n    Ingress --&gt; Cache\n    Publish --&gt; Fanout\n    Fanout --&gt; Subscribe\n\n    style Ingress fill:#e3f2fd\n    style Publish fill:#fff9c4\n    style Subscribe fill:#f3e5f5\n    style Cache fill:#e0f2f1\n    style Fanout fill:#fce4ec</code></pre>"},{"location":"architecture/components/#stream-routing","title":"Stream Routing","text":"<p>When a client opens a stream to the broker, the first message determines stream behavior:</p> <ol> <li>Control stream (bidirectional): Publish, subscribe setup, acknowledgements</li> <li>Event stream (unidirectional): Server-opened for event delivery</li> <li>Cache stream (bidirectional): Cache request/response multiplexing</li> </ol>"},{"location":"architecture/components/#publish-pipeline","title":"Publish Pipeline","text":"<p>The publish pipeline is optimized for both latency and throughput:</p> <p>Stages:</p> <ol> <li>Ingestion: Receive publish frame from client stream</li> <li>Validation: Check tenant/namespace/stream authorization</li> <li>Queueing: Enqueue to bounded publish queue</li> <li>Worker processing: Parallel workers dequeue and prepare for fanout</li> <li>Fanout: Distribute to all active subscribers</li> </ol> <p>Configuration:</p> <pre><code>pub_workers_per_conn: 4      # Worker parallelism per connection\npub_queue_depth: 1024         # Bounded queue size\npublish_chunk_bytes: 16384    # Chunking for large payloads\n</code></pre> <p>Worker Sizing</p> <p>Set <code>pub_workers_per_conn</code> to match your active publish stream count. Excess workers increase contention without improving throughput. For single-stream publishers, use 1-2 workers.</p>"},{"location":"architecture/components/#subscription-management","title":"Subscription Management","text":"<p>Each subscription maintains isolated state:</p> <pre><code>pub struct Subscription {\n    subscription_id: String,\n    tenant_id: String,\n    namespace: String,\n    stream: String,\n    event_stream: UnidirectionalStream,\n    buffer: BoundedQueue&lt;Event&gt;,\n}\n</code></pre> <p>Isolation guarantees:</p> <ul> <li>Slow subscribers never block fast subscribers</li> <li>Per-subscription buffering with configurable depth</li> <li>Independent flow control per subscription stream</li> <li>Lag detection and optional subscriber backpressure</li> </ul>"},{"location":"architecture/components/#fanout-architecture","title":"Fanout Architecture","text":"<p>When a message is published, the broker fans it out to all subscribers:</p> <pre><code>sequenceDiagram\n    participant P as Publisher\n    participant B as Broker Queue\n    participant W as Worker\n    participant S1 as Subscriber 1\n    participant S2 as Subscriber 2\n    participant S3 as Subscriber 3\n\n    P-&gt;&gt;B: publish_batch\n    B-&gt;&gt;W: dequeue\n    W-&gt;&gt;W: prepare event frames\n    par Parallel Fanout\n        W-&gt;&gt;S1: event batch\n    and\n        W-&gt;&gt;S2: event batch\n    and\n        W-&gt;&gt;S3: event batch\n    end</code></pre> <p>Batching behavior:</p> <ul> <li>Events are accumulated up to <code>event_batch_max_events</code> (default: 64)</li> <li>Or until <code>event_batch_max_delay_us</code> elapses (default: 250 \u00b5s)</li> <li>Or until <code>event_batch_max_bytes</code> is reached (default: 256 KB)</li> </ul>"},{"location":"architecture/components/#cache-engine","title":"Cache Engine","text":"<p>The cache provides low-latency key-value operations with TTL:</p> <p>Operations: - <code>cache_put(key, value, ttl_ms)</code>: Store with optional expiration - <code>cache_get(key)</code>: Retrieve value or null if missing/expired - <code>cache_delete(key)</code>: Explicit deletion (future)</p> <p>Implementation characteristics:</p> <ul> <li>In-memory hash map with TTL tracking</li> <li>Lazy expiration on access</li> <li>Scoped to <code>(tenant_id, namespace, cache_name, key)</code></li> <li>No persistence in MVP (ephemeral)</li> <li>Best-effort eviction under memory pressure</li> </ul> <p>Performance profile (localhost, concurrency=32):</p> Payload Size put p50 get_hit p50 get_miss p50 0 B 158 \u00b5s 164 \u00b5s 162 \u00b5s 256 B 179 \u00b5s 177 \u00b5s 165 \u00b5s 4096 B 260 \u00b5s 238 \u00b5s 165 \u00b5s"},{"location":"architecture/components/#felix-storage-storage-abstraction","title":"felix-storage: Storage Abstraction","text":"<p>The storage layer provides pluggable backends for different durability and performance requirements.</p>"},{"location":"architecture/components/#storage-modes","title":"Storage Modes","text":""},{"location":"architecture/components/#ephemeral-storage-current","title":"Ephemeral Storage (Current)","text":"<p>Fully in-memory storage optimized for latency:</p> <ul> <li>Ring buffers for stream data</li> <li>Hash maps for cache entries</li> <li>TTL indexes for expiration</li> <li>No disk I/O on hot path</li> <li>At-most-once delivery semantics</li> </ul> <p>Use cases: real-time signals, transient caching, development</p>"},{"location":"architecture/components/#durable-storage-planned","title":"Durable Storage (Planned)","text":"<p>Persistent storage with configurable durability:</p> <ul> <li>Write-ahead log (WAL) for crash recovery</li> <li>Segmented log files for efficient compaction</li> <li>Sparse indexes for offset lookups</li> <li>Configurable fsync policies</li> <li>At-least-once delivery semantics</li> </ul>"},{"location":"architecture/components/#retention-policies","title":"Retention Policies","text":"<p>Retention is enforced per stream:</p> <pre><code>streams:\n  - name: metrics\n    retention:\n      time: 24h\n      size: 100GB\n\n  - name: events\n    retention:\n      time: 7d\n      size: 1TB\n</code></pre>"},{"location":"architecture/components/#control-plane-metadata-management","title":"Control Plane: Metadata Management","text":"<p>The control plane is a separate service (planned) that manages cluster metadata and configuration.</p>"},{"location":"architecture/components/#metadata-scope","title":"Metadata Scope","text":"<p>The control plane stores authoritative information about:</p> <ul> <li>Stream definitions: Tenant, namespace, stream names, retention policies</li> <li>Shard placement: Which brokers own which shards</li> <li>Node membership: Broker health and availability</li> <li>Configuration: Cluster-wide settings and feature flags</li> <li>Bridges: Cross-region replication configuration</li> </ul>"},{"location":"architecture/components/#consistency-model","title":"Consistency Model","text":"<p>Metadata uses strong consistency via RAFT:</p> <ul> <li>Single leader accepts all metadata writes</li> <li>Quorum replication for durability</li> <li>Linearizable reads from leader</li> <li>Follower reads for stale-ok queries</li> </ul>"},{"location":"architecture/components/#broker-synchronization","title":"Broker Synchronization","text":"<p>Brokers are not part of the RAFT cluster. They consume metadata via:</p> <pre><code>sequenceDiagram\n    participant B as Broker\n    participant CP as Control Plane\n\n    B-&gt;&gt;CP: WatchUpdates(from_version)\n    CP--&gt;&gt;B: Stream of incremental updates\n\n    Note over B: Apply updates locally\n    Note over B: Update routing tables\n    Note over B: Start/stop shard ownership\n\n    B-&gt;&gt;CP: WatchUpdates(new_version)\n    CP--&gt;&gt;B: Stream continues...</code></pre> <p>API operations:</p> <ul> <li><code>GetSnapshot()</code>: Full metadata snapshot with version</li> <li><code>WatchUpdates(from_version)</code>: Long-poll stream of changes</li> <li><code>ReportHealth(node_id, status)</code>: Liveness signaling</li> </ul>"},{"location":"architecture/components/#failure-handling","title":"Failure Handling","text":"<p>When the control plane leader fails:</p> <ol> <li>RAFT elects a new leader (typically &lt; 1 second)</li> <li>Brokers detect disconnection and reconnect</li> <li>Brokers resume watching from last known version</li> <li>No data-plane disruption during control plane failover</li> </ol> <p>Data Plane Independence</p> <p>Brokers cache all necessary metadata to continue serving reads and writes during control plane unavailability. Only administrative operations and new stream creation are affected.</p>"},{"location":"architecture/components/#component-interactions","title":"Component Interactions","text":""},{"location":"architecture/components/#end-to-end-publish-flow","title":"End-to-End Publish Flow","text":"<pre><code>sequenceDiagram\n    participant C as felix-client\n    participant W as felix-wire\n    participant T as felix-transport\n    participant B as felix-broker\n    participant S as felix-storage\n\n    C-&gt;&gt;W: Encode publish_batch\n    W-&gt;&gt;T: Send frame on QUIC stream\n    T-&gt;&gt;B: Deliver to control stream handler\n    B-&gt;&gt;B: Validate &amp; enqueue\n    B-&gt;&gt;B: Worker dequeues\n    B-&gt;&gt;S: Write to stream (if durable)\n    B-&gt;&gt;B: Fan out to subscribers\n    B-&gt;&gt;T: Send ack on control stream\n    T-&gt;&gt;W: Receive ack frame\n    W-&gt;&gt;C: Decode ack</code></pre>"},{"location":"architecture/components/#end-to-end-cache-flow","title":"End-to-End Cache Flow","text":"<pre><code>sequenceDiagram\n    participant C as felix-client\n    participant W as felix-wire\n    participant T as felix-transport\n    participant B as felix-broker\n    participant S as felix-storage\n\n    C-&gt;&gt;W: Encode cache_get with request_id\n    W-&gt;&gt;T: Send frame on cache stream\n    T-&gt;&gt;B: Deliver to cache handler\n    B-&gt;&gt;S: Lookup key in cache map\n    S--&gt;&gt;B: Return value or null\n    B-&gt;&gt;T: Send cache_value on same stream\n    T-&gt;&gt;W: Receive response frame\n    W-&gt;&gt;C: Decode cache_value</code></pre>"},{"location":"architecture/components/#component-configuration","title":"Component Configuration","text":"<p>Each component exposes its own configuration surface:</p> Component Configuration Scope felix-wire Protocol version, frame limits, binary mode thresholds felix-transport Connection pools, window sizes, TLS settings felix-broker Queue depths, worker counts, batching parameters felix-storage Retention policies, cache sizes, durability modes Control Plane RAFT tuning, snapshot intervals, health check periods <p>See the Performance Tuning guide for detailed configuration examples.</p>"},{"location":"architecture/components/#design-principles","title":"Design Principles","text":"<p>The component architecture embodies several key principles:</p> <ol> <li>Clear boundaries: Each component has a well-defined responsibility</li> <li>Testability: Components can be tested in isolation with mock implementations</li> <li>Composability: Components can be combined in different ways (in-process, networked, clustered)</li> <li>Observability: Each component exposes metrics and structured logs</li> <li>Performance: Hot paths avoid unnecessary allocations and copies</li> <li>Explicitness: Configuration is explicit, not hidden behind auto-tuning</li> </ol> <p>Understanding Performance</p> <p>When debugging performance issues, think in terms of component boundaries. Is the bottleneck in wire encoding? Transport flow control? Broker queueing? Storage I/O? Each component has different tuning knobs and scaling characteristics.</p>"},{"location":"architecture/semantics/","title":"Delivery Semantics and Consistency Model","text":"<p>Felix provides explicit, tunable delivery guarantees and consistency semantics. This document defines the behavioral contract that applications can rely on when building systems with Felix.</p>"},{"location":"architecture/semantics/#philosophy-explicit-over-implicit","title":"Philosophy: Explicit Over Implicit","text":"<p>Felix makes trade-offs explicit rather than hiding them behind ambiguous guarantees. Every semantic choice has observable behavior that can be tested and reasoned about.</p> <p>MVP Scope</p> <p>This document describes both current MVP semantics and planned future semantics. MVP limitations are clearly marked.</p>"},{"location":"architecture/semantics/#pubsub-delivery-semantics","title":"Pub/Sub Delivery Semantics","text":""},{"location":"architecture/semantics/#delivery-guarantees-mvp","title":"Delivery Guarantees (MVP)","text":"<p>Current guarantee: At-most-once</p> <p>In the MVP, Felix provides at-most-once delivery semantics for pub/sub:</p> <ul> <li>Messages are delivered to subscribers zero or one time</li> <li>No retries or redelivery</li> <li>No acknowledgements from subscribers</li> <li>Slow subscribers may drop messages without notification</li> </ul> <p>This semantic is appropriate for: - Real-time signals where latest value matters most - High-frequency metrics and telemetry - Workloads where occasional loss is acceptable - Applications that implement their own deduplication</p> <p>Message Loss Scenarios</p> <p>Messages can be lost when: - Subscriber falls behind buffer capacity - Network partition between broker and subscriber - Subscriber disconnects without draining buffer - Broker restarts (no durability in MVP)</p> <p>Example at-most-once workload:</p> <pre><code>// Real-time sensor data where latest reading matters most\nlet mut subscription = client.subscribe(\"sensors\", \"temperature\").await?;\n\nwhile let Some(event) = subscription.next().await {\n    // Process latest temperature reading\n    // If we miss a reading, the next one will arrive soon\n    update_dashboard(event.payload);\n}\n</code></pre>"},{"location":"architecture/semantics/#planned-delivery-guarantees-future","title":"Planned Delivery Guarantees (Future)","text":"<p>At-least-once delivery (planned):</p> <ul> <li>Messages delivered one or more times</li> <li>Subscriber acknowledgements required</li> <li>Broker retries unacknowledged messages</li> <li>Requires durable storage</li> <li>Applications must handle duplicates</li> </ul> <p>Exactly-once semantics (future):</p> <ul> <li>Messages delivered exactly one time (from application perspective)</li> <li>Idempotent producers with sequence numbers</li> <li>Transactional coordination</li> <li>Deduplication on receive side</li> </ul> <p>Configuration example (future):</p> <pre><code>streams:\n  - name: orders\n    delivery: at_least_once\n    retention: 7d\n\n  - name: transactions\n    delivery: exactly_once\n    retention: 30d\n</code></pre>"},{"location":"architecture/semantics/#message-ordering","title":"Message Ordering","text":"<p>Within a stream: Ordering is preserved per publisher-broker-subscriber path.</p> <pre><code>graph LR\n    P[Publisher] --&gt;|msg 1, 2, 3| B[Broker]\n    B --&gt;|msg 1, 2, 3| S[Subscriber]\n\n    style P fill:#e3f2fd\n    style B fill:#fff9c4\n    style S fill:#c8e6c9</code></pre> <p>Guarantees: - Messages from a single publisher to a stream arrive in send order - A single subscriber sees messages in the order they were enqueued - Order is preserved through batching and fanout</p> <p>Across streams: No ordering guarantees.</p> <pre><code>graph LR\n    P[Publisher]\n    P --&gt;|msg A| S1[Stream 1]\n    P --&gt;|msg B| S2[Stream 2]\n\n    Sub[Subscriber]\n    S1 --&gt; Sub\n    S2 --&gt; Sub\n\n    Note[msg A and B may arrive in any order]\n\n    style P fill:#e3f2fd\n    style Sub fill:#c8e6c9</code></pre> <p>Example:</p> <pre><code>// Publish to two streams\nclient.publish(\"events\", \"user-login\", login_event).await?;\nclient.publish(\"events\", \"audit-log\", audit_event).await?;\n\n// Subscribers to user-login and audit-log may see events in any relative order\n</code></pre> <p>Ordering within batches:</p> <pre><code>// Batch publish preserves order within the batch\nlet messages = vec![msg1, msg2, msg3];\nclient.publish_batch(\"events\", \"orders\", messages).await?;\n\n// Subscribers will see msg1, msg2, msg3 in that order\n</code></pre>"},{"location":"architecture/semantics/#fanout-fairness","title":"Fanout Fairness","text":"<p>Felix enforces subscriber isolation: slow subscribers never block fast subscribers.</p> <pre><code>graph TB\n    P[Publisher] --&gt; B[Broker]\n    B --&gt; S1[Fast Subscriber]\n    B --&gt; S2[Slow Subscriber]\n    B --&gt; S3[Fast Subscriber]\n\n    S1 --&gt;|Processing msgs 1-100| D1[Dashboard]\n    S2 --&gt;|Still on msg 23, dropping msgs| D2[Slow System]\n    S3 --&gt;|Processing msgs 1-100| D3[Analytics]\n\n    style S1 fill:#c8e6c9\n    style S2 fill:#ffccbc\n    style S3 fill:#c8e6c9</code></pre> <p>Isolation mechanism:</p> <p>Each subscription maintains an independent buffer:</p> <pre><code>pub struct Subscription {\n    buffer: BoundedQueue&lt;Event&gt;,  // Per-subscription buffer\n    event_stream: UnidirectionalStream,  // Independent QUIC stream\n}\n</code></pre> <p>Buffer behavior:</p> <ul> <li>Each subscriber has <code>event_queue_depth</code> buffer slots (default: 1024)</li> <li>When buffer fills, new events are dropped for that subscriber only</li> <li>Other subscribers continue receiving events normally</li> <li>No explicit notification of drops in MVP (future: lag metrics)</li> </ul> <p>Configuration:</p> <pre><code># Broker config\nevent_queue_depth: 1024  # Per-subscriber buffer size\n\n# Larger buffer tolerates more bursty subscribers\nevent_queue_depth: 4096  # Trade memory for burst tolerance\n</code></pre> <p>Sizing Buffer Depth</p> <p>Choose <code>event_queue_depth</code> based on: - Expected subscriber processing latency variance - Memory budget (depth \u00d7 average event size \u00d7 subscriber count) - Tolerance for temporary slowdowns</p> <p>For latency-sensitive workloads with consistent throughput: 512-1024 For bursty workloads with high fanout: 2048-4096</p>"},{"location":"architecture/semantics/#publisher-backpressure","title":"Publisher Backpressure","text":"<p>Publisher behavior: Publishing never blocks on subscriber speed.</p> <pre><code>sequenceDiagram\n    participant P as Publisher\n    participant B as Broker Queue\n    participant F as Fanout Workers\n    participant S1 as Fast Subscriber\n    participant S2 as Slow Subscriber\n\n    P-&gt;&gt;B: publish_batch\n    B--&gt;&gt;P: ack (immediate)\n    B-&gt;&gt;F: dequeue for fanout\n    par Independent fanout\n        F-&gt;&gt;S1: deliver events\n    and\n        F-&gt;&gt;S2: deliver events (buffer fills, drops)\n    end\n\n    Note over P: Publisher never waits for subscribers</code></pre> <p>Publisher queue:</p> <p>Publishers write to a bounded queue with configurable depth:</p> <pre><code>pub_queue_depth: 1024  # Bounded publish queue\npublish_queue_wait_timeout_ms: 2000  # Timeout if queue full\n</code></pre> <p>When the publish queue is full: - New publishes block up to <code>publish_queue_wait_timeout_ms</code> - After timeout, publish fails with error - This indicates broker overload (too many publishes, insufficient workers)</p> <p>Tuning publish pipeline:</p> <pre><code># Increase parallelism\npub_workers_per_conn: 4\n\n# Increase buffer (trades latency for burst tolerance)\npub_queue_depth: 2048\n\n# Faster timeout for fail-fast behavior\npublish_queue_wait_timeout_ms: 1000\n</code></pre>"},{"location":"architecture/semantics/#disconnection-behavior","title":"Disconnection Behavior","text":"<p>Subscriber disconnects:</p> <ul> <li>Subscription is immediately removed from registry</li> <li>Buffered events for that subscriber are discarded</li> <li>No redelivery when subscriber reconnects</li> <li>Subscriber must re-subscribe (starts from tail)</li> </ul> <p>Publisher disconnects:</p> <ul> <li>In-flight publishes may be lost if not acknowledged</li> <li>No automatic retry or persistence of unacked publishes</li> <li>Application must handle reconnection and retry logic</li> </ul> <p>Broker restarts:</p> <ul> <li>All in-memory state is lost (ephemeral storage in MVP)</li> <li>Active subscriptions are terminated</li> <li>Clients detect connection loss and must reconnect</li> <li>No historical replay available</li> </ul>"},{"location":"architecture/semantics/#cache-semantics","title":"Cache Semantics","text":""},{"location":"architecture/semantics/#consistency-model","title":"Consistency Model","text":"<p>Felix cache provides eventual consistency with read-your-writes for single clients:</p> <pre><code>sequenceDiagram\n    participant C1 as Client 1\n    participant B as Broker Cache\n    participant C2 as Client 2\n\n    C1-&gt;&gt;B: put(key=X, value=1)\n    B--&gt;&gt;C1: ok\n    C1-&gt;&gt;B: get(key=X)\n    B--&gt;&gt;C1: value=1\n\n    Note over C2: Concurrent get may see old value briefly\n    C2-&gt;&gt;B: get(key=X)\n    B--&gt;&gt;C2: value=1 (or old value)</code></pre> <p>Guarantees:</p> <ol> <li>Read-your-writes: Client sees its own writes immediately</li> <li>Monotonic reads: Client never sees older values after newer ones (single session)</li> <li>Eventual consistency: All clients eventually see the latest value</li> <li>No dirty reads: Clients never see partial or uncommitted writes</li> </ol> <p>Not guaranteed:</p> <ul> <li>Linearizability across clients</li> <li>Causal consistency across keys</li> <li>Multi-key transactions</li> </ul>"},{"location":"architecture/semantics/#ttl-and-expiration","title":"TTL and Expiration","text":"<p>TTL semantics:</p> <pre><code>// Store with 60-second TTL\nclient.cache_put(\"session\", session_id, session_data, Some(60_000)).await?;\n\n// Store without expiration\nclient.cache_put(\"config\", config_key, config_value, None).await?;\n</code></pre> <p>Expiration behavior:</p> <ul> <li>TTL countdown starts when <code>cache_put</code> returns <code>ok</code></li> <li>Expiration is lazy: checked on access, not proactively</li> <li>Expired entries return <code>null</code> on <code>cache_get</code></li> <li>Expired entries may occupy memory until accessed or evicted</li> </ul> <p>TTL Precision</p> <p>TTL enforcement is best-effort. Under high load, expired entries might be accessible for short periods after TTL expires. This is typically &lt; 100ms but not guaranteed.</p>"},{"location":"architecture/semantics/#cache-scoping","title":"Cache Scoping","text":"<p>Cache entries are scoped to <code>(tenant_id, namespace, cache_name, key)</code>:</p> <pre><code>// These are independent cache entries:\nclient.cache_put_scoped(\"tenant1\", \"prod\", \"sessions\", \"user123\", data).await?;\nclient.cache_put_scoped(\"tenant1\", \"staging\", \"sessions\", \"user123\", data).await?;\nclient.cache_put_scoped(\"tenant2\", \"prod\", \"sessions\", \"user123\", data).await?;\n</code></pre> <p>Isolation guarantees:</p> <ul> <li>Different tenants cannot access each other's cache entries</li> <li>Different namespaces within a tenant are isolated</li> <li>Keys are unique only within their (tenant, namespace, cache) scope</li> </ul>"},{"location":"architecture/semantics/#eviction-policy","title":"Eviction Policy","text":"<p>MVP policy: Best-effort eviction when memory pressure occurs.</p> <ul> <li>No guaranteed LRU or LFU policy</li> <li>Eviction is opportunistic</li> <li>Applications should not rely on specific eviction order</li> </ul> <p>Capacity configuration (future):</p> <pre><code>caches:\n  - tenant: tenant1\n    namespace: prod\n    cache: sessions\n    max_entries: 100000\n    max_bytes: 1GB\n    eviction_policy: lru\n</code></pre>"},{"location":"architecture/semantics/#concurrency-and-race-conditions","title":"Concurrency and Race Conditions","text":"<p>Concurrent writes to same key:</p> <pre><code>sequenceDiagram\n    participant C1 as Client 1\n    participant C2 as Client 2\n    participant B as Broker\n\n    par Concurrent puts\n        C1-&gt;&gt;B: put(key=X, value=A)\n    and\n        C2-&gt;&gt;B: put(key=X, value=B)\n    end\n\n    Note over B: Last write wins (undefined order)\n\n    C1-&gt;&gt;B: get(key=X)\n    B--&gt;&gt;C1: value=A or value=B</code></pre> <p>Behavior: Last write wins, but order is undefined for concurrent writes.</p> <p>No atomic operations in MVP:</p> <ul> <li>No compare-and-swap</li> <li>No atomic increment</li> <li>No multi-key transactions</li> </ul> <p>Planned features:</p> <ul> <li>Conditional put (if-not-exists, if-match)</li> <li>Atomic increment/decrement</li> <li>Watch/notify on key changes</li> </ul>"},{"location":"architecture/semantics/#cache-vs-pubsub-integration-future","title":"Cache vs. Pub/Sub Integration (Future)","text":"<p>Planned feature: Pub/sub invalidation for cache consistency.</p> <pre><code>// Publish invalidates cache entry\nclient.publish_with_invalidation(\"events\", \"user-updated\", event, \n    vec![\"cache:sessions:user123\"]).await?;\n\n// Subscribers and cache both receive update\n</code></pre>"},{"location":"architecture/semantics/#tenant-and-namespace-model","title":"Tenant and Namespace Model","text":""},{"location":"architecture/semantics/#existence-enforcement","title":"Existence Enforcement","text":"<p>Wire protocol requirement: All data-plane operations must specify tenant and namespace.</p> <pre><code>{\n  \"type\": \"publish\",\n  \"tenant_id\": \"acme-corp\",\n  \"namespace\": \"production\",\n  \"stream\": \"orders\",\n  \"payload\": \"...\"\n}\n</code></pre> <p>Broker validation:</p> <p>The broker enforces tenant/namespace existence:</p> <ol> <li>Broker syncs metadata from control plane</li> <li>Broker maintains local registry of valid tenant/namespace pairs</li> <li>Operations for unknown tenant/namespace are rejected with <code>error</code> response</li> </ol> <pre><code>sequenceDiagram\n    participant C as Client\n    participant B as Broker\n    participant CP as Control Plane\n\n    CP-&gt;&gt;B: Sync metadata (tenants, namespaces)\n    C-&gt;&gt;B: publish (tenant=unknown, ...)\n    B--&gt;&gt;C: error (unknown tenant)\n\n    C-&gt;&gt;B: publish (tenant=acme, namespace=prod, ...)\n    B-&gt;&gt;B: Validate against registry\n    B--&gt;&gt;C: ok</code></pre>"},{"location":"architecture/semantics/#authorization-planned","title":"Authorization (Planned)","text":"<p>Future: ACL-based authorization per tenant/namespace/stream.</p> <pre><code>acls:\n  - tenant: acme-corp\n    namespace: production\n    resource: orders\n    principal: service-account-1\n    permissions: [publish, subscribe]\n\n  - tenant: acme-corp\n    namespace: production\n    resource: analytics\n    principal: service-account-2\n    permissions: [subscribe]\n</code></pre> <p>Enforcement points: - Publish operations - Subscribe operations - Cache operations - Control plane operations</p>"},{"location":"architecture/semantics/#quota-enforcement-planned","title":"Quota Enforcement (Planned)","text":"<p>Future: Per-tenant and per-namespace quotas.</p> <pre><code>quotas:\n  - tenant: acme-corp\n    namespace: production\n    publish_rate_limit: 10000/s\n    subscribe_connections: 100\n    cache_memory: 10GB\n    stream_retention: 7d\n</code></pre>"},{"location":"architecture/semantics/#consistency-across-components","title":"Consistency Across Components","text":""},{"location":"architecture/semantics/#broker-internal-consistency","title":"Broker Internal Consistency","text":"<p>Within a single broker:</p> <ul> <li>Publish-fanout ordering: Messages fan out in publish order</li> <li>Cache consistency: Single-writer per key (no torn writes)</li> <li>Subscription isolation: Independent queues prevent crosstalk</li> </ul>"},{"location":"architecture/semantics/#multi-broker-consistency-future","title":"Multi-Broker Consistency (Future)","text":"<p>In a clustered deployment:</p> <ul> <li>Shard leadership: Only one leader per shard</li> <li>Metadata consistency: Strongly consistent via RAFT control plane</li> <li>Cross-shard ordering: Not guaranteed</li> <li>Cache consistency: Eventually consistent across brokers</li> </ul>"},{"location":"architecture/semantics/#failure-scenarios-and-behavior","title":"Failure Scenarios and Behavior","text":""},{"location":"architecture/semantics/#network-partition","title":"Network Partition","text":"<p>Publisher-Broker partition:</p> <ul> <li>Publisher detects connection loss (QUIC idle timeout)</li> <li>Unacknowledged publishes are lost</li> <li>Publisher must reconnect and retry</li> </ul> <p>Subscriber-Broker partition:</p> <ul> <li>Subscriber detects connection loss</li> <li>Buffered events are lost</li> <li>Subscriber must reconnect and re-subscribe (starts from tail)</li> </ul> <p>Broker-Control Plane partition:</p> <ul> <li>Broker continues serving with cached metadata</li> <li>New stream creation fails</li> <li>Existing streams continue operating</li> <li>Broker reconciles when connection restored</li> </ul>"},{"location":"architecture/semantics/#broker-failure","title":"Broker Failure","text":"<p>Process crash:</p> <ul> <li>All in-memory state lost (ephemeral storage in MVP)</li> <li>Clients detect connection loss</li> <li>Clients must reconnect to recovered broker</li> <li>Subscriptions must be re-established</li> </ul> <p>Planned behavior with durability:</p> <ul> <li>Durable streams can replay from last checkpoint</li> <li>Subscribers can resume from last acknowledged offset</li> <li>Cache state can be rebuilt from log</li> </ul>"},{"location":"architecture/semantics/#slow-subscriber-behavior","title":"Slow Subscriber Behavior","text":"<p>Scenario: Subscriber processing slows down.</p> <p>Stages:</p> <ol> <li>Buffer absorbs slowdown: Events accumulate in subscriber buffer</li> <li>Buffer fills: New events start getting dropped for that subscriber</li> <li>Other subscribers unaffected: Fast subscribers continue normally</li> </ol> <p>Detection (future):</p> <ul> <li>Lag metrics exposed per subscription</li> <li>Configurable alerts for subscribers falling behind</li> <li>Optional disconnect of chronically slow subscribers</li> </ul> <pre><code>// Future API\nlet lag = subscription.lag_metric().await?;\nif lag.messages_behind &gt; 1000 {\n    warn!(\"Subscription falling behind: {} messages\", lag.messages_behind);\n}\n</code></pre>"},{"location":"architecture/semantics/#testing-semantics","title":"Testing Semantics","text":""},{"location":"architecture/semantics/#conformance-testing","title":"Conformance Testing","text":"<p>Applications can test semantic guarantees:</p> <p>Ordering test:</p> <pre><code>// Publish ordered batch\nlet messages = vec![\"msg1\", \"msg2\", \"msg3\"];\nclient.publish_batch(\"test\", \"orders\", messages).await?;\n\n// Verify subscriber receives in order\nlet events = collect_events(&amp;mut subscription, 3).await?;\nassert_eq!(events, vec![\"msg1\", \"msg2\", \"msg3\"]);\n</code></pre> <p>Isolation test:</p> <pre><code>// Start fast and slow subscribers\nlet mut fast_sub = client.subscribe(\"test\", \"stream\").await?;\nlet mut slow_sub = client.subscribe(\"test\", \"stream\").await?;\n\n// Slow subscriber delays processing\nsimulate_slow_processing(&amp;mut slow_sub);\n\n// Verify fast subscriber still receives all messages\nlet fast_count = count_events(&amp;mut fast_sub, timeout).await?;\nassert!(fast_count &gt;= expected_count);\n</code></pre>"},{"location":"architecture/semantics/#summary-semantic-guarantees-matrix","title":"Summary: Semantic Guarantees Matrix","text":"Property MVP Guarantee Future Guarantee Pub/Sub delivery At-most-once At-least-once, Exactly-once Message ordering Per-stream Configurable cross-stream Subscriber isolation Yes Yes Cache consistency Read-your-writes Tunable (linearizable option) TTL precision Best-effort (~100ms) Guaranteed Durability None (ephemeral) Configurable per stream Authorization None RBAC per resource Quotas None Per-tenant, per-namespace Multi-key operations None Transactions"},{"location":"architecture/semantics/#recommendations","title":"Recommendations","text":""},{"location":"architecture/semantics/#choosing-delivery-semantics","title":"Choosing Delivery Semantics","text":"<p>Use at-most-once (current MVP) when: - Latest value is more important than history (sensor data, metrics) - Occasional loss is acceptable (telemetry, monitoring) - Throughput and latency matter more than guarantees - Application implements own deduplication</p> <p>Use at-least-once (future) when: - Every message matters (financial transactions, orders) - Application can handle duplicates (idempotent processing) - Durability matters more than latency</p> <p>Use exactly-once (future) when: - Duplicates are unacceptable (billing, accounting) - Application cannot easily deduplicate - Willing to pay latency cost for guarantees</p>"},{"location":"architecture/semantics/#cache-usage-patterns","title":"Cache Usage Patterns","text":"<p>Good cache use cases: - Session data with TTL - Configuration with infrequent updates - Rate limiting counters (with planned atomic increment) - Recently published message lookup</p> <p>Poor cache use cases: - Strongly consistent shared state requiring transactions - Large values (&gt; 1 MB) better served by object storage - Frequently updated counters (better as pub/sub)</p> <p>Design for Semantics</p> <p>Design your application for the semantics Felix provides, not the semantics you wish it had. If you need stronger guarantees than MVP provides, layer them in your application or wait for planned features.</p>"},{"location":"architecture/system-design/","title":"System Design","text":"<p>Felix is a sovereign-first, low-latency distributed data backend that unifies event streaming, message queueing, and distributed caching over a single QUIC-based transport layer.</p>"},{"location":"architecture/system-design/#design-principles","title":"Design Principles","text":""},{"location":"architecture/system-design/#1-sovereignty-by-default","title":"1. Sovereignty by Default","text":"<p>Each Felix cluster represents a single sovereign region. Data is isolated by default and cannot leave the region unless an explicit, configured bridge exists. This is enforced in routing, metadata, and encryption boundaries\u2014not left to deployment discipline.</p> <p>Why this matters:</p> <ul> <li>Regulatory Compliance: GDPR, CCPA, HIPAA require data residency</li> <li>Data Sovereignty: Government and enterprise data governance</li> <li>Security: Reduced attack surface with explicit data movement</li> <li>Auditability: Complete visibility into cross-region data flow</li> </ul>"},{"location":"architecture/system-design/#2-one-core-log-many-semantics","title":"2. One Core Log, Many Semantics","text":"<p>Internally, Felix is built around a single append-only log abstraction. Different external semantics are projections over this core:</p> <ul> <li>Streams (Pub/Sub): Fanout cursors per subscription</li> <li>Queues: Shared consumer-group cursors with acknowledgements</li> <li>Cache: Key \u2192 latest value with TTL, backed by the same log for invalidation and replay</li> </ul> <p>This drastically reduces operational complexity and consistency bugs compared to running Kafka, Redis, and a queueing system side-by-side.</p>"},{"location":"architecture/system-design/#3-low-latency-first","title":"3. Low-Latency First","text":"<p>Felix prioritizes predictable low latency over maximum batch throughput:</p> <ul> <li>QUIC transport: Multiplexed, encrypted, congestion-aware</li> <li>Optional ephemeral streams: No disk on hot path</li> <li>Aggressive backpressure: Bounded memory everywhere</li> <li>Leader-based writes: Tunable acknowledgement policies</li> </ul>"},{"location":"architecture/system-design/#4-kubernetes-native","title":"4. Kubernetes-Native","text":"<p>Felix assumes Kubernetes for process lifecycle, identity (ServiceAccounts), networking and service discovery, and failure detection. Felix does not attempt to reimplement scheduling or node membership logic that Kubernetes already provides.</p>"},{"location":"architecture/system-design/#system-architecture-current-mvp","title":"System Architecture (Current MVP)","text":"<p>The current implementation is a single-node broker for development and testing:</p> <pre><code>flowchart TB\n    subgraph Clients[\"Client Applications\"]\n        P1[\"Publisher 1\"]\n        P2[\"Publisher 2\"]\n        S1[\"Subscriber 1\"]\n        S2[\"Subscriber 2\"]\n        C1[\"Cache Client\"]\n    end\n\n    subgraph Broker[\"Felix Broker (Single Node)\"]\n        direction TB\n        Transport[\"QUIC Transport Layer&lt;br/&gt;felix-transport\"]\n        Wire[\"Wire Protocol Handler&lt;br/&gt;felix-wire framing\"]\n        Router[\"Stream Router&lt;br/&gt;Control vs Event vs Cache\"]\n\n        subgraph DataPlane[\"Data Plane\"]\n            PubSub[\"Pub/Sub Engine&lt;br/&gt;felix-broker\"]\n            Cache[\"Cache Engine&lt;br/&gt;TTL + eviction\"]\n            Storage[\"Ephemeral Storage&lt;br/&gt;In-memory\"]\n        end\n\n        Metrics[\"Metrics Server&lt;br/&gt;:8080\"]\n\n        Transport --&gt; Wire\n        Wire --&gt; Router\n        Router --&gt; PubSub\n        Router --&gt; Cache\n        PubSub --&gt; Storage\n        Cache --&gt; Storage\n    end\n\n    P1 &amp; P2 --&gt; Transport\n    Transport --&gt; S1 &amp; S2\n    C1 &lt;--&gt; Transport\n\n    PubSub -.-&gt; Metrics\n    Cache -.-&gt; Metrics</code></pre> <p>Key Components:</p> <ul> <li>Transport Layer: Accepts QUIC connections, manages stream lifecycle</li> <li>Wire Protocol: Frames messages, validates envelopes, routes by type</li> <li>Pub/Sub Engine: Enqueues publishes, manages subscriptions, fans out events</li> <li>Cache Engine: Handles put/get operations with TTL and lazy expiration</li> <li>Storage: In-memory ring buffers and hash maps (ephemeral)</li> <li>Metrics Server: Prometheus-compatible endpoint for monitoring</li> </ul>"},{"location":"architecture/system-design/#planned-multi-node-architecture","title":"Planned Multi-Node Architecture","text":"<p>The intended multi-node design adds explicit control-plane coordination and data-plane scalability:</p> <pre><code>flowchart TB\n    subgraph Clients[\"Clients\"]\n        C1[\"Producers\"]\n        C2[\"Consumers\"]\n        C3[\"Cache Clients\"]\n    end\n\n    LB[\"Load Balancer&lt;br/&gt;(L4 for QUIC)\"]\n\n    Clients --&gt; LB\n\n    subgraph ControlPlane[\"Control Plane (RAFT)\"]\n        direction LR\n        CP1[\"controlplane-0\"]\n        CP2[\"controlplane-1\"]\n        CP3[\"controlplane-2\"]\n\n        CP1 &lt;--&gt; CP2\n        CP2 &lt;--&gt; CP3\n        CP1 &lt;--&gt; CP3\n\n        Meta[\"Metadata Store&lt;br/&gt;\u2022 Topics/Streams&lt;br/&gt;\u2022 Tenants/Namespaces&lt;br/&gt;\u2022 Shard Placement&lt;br/&gt;\u2022 ACLs/Quotas\"]\n    end\n\n    subgraph DataPlane[\"Data Plane (Brokers)\"]\n        direction LR\n        B1[\"Broker A&lt;br/&gt;Shards 0-99\"]\n        B2[\"Broker B&lt;br/&gt;Shards 100-199\"]\n        B3[\"Broker C&lt;br/&gt;Shards 200-299\"]\n    end\n\n    subgraph Storage[\"Storage Layer\"]\n        direction LR\n        Ephemeral[\"Ephemeral&lt;br/&gt;(in-memory)\"]\n        Durable[\"Durable Log&lt;br/&gt;(persistent volumes)\"]\n        Snapshots[\"Snapshots&lt;br/&gt;(object storage)\"]\n    end\n\n    LB --&gt; DataPlane\n    ControlPlane --&gt; Meta\n    DataPlane &lt;--&gt; ControlPlane\n    DataPlane --&gt; Storage</code></pre>"},{"location":"architecture/system-design/#control-plane-responsibilities","title":"Control Plane Responsibilities","text":"<ul> <li>Metadata Management: Topics, tenants, namespaces, ACLs</li> <li>Shard Placement: Assign shards to broker nodes</li> <li>Health Monitoring: Track broker liveness and readiness</li> <li>Configuration: Cluster-wide retention, limits, feature flags</li> <li>Rebalancing: Migrate shards on node failures or scaling events</li> </ul>"},{"location":"architecture/system-design/#data-plane-responsibilities","title":"Data Plane Responsibilities","text":"<ul> <li>Client Connections: Accept and route QUIC streams</li> <li>Data Operations: Publish, subscribe, cache operations</li> <li>Shard Ownership: Host assigned shards (leaders and followers)</li> <li>Replication: (Future) Replicate log entries to followers</li> <li>Backpressure: Enforce flow control and isolation</li> </ul>"},{"location":"architecture/system-design/#data-flow-patterns","title":"Data Flow Patterns","text":""},{"location":"architecture/system-design/#publishsubscribe-flow","title":"Publish/Subscribe Flow","text":"<pre><code>sequenceDiagram\n    participant P as Publisher\n    participant B as Broker\n    participant S1 as Subscriber 1\n    participant S2 as Subscriber 2\n\n    P-&gt;&gt;B: Open control stream (QUIC bi)\n    S1-&gt;&gt;B: Open control stream (QUIC bi)\n    S2-&gt;&gt;B: Open control stream (QUIC bi)\n\n    S1-&gt;&gt;B: Subscribe(tenant, namespace, stream)\n    B--&gt;&gt;S1: OK\n    B-&gt;&gt;S1: Open event stream (QUIC uni)\n\n    S2-&gt;&gt;B: Subscribe(tenant, namespace, stream)\n    B--&gt;&gt;S2: OK\n    B-&gt;&gt;S2: Open event stream (QUIC uni)\n\n    loop Publishing\n        P-&gt;&gt;B: Publish(batch of messages)\n        B--&gt;&gt;P: ACK (optional)\n        B-&gt;&gt;B: Enqueue for fanout\n        par Fanout to subscribers\n            B-&gt;&gt;S1: Event batch\n            B-&gt;&gt;S2: Event batch\n        end\n    end</code></pre> <p>Key characteristics:</p> <ul> <li>Publishers use bidirectional control streams for publish requests</li> <li>Subscribers get dedicated unidirectional event streams</li> <li>Fanout happens independently per subscriber (isolation)</li> <li>Batching is time and count-bounded for throughput optimization</li> </ul>"},{"location":"architecture/system-design/#cache-flow","title":"Cache Flow","text":"<pre><code>sequenceDiagram\n    participant C as Client\n    participant B as Broker\n\n    C-&gt;&gt;B: Open cache stream pool (N connections)\n    Note over C,B: M stream workers per connection\n\n    par Concurrent requests\n        C-&gt;&gt;B: cache_put(key1, value1, ttl)\n        C-&gt;&gt;B: cache_get(key2)\n        C-&gt;&gt;B: cache_put(key3, value3, ttl)\n    end\n\n    par Concurrent responses\n        B--&gt;&gt;C: OK (key1)\n        B--&gt;&gt;C: cache_value(key2, null)\n        B--&gt;&gt;C: OK (key3)\n    end</code></pre> <p>Key characteristics:</p> <ul> <li>Connection pooling reduces handshake overhead</li> <li>Request multiplexing over long-lived streams</li> <li>Request IDs for request/response matching</li> <li>Sub-millisecond latency at moderate concurrency</li> </ul>"},{"location":"architecture/system-design/#cross-broker-routing-planned","title":"Cross-Broker Routing (Planned)","text":"<p>When a client connects to a broker that doesn't own the target shard:</p> <pre><code>sequenceDiagram\n    participant C as Client\n    participant B1 as Broker (ingress)\n    participant CP as Control Plane\n    participant B2 as Broker (shard owner)\n\n    C-&gt;&gt;B1: Publish(topic, batch)\n    B1-&gt;&gt;CP: Lookup shard placement(topic)\n    CP--&gt;&gt;B1: owner = B2\n    B1-&gt;&gt;B2: Forward publish (internal QUIC)\n    B2-&gt;&gt;B2: Commit to log\n    B2--&gt;&gt;B1: ACK\n    B1--&gt;&gt;C: ACK</code></pre>"},{"location":"architecture/system-design/#storage-architecture","title":"Storage Architecture","text":""},{"location":"architecture/system-design/#ephemeral-current-mvp","title":"Ephemeral (Current MVP)","text":"<ul> <li>In-memory only: No disk writes on hot path</li> <li>Bounded buffers: Ring buffers with fixed capacity</li> <li>TTL support: Lazy expiration on access</li> <li>No persistence: Data lost on restart</li> </ul> <p>Use cases:</p> <ul> <li>Ultra-low latency workloads</li> <li>Development and testing</li> <li>Temporary caching</li> <li>Non-critical event streams</li> </ul>"},{"location":"architecture/system-design/#durable-planned","title":"Durable (Planned)","text":"<ul> <li>Write-Ahead Log (WAL): Append-only log segments</li> <li>Segmented storage: Rotate segments based on time/size</li> <li>Retention policies: Time-based and size-based limits</li> <li>Snapshots: Periodic state snapshots for faster recovery</li> </ul> <p>Use cases:</p> <ul> <li>Production event streaming</li> <li>Critical message delivery</li> <li>Long-term event retention</li> <li>Replay and audit trails</li> </ul>"},{"location":"architecture/system-design/#consistency-model","title":"Consistency Model","text":""},{"location":"architecture/system-design/#single-node-mvp","title":"Single-Node (MVP)","text":"<ul> <li>Delivery: At-most-once (best-effort)</li> <li>Ordering: Per-stream ordering preserved per subscriber</li> <li>Durability: None (ephemeral only)</li> </ul>"},{"location":"architecture/system-design/#multi-node-planned","title":"Multi-Node (Planned)","text":"<p>Tunable per stream:</p> <ul> <li>Leader-only acknowledgements: Lowest latency, leader commits before replicating</li> <li>Quorum acknowledgements: Higher durability, waits for majority replica confirmation</li> <li>Asynchronous replication: Background replication after ACK</li> <li>Synchronous replication: Blocks on replication before ACK</li> </ul> <p>Delivery guarantees:</p> <ul> <li>At-least-once: With durable storage and replay on failure</li> <li>At-most-once: Best-effort with no retries</li> <li>Exactly-once: (Future roadmap) via idempotent producers and transactions</li> </ul>"},{"location":"architecture/system-design/#multi-region-architecture-planned","title":"Multi-Region Architecture (Planned)","text":"<p>Felix enforces regional isolation with explicit bridges:</p> <pre><code>flowchart LR\n    subgraph Region1[\"Region: US-EAST\"]\n        B1[\"Brokers&lt;br/&gt;US-EAST\"]\n        CP1[\"Control Plane&lt;br/&gt;US-EAST\"]\n    end\n\n    subgraph Region2[\"Region: EU-WEST\"]\n        B2[\"Brokers&lt;br/&gt;EU-WEST\"]\n        CP2[\"Control Plane&lt;br/&gt;EU-WEST\"]\n    end\n\n    subgraph Bridge[\"Explicit Bridge\"]\n        BridgeAgent[\"Bridge Agent&lt;br/&gt;\u2022 Allowlist&lt;br/&gt;\u2022 Encryption&lt;br/&gt;\u2022 Audit Log\"]\n    end\n\n    B1 &lt;--&gt;|\"Explicit config only\"| BridgeAgent\n    BridgeAgent &lt;--&gt;|\"Explicit config only\"| B2\n\n    style Region1 fill:#e1f5ff\n    style Region2 fill:#fff4e1\n    style Bridge fill:#ffe1e1</code></pre> <p>Bridge characteristics:</p> <ul> <li>Explicit Configuration: No implicit data movement</li> <li>Stream Allowlist: Only specified streams replicate</li> <li>Independent Encryption: Per-region key contexts</li> <li>Audit Trail: Complete log of cross-region data movement</li> <li>Compliance: Satisfies strict data sovereignty requirements</li> </ul>"},{"location":"architecture/system-design/#scalability-considerations","title":"Scalability Considerations","text":""},{"location":"architecture/system-design/#vertical-scaling-single-node","title":"Vertical Scaling (Single-Node)","text":"<ul> <li>CPU: More cores for parallel stream processing</li> <li>Memory: Larger buffers and cache capacity</li> <li>Network: Higher bandwidth for fanout</li> <li>Typical: 10k-50k msg/s on modern hardware</li> </ul>"},{"location":"architecture/system-design/#horizontal-scaling-multi-node","title":"Horizontal Scaling (Multi-Node)","text":"<ul> <li>Sharding: Partition streams across brokers</li> <li>Connection pooling: Reuse connections across shards</li> <li>Control plane: RAFT quorum for metadata (3-5 nodes)</li> <li>Data plane: Many broker nodes for capacity</li> <li>Target: 100k-1M+ msg/s per cluster</li> </ul>"},{"location":"architecture/system-design/#next-steps","title":"Next Steps","text":"<ul> <li>Components Deep Dive - Detailed component architecture</li> <li>Wire Protocol - Protocol specification</li> <li>Semantics - Delivery and consistency guarantees</li> <li>Performance Tuning - Optimize for your workload</li> </ul>"},{"location":"architecture/wire-protocol/","title":"Wire Protocol Specification","text":"<p>The Felix wire protocol is the language-neutral specification that defines how clients and brokers communicate over the network. This document provides a comprehensive reference for implementing Felix-compatible clients and servers.</p>"},{"location":"architecture/wire-protocol/#design-goals","title":"Design Goals","text":"<p>The wire protocol is designed with the following priorities:</p> <ol> <li>Language neutrality: No Rust-specific types or semantics</li> <li>Forward compatibility: Version negotiation and feature flags</li> <li>Debuggability: Human-readable messages in v1 with binary fast paths</li> <li>Explicit framing: Clear message boundaries over stream transport</li> <li>Performance escape hatches: Binary encodings for high-throughput workloads</li> </ol> <p>Stability Guarantee</p> <p>The wire protocol v1 is considered stable. All future changes will maintain backward compatibility through version negotiation or optional feature flags.</p>"},{"location":"architecture/wire-protocol/#transport-layer","title":"Transport Layer","text":"<p>Felix uses QUIC over TLS 1.3 (IETF QUIC) as its exclusive transport:</p> <ul> <li>Encrypted by default: TLS 1.3 handshake integrated into connection setup</li> <li>Multiplexed streams: Multiple independent streams per connection</li> <li>Flow control: Built-in backpressure at connection and stream levels</li> <li>No head-of-line blocking: Stream independence prevents HOL blocking</li> <li>0-RTT support: Future optimization for repeat connections</li> </ul> <p>The protocol is transport-agnostic in design and could theoretically run over TCP+TLS, but QUIC is the only supported transport in the initial implementation.</p>"},{"location":"architecture/wire-protocol/#frame-structure","title":"Frame Structure","text":"<p>Every Felix message is transmitted as a frame consisting of a fixed-size header followed by a variable-length payload.</p>"},{"location":"architecture/wire-protocol/#frame-header-12-bytes","title":"Frame Header (12 bytes)","text":"<pre><code> 0                   1                   2                   3\n 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            magic              \u2502    version    \u2502     flags     \u2502\n\u2502         (4 bytes)             \u2502   (2 bytes)   \u2502   (2 bytes)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                           length                              \u2502\n\u2502                         (4 bytes)                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nAll multi-byte integers are big-endian (network byte order)\n</code></pre>"},{"location":"architecture/wire-protocol/#field-definitions","title":"Field Definitions","text":"<p>magic (u32, big-endian)</p> <p>Fixed value: <code>0x464C5831</code> (ASCII \"FLX1\")</p> <p>Purpose: Protocol identification and frame synchronization. Decoders should reject frames with incorrect magic numbers.</p> <p>version (u16, big-endian)</p> <p>Protocol version: <code>1</code> for current specification</p> <p>Future versions will use different version numbers to enable negotiation and backward compatibility.</p> <p>flags (u16, big-endian)</p> <p>Bit field for optional features:</p> Bit Mask Meaning 0 0x0001 Binary publish batch encoding 1-15 - Reserved (must be 0 in v1) <p>Receivers must ignore unknown flag bits to allow forward compatibility.</p> <p>length (u32, big-endian)</p> <p>Payload length in bytes: <code>0</code> to <code>2^32 - 1</code></p> <p>This is the byte count of the payload following the header. The maximum practical frame size is typically much smaller (16 MB default limit).</p>"},{"location":"architecture/wire-protocol/#frame-payload","title":"Frame Payload","text":"<p>The payload encoding depends on the flags:</p> <p>Standard JSON Encoding (flags = 0x0000): - Payload is a UTF-8 encoded JSON object - Must be valid JSON per RFC 8259 - No trailing whitespace required</p> <p>Binary Batch Encoding (flags &amp; 0x0001): - Payload is a binary-encoded publish batch (see Binary Encoding section) - Used for high-throughput publish workloads</p>"},{"location":"architecture/wire-protocol/#message-types","title":"Message Types","text":"<p>All JSON payloads are objects with a <code>type</code> discriminator field. The type determines the message schema and semantics.</p>"},{"location":"architecture/wire-protocol/#client-server-messages","title":"Client \u2192 Server Messages","text":""},{"location":"architecture/wire-protocol/#publish","title":"Publish","text":"<p>Single-message publish operation.</p> <pre><code>{\n  \"type\": \"publish\",\n  \"tenant_id\": \"string\",\n  \"namespace\": \"string\",\n  \"stream\": \"string\",\n  \"payload\": \"base64-encoded-bytes\",\n  \"ack\": \"none\" | \"per_message\"\n}\n</code></pre> <p>Fields: - <code>tenant_id</code>: Tenant identifier (must exist in broker registry) - <code>namespace</code>: Namespace identifier within tenant - <code>stream</code>: Stream name to publish to - <code>payload</code>: Message payload encoded as base64 - <code>ack</code>: Acknowledgement mode   - <code>none</code>: Fire-and-forget, no ack sent   - <code>per_message</code>: Broker sends <code>ok</code> after accepting message</p> <p>Semantics: - Message is enqueued to the broker's publish pipeline - If <code>ack</code> is <code>per_message</code>, broker responds with <code>ok</code> after enqueuing - No ordering guarantees across different publish operations</p>"},{"location":"architecture/wire-protocol/#publishbatch","title":"PublishBatch","text":"<p>Batch publish operation for improved throughput.</p> <pre><code>{\n  \"type\": \"publish_batch\",\n  \"tenant_id\": \"string\",\n  \"namespace\": \"string\",\n  \"stream\": \"string\",\n  \"payloads\": [\"base64-1\", \"base64-2\", \"base64-n\"],\n  \"ack\": \"none\" | \"per_batch\"\n}\n</code></pre> <p>Fields: - <code>tenant_id</code>, <code>namespace</code>, <code>stream</code>: Same as Publish - <code>payloads</code>: Array of base64-encoded message payloads - <code>ack</code>: Acknowledgement mode   - <code>none</code>: Fire-and-forget   - <code>per_batch</code>: Single <code>ok</code> after entire batch is accepted</p> <p>Semantics: - All messages in batch are enqueued atomically - Ordering is preserved within the batch - More efficient than individual publishes for high-throughput workloads</p>"},{"location":"architecture/wire-protocol/#subscribe","title":"Subscribe","text":"<p>Initiate a subscription to a stream.</p> <pre><code>{\n  \"type\": \"subscribe\",\n  \"tenant_id\": \"string\",\n  \"namespace\": \"string\",\n  \"stream\": \"string\"\n}\n</code></pre> <p>Semantics: - Subscription starts at tail (current offset) - No historical replay in MVP - Broker responds with <code>ok</code> on the control stream - Broker opens a new unidirectional stream for event delivery - First frame on event stream is <code>EventStreamHello</code> (see below)</p>"},{"location":"architecture/wire-protocol/#cacheput","title":"CachePut","text":"<p>Store a key-value pair in the cache with optional TTL.</p> <pre><code>{\n  \"type\": \"cache_put\",\n  \"request_id\": \"string\",\n  \"key\": \"string\",\n  \"value\": \"base64-encoded-bytes\",\n  \"ttl_ms\": number | null\n}\n</code></pre> <p>Fields: - <code>request_id</code>: Client-provided identifier for request/response matching - <code>key</code>: Cache key (arbitrary string) - <code>value</code>: Value encoded as base64 - <code>ttl_ms</code>: Time-to-live in milliseconds (null = no expiration)</p> <p>Semantics: - Value is stored and expires after TTL if specified - Broker responds with <code>ok</code> containing the same <code>request_id</code> - Expiration is lazy (checked on access)</p>"},{"location":"architecture/wire-protocol/#cacheget","title":"CacheGet","text":"<p>Retrieve a value from the cache.</p> <pre><code>{\n  \"type\": \"cache_get\",\n  \"request_id\": \"string\",\n  \"key\": \"string\"\n}\n</code></pre> <p>Semantics: - Broker responds with <code>cache_value</code> containing the same <code>request_id</code> - Value is <code>null</code> if key is missing or expired</p>"},{"location":"architecture/wire-protocol/#server-client-messages","title":"Server \u2192 Client Messages","text":""},{"location":"architecture/wire-protocol/#event","title":"Event","text":"<p>Event delivery on a subscription stream.</p> <pre><code>{\n  \"type\": \"event\",\n  \"tenant_id\": \"string\",\n  \"namespace\": \"string\",\n  \"stream\": \"string\",\n  \"payload\": \"base64-encoded-bytes\"\n}\n</code></pre> <p>Semantics: - Sent on unidirectional event streams - One event per frame (unless batched) - No acknowledgement from client in MVP</p>"},{"location":"architecture/wire-protocol/#eventbatch","title":"EventBatch","text":"<p>Batched event delivery (optimization).</p> <pre><code>{\n  \"type\": \"event_batch\",\n  \"tenant_id\": \"string\",\n  \"namespace\": \"string\",\n  \"stream\": \"string\",\n  \"payloads\": [\"base64-1\", \"base64-2\", \"base64-n\"]\n}\n</code></pre> <p>Semantics: - Multiple events delivered in single frame - Reduces framing overhead for high-throughput streams - Configurable via broker batching parameters</p>"},{"location":"architecture/wire-protocol/#eventstreamhello","title":"EventStreamHello","text":"<p>First frame on a subscription event stream.</p> <pre><code>{\n  \"type\": \"event_stream_hello\",\n  \"subscription_id\": \"string\"\n}\n</code></pre> <p>Semantics: - Allows client to correlate stream with subscription request - Must be first frame on event stream - Subsequent frames are events</p>"},{"location":"architecture/wire-protocol/#cachevalue","title":"CacheValue","text":"<p>Cache lookup response.</p> <pre><code>{\n  \"type\": \"cache_value\",\n  \"request_id\": \"string\",\n  \"key\": \"string\",\n  \"value\": \"base64-encoded-bytes\" | null\n}\n</code></pre> <p>Fields: - <code>request_id</code>: Matches the request - <code>key</code>: Requested key - <code>value</code>: Retrieved value or <code>null</code> if missing/expired</p>"},{"location":"architecture/wire-protocol/#ok","title":"Ok","text":"<p>Generic success acknowledgement.</p> <pre><code>{\n  \"type\": \"ok\",\n  \"request_id\": \"string\"\n}\n</code></pre> <p>Semantics: - Sent in response to publish (if acked), subscribe, cache_put - <code>request_id</code> matches the request when applicable</p>"},{"location":"architecture/wire-protocol/#error","title":"Error","text":"<p>Error response.</p> <pre><code>{\n  \"type\": \"error\",\n  \"request_id\": \"string\",\n  \"message\": \"human-readable-error-description\"\n}\n</code></pre> <p>Common error conditions: - Unknown tenant/namespace/stream - Malformed frame - Authorization failure (future) - Resource exhaustion</p>"},{"location":"architecture/wire-protocol/#binary-publish-batch-encoding","title":"Binary Publish Batch Encoding","text":"<p>For high-throughput publish workloads, Felix supports a binary encoding that eliminates JSON parsing overhead.</p>"},{"location":"architecture/wire-protocol/#when-to-use-binary-mode","title":"When to Use Binary Mode","text":"<p>Binary mode is enabled by setting flag bit 0 (<code>flags | 0x0001</code>). Use when:</p> <ul> <li>Publishing large batches (64+ messages)</li> <li>Payload sizes exceed 512 bytes</li> <li>Throughput is more important than debuggability</li> <li>You've validated the binary encoding implementation</li> </ul> <p>Performance Impact</p> <p>Binary batches can achieve 30-40% higher throughput than JSON batches, especially with large payloads and high fanout. Enable with <code>event_single_binary_enabled: true</code> in broker config.</p>"},{"location":"architecture/wire-protocol/#binary-format-specification","title":"Binary Format Specification","text":"<pre><code> 0               2               4\n 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 ...\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  tenant_len   \u2502  tenant_id    \u2502 ...                         \u2502\n\u2502   (u16 BE)    \u2502  (bytes)      \u2502                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 namespace_len \u2502  namespace    \u2502 ...                         \u2502\n\u2502   (u16 BE)    \u2502  (bytes)      \u2502                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  stream_len   \u2502  stream       \u2502 ...                         \u2502\n\u2502   (u16 BE)    \u2502  (bytes)      \u2502                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                     count (u32 BE)                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  payload_1_len (u32 BE)                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  payload_1 (bytes)                                          \u2502\n\u2502  ...                                                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  payload_2_len (u32 BE)                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  payload_2 (bytes)                                          \u2502\n\u2502  ...                                                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Encoding steps:</p> <ol> <li>Write <code>tenant_len</code> as u16 big-endian</li> <li>Write <code>tenant_id</code> bytes (UTF-8)</li> <li>Write <code>namespace_len</code> as u16 big-endian</li> <li>Write <code>namespace</code> bytes (UTF-8)</li> <li>Write <code>stream_len</code> as u16 big-endian</li> <li>Write <code>stream</code> bytes (UTF-8)</li> <li>Write <code>count</code> as u32 big-endian (number of payloads)</li> <li>For each payload:</li> <li>Write <code>payload_len</code> as u32 big-endian</li> <li>Write <code>payload</code> bytes (raw binary)</li> </ol> <p>Constraints: - tenant_id, namespace, stream limited to 65535 bytes each - count limited to 2^32 - 1 payloads per batch - Each payload limited to 2^32 - 1 bytes</p>"},{"location":"architecture/wire-protocol/#protocol-flows","title":"Protocol Flows","text":""},{"location":"architecture/wire-protocol/#connection-establishment","title":"Connection Establishment","text":"<pre><code>sequenceDiagram\n    participant C as Client\n    participant S as Server\n\n    Note over C,S: QUIC/TLS 1.3 Handshake\n    C-&gt;&gt;S: ClientHello (QUIC Initial)\n    S-&gt;&gt;C: ServerHello + Certificate\n    C-&gt;&gt;S: Certificate Verify + Finished\n    S-&gt;&gt;C: Finished\n    Note over C,S: Connection established</code></pre>"},{"location":"architecture/wire-protocol/#publish-with-acknowledgement","title":"Publish with Acknowledgement","text":"<pre><code>sequenceDiagram\n    participant C as Client\n    participant S as Server\n\n    Note over C: Open bidirectional control stream\n    C-&gt;&gt;S: publish_batch (ack: per_batch)\n    Note over S: Validate &amp; enqueue\n    S-&gt;&gt;C: ok</code></pre>"},{"location":"architecture/wire-protocol/#subscribe-and-receive-events","title":"Subscribe and Receive Events","text":"<pre><code>sequenceDiagram\n    participant C as Client\n    participant S as Server\n\n    Note over C: Open bidirectional control stream\n    C-&gt;&gt;S: subscribe\n    S-&gt;&gt;C: ok\n    Note over S: Open unidirectional event stream\n    S-&gt;&gt;C: event_stream_hello\n    loop Event delivery\n        S-&gt;&gt;C: event\n        S-&gt;&gt;C: event\n        S-&gt;&gt;C: event_batch\n    end</code></pre>"},{"location":"architecture/wire-protocol/#cache-operations","title":"Cache Operations","text":"<pre><code>sequenceDiagram\n    participant C as Client\n    participant S as Server\n\n    Note over C: Open bidirectional cache stream\n    C-&gt;&gt;S: cache_put (request_id: 1)\n    S-&gt;&gt;C: ok (request_id: 1)\n    C-&gt;&gt;S: cache_get (request_id: 2)\n    S-&gt;&gt;C: cache_value (request_id: 2)\n    C-&gt;&gt;S: cache_get (request_id: 3)\n    S-&gt;&gt;C: cache_value (request_id: 3, value: null)</code></pre> <p>Request Multiplexing</p> <p>Cache streams support request pipelining. Clients can send multiple requests without waiting for responses. The broker may respond out of order; use <code>request_id</code> to correlate requests and responses.</p>"},{"location":"architecture/wire-protocol/#stream-types-and-lifecycle","title":"Stream Types and Lifecycle","text":"<p>Felix uses different QUIC stream patterns for different workload characteristics:</p>"},{"location":"architecture/wire-protocol/#control-streams-bidirectional","title":"Control Streams (Bidirectional)","text":"<p>Purpose: Request/response control plane operations</p> <p>Lifecycle: 1. Client opens bidirectional stream 2. Client sends publish, subscribe, or cache requests 3. Server sends acknowledgements and responses 4. Either side can close when done</p> <p>Characteristics: - Long-lived or short-lived depending on usage - Multiplexed on single connection - Flow control prevents backpressure</p>"},{"location":"architecture/wire-protocol/#event-streams-unidirectional-server-opened","title":"Event Streams (Unidirectional, Server-opened)","text":"<p>Purpose: Push events from server to client</p> <p>Lifecycle: 1. Server opens unidirectional stream after subscribe 2. Server sends <code>event_stream_hello</code> 3. Server sends stream of events 4. Server closes stream when subscription ends</p> <p>Characteristics: - One stream per subscription - Independent flow control - Isolation between subscriptions</p>"},{"location":"architecture/wire-protocol/#cache-streams-bidirectional-pooled","title":"Cache Streams (Bidirectional, Pooled)","text":"<p>Purpose: High-concurrency cache operations</p> <p>Lifecycle: 1. Client opens bidirectional stream 2. Client sends multiple cache requests with unique request_ids 3. Server responds with matching request_ids 4. Stream lives for duration of cache operations</p> <p>Characteristics: - Pooled for concurrency (multiple streams per connection) - Request/response multiplexing via request_id - Reduces stream setup overhead</p>"},{"location":"architecture/wire-protocol/#error-handling","title":"Error Handling","text":""},{"location":"architecture/wire-protocol/#protocol-errors","title":"Protocol Errors","text":"<p>Malformed frame header: - Close connection with QUIC error code - Log protocol violation</p> <p>Invalid JSON payload: - Send <code>error</code> message on same stream - Close stream if error is unrecoverable</p> <p>Unknown message type: - Send <code>error</code> message - Future versions may handle gracefully</p>"},{"location":"architecture/wire-protocol/#application-errors","title":"Application Errors","text":"<p>Unknown tenant/namespace/stream: - Send <code>error</code> with descriptive message - Client should not retry without fixing configuration</p> <p>Authorization failure: - Send <code>error</code> with \"unauthorized\" message - Client should refresh credentials or permissions</p> <p>Backpressure / resource exhaustion: - Apply QUIC flow control (stop granting credits) - Slow subscribers may drop events in MVP</p>"},{"location":"architecture/wire-protocol/#conformance-testing","title":"Conformance Testing","text":"<p>All Felix client and server implementations must pass the shared conformance test suite.</p>"},{"location":"architecture/wire-protocol/#test-vectors","title":"Test Vectors","text":"<p>Test vectors are located in <code>crates/felix-wire/tests/vectors/</code>:</p> <ul> <li><code>frame_valid.json</code>: Valid frame encodings</li> <li><code>frame_invalid.json</code>: Invalid frames that must be rejected</li> <li><code>message_valid.json</code>: Valid message payloads</li> <li><code>message_invalid.json</code>: Invalid messages</li> <li><code>binary_batch_valid.bin</code>: Binary batch test cases</li> </ul>"},{"location":"architecture/wire-protocol/#conformance-runner","title":"Conformance Runner","text":"<p>Run the conformance suite:</p> <pre><code>cargo run -p felix-conformance\n</code></pre> <p>What it tests: - Frame header encoding/decoding - JSON message serialization/deserialization - Binary batch encoding/decoding - Error handling for malformed inputs - Round-trip serialization stability</p> <p>Implementation Requirement</p> <p>Any client or server claiming Felix protocol compatibility must pass the full conformance suite. This ensures interoperability and prevents subtle edge case bugs.</p>"},{"location":"architecture/wire-protocol/#backward-compatibility","title":"Backward Compatibility","text":""},{"location":"architecture/wire-protocol/#version-negotiation-future","title":"Version Negotiation (Future)","text":"<p>Future protocol versions will negotiate using the <code>version</code> field:</p> <ol> <li>Client sends supported version list in connection metadata</li> <li>Server selects highest mutually supported version</li> <li>All subsequent frames use negotiated version</li> </ol>"},{"location":"architecture/wire-protocol/#feature-flag-negotiation-future","title":"Feature Flag Negotiation (Future)","text":"<p>Optional features (compression, alternative encodings) will be negotiated via the <code>flags</code> field:</p> <ol> <li>Client advertises supported flag bits</li> <li>Server responds with enabled flags</li> <li>Both sides enable only mutually supported features</li> </ol>"},{"location":"architecture/wire-protocol/#deprecation-policy","title":"Deprecation Policy","text":"<p>Deprecated protocol features will:</p> <ol> <li>Be marked deprecated for at least 2 major versions</li> <li>Generate warnings when used</li> <li>Eventually be removed with major version bump</li> </ol>"},{"location":"architecture/wire-protocol/#implementation-guidance","title":"Implementation Guidance","text":""},{"location":"architecture/wire-protocol/#client-implementation-checklist","title":"Client Implementation Checklist","text":"<ul> <li> Implement frame header encoding/decoding</li> <li> Implement JSON message serialization</li> <li> Implement binary batch encoding (optional but recommended)</li> <li> Handle all standard message types</li> <li> Implement proper error handling</li> <li> Pass conformance test suite</li> <li> Support connection pooling</li> <li> Implement proper QUIC stream lifecycle</li> <li> Handle backpressure gracefully</li> </ul>"},{"location":"architecture/wire-protocol/#server-implementation-checklist","title":"Server Implementation Checklist","text":"<ul> <li> Implement frame header decoding/encoding</li> <li> Implement JSON message deserialization</li> <li> Implement binary batch decoding</li> <li> Route messages to appropriate handlers</li> <li> Implement proper error responses</li> <li> Pass conformance test suite</li> <li> Enforce stream type invariants</li> <li> Apply backpressure when needed</li> <li> Log protocol violations</li> </ul>"},{"location":"architecture/wire-protocol/#performance-optimization-tips","title":"Performance Optimization Tips","text":"<ol> <li>Avoid per-message allocation: Pre-allocate buffers for frame headers</li> <li>Use binary batches: 30-40% throughput improvement for large batches</li> <li>Pool connections: Amortize connection setup costs</li> <li>Pipeline cache requests: Don't wait for responses before sending next request</li> <li>Batch events: Reduce framing overhead by batching event deliveries</li> <li>Monitor flow control: Don't send faster than receiver can consume</li> </ol>"},{"location":"architecture/wire-protocol/#future-protocol-extensions","title":"Future Protocol Extensions","text":"<p>Planned protocol enhancements (not in v1):</p> <ul> <li>Compression: Optional zstd or lz4 compression (negotiated via flags)</li> <li>Encryption metadata: End-to-end encryption with key IDs in envelope</li> <li>Message ordering: Sequence numbers for exactly-once semantics</li> <li>Acknowledgements: Consumer acks for at-least-once delivery</li> <li>Stream filtering: Server-side filtering to reduce client bandwidth</li> <li>Historical replay: Subscribe from offset or timestamp</li> <li>Multi-tenancy: Tenant isolation and quotas</li> </ul> <p>These extensions will be added in backward-compatible ways through version negotiation or optional feature flags.</p>"},{"location":"deployment/docker-compose/","title":"Docker Compose Deployment","text":"<p>This guide demonstrates how to deploy Felix using Docker Compose for local development, testing, and small-scale production scenarios.</p>"},{"location":"deployment/docker-compose/#overview","title":"Overview","text":"<p>Docker Compose provides an easy way to run Felix with multiple components:</p> <ul> <li>Felix broker: Main data plane service</li> <li>Prometheus (optional): Metrics collection</li> <li>OpenTelemetry Collector (optional): Distributed tracing</li> <li>Control plane (future): Metadata and coordination</li> </ul> <p>Compose vs Kubernetes</p> <p>Use Docker Compose for local development and testing. For production deployments with high availability, see the Kubernetes guide.</p>"},{"location":"deployment/docker-compose/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker: 20.10 or later</li> <li>Docker Compose: v2.0 or later (or <code>docker compose</code> plugin)</li> <li>4GB RAM minimum: Recommended 8GB for comfortable operation</li> <li>Git: To clone the repository</li> </ul> <p>Install Docker Compose:</p> <pre><code># Check if already installed\ndocker compose version\n\n# If not, install Docker Desktop (includes Compose)\n# Or install standalone: https://docs.docker.com/compose/install/\n</code></pre>"},{"location":"deployment/docker-compose/#quick-start","title":"Quick Start","text":""},{"location":"deployment/docker-compose/#basic-broker-deployment","title":"Basic Broker Deployment","text":"<p>Create a minimal <code>docker-compose.yml</code>:</p> <pre><code>version: '3.8'\n\nservices:\n  felix-broker:\n    image: felix/broker:latest\n    build:\n      context: .\n      dockerfile: docker/broker.Dockerfile\n      args:\n        PROFILE: release\n    ports:\n      - \"5000:5000/udp\"  # QUIC data plane\n      - \"8080:8080\"      # Metrics HTTP\n    environment:\n      - FELIX_QUIC_BIND=0.0.0.0:5000\n      - FELIX_BROKER_METRICS_BIND=0.0.0.0:8080\n      - RUST_LOG=info\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"wget\", \"-qO-\", \"http://localhost:8080/healthz\"]\n      interval: 10s\n      timeout: 2s\n      retries: 3\n      start_period: 10s\n</code></pre> <p>Start the broker:</p> <pre><code>docker compose up -d\n</code></pre> <p>Check status:</p> <pre><code>docker compose ps\ndocker compose logs -f felix-broker\n</code></pre> <p>Test connectivity:</p> <pre><code>curl http://localhost:8080/healthz\n</code></pre>"},{"location":"deployment/docker-compose/#full-stack-with-observability","title":"Full Stack with Observability","text":"<p>Complete setup with monitoring:</p> <p><code>docker-compose.yml</code>:</p> <pre><code>version: '3.8'\n\nservices:\n  felix-broker:\n    image: felix/broker:latest\n    build:\n      context: .\n      dockerfile: docker/broker.Dockerfile\n      args:\n        PROFILE: release\n        CARGO_FEATURES: \"--features telemetry\"\n    ports:\n      - \"5000:5000/udp\"\n      - \"8080:8080\"\n    environment:\n      - FELIX_QUIC_BIND=0.0.0.0:5000\n      - FELIX_BROKER_METRICS_BIND=0.0.0.0:8080\n      - FELIX_EVENT_BATCH_MAX_EVENTS=64\n      - FELIX_EVENT_BATCH_MAX_DELAY_US=250\n      - FELIX_CACHE_CONN_POOL=8\n      - FELIX_CACHE_STREAMS_PER_CONN=4\n      - RUST_LOG=info\n    volumes:\n      - felix-data:/data\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"wget\", \"-qO-\", \"http://localhost:8080/healthz\"]\n      interval: 10s\n      timeout: 2s\n      retries: 3\n      start_period: 10s\n    networks:\n      - felix-net\n\n  prometheus:\n    image: prom/prometheus:latest\n    ports:\n      - \"9090:9090\"\n    volumes:\n      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro\n      - prometheus-data:/prometheus\n    command:\n      - '--config.file=/etc/prometheus/prometheus.yml'\n      - '--storage.tsdb.path=/prometheus'\n      - '--web.console.libraries=/usr/share/prometheus/console_libraries'\n      - '--web.console.templates=/usr/share/prometheus/consoles'\n    restart: unless-stopped\n    networks:\n      - felix-net\n    depends_on:\n      - felix-broker\n\n  otel-collector:\n    image: otel/opentelemetry-collector:latest\n    ports:\n      - \"4317:4317\"   # OTLP gRPC\n      - \"4318:4318\"   # OTLP HTTP\n      - \"8888:8888\"   # Prometheus metrics\n    volumes:\n      - ./docker/otel-collector/config.yml:/etc/otel-collector-config.yml:ro\n    command: [\"--config=/etc/otel-collector-config.yml\"]\n    restart: unless-stopped\n    networks:\n      - felix-net\n\nvolumes:\n  felix-data:\n    driver: local\n  prometheus-data:\n    driver: local\n\nnetworks:\n  felix-net:\n    driver: bridge\n</code></pre> <p>Prometheus configuration (<code>docker/prometheus/prometheus.yml</code>):</p> <pre><code>global:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n\nscrape_configs:\n  - job_name: 'felix-broker'\n    static_configs:\n      - targets: ['felix-broker:8080']\n        labels:\n          service: 'felix'\n          component: 'broker'\n\n  - job_name: 'otel-collector'\n    static_configs:\n      - targets: ['otel-collector:8888']\n</code></pre> <p>Start the full stack:</p> <pre><code>docker compose up -d\n\n# View logs\ndocker compose logs -f\n\n# Check services\ndocker compose ps\n\n# Access Prometheus UI\nopen http://localhost:9090\n</code></pre>"},{"location":"deployment/docker-compose/#configuration-options","title":"Configuration Options","text":""},{"location":"deployment/docker-compose/#environment-variables","title":"Environment Variables","text":"<p>Pass configuration via environment variables in <code>docker-compose.yml</code>:</p> <pre><code>services:\n  felix-broker:\n    environment:\n      # Network\n      - FELIX_QUIC_BIND=0.0.0.0:5000\n      - FELIX_BROKER_METRICS_BIND=0.0.0.0:8080\n\n      # Control plane\n      - FELIX_CP_URL=http://controlplane:8443\n      - FELIX_CP_SYNC_INTERVAL_MS=2000\n\n      # Publishing\n      - FELIX_ACK_ON_COMMIT=false\n      - FELIX_MAX_FRAME_BYTES=16777216\n      - FELIX_PUBLISH_QUEUE_WAIT_MS=2000\n\n      # Event batching\n      - FELIX_EVENT_BATCH_MAX_EVENTS=64\n      - FELIX_EVENT_BATCH_MAX_BYTES=262144\n      - FELIX_EVENT_BATCH_MAX_DELAY_US=250\n      - FELIX_FANOUT_BATCH=64\n\n      # Cache\n      - FELIX_CACHE_CONN_POOL=8\n      - FELIX_CACHE_STREAMS_PER_CONN=4\n      - FELIX_CACHE_CONN_RECV_WINDOW=268435456\n      - FELIX_CACHE_STREAM_RECV_WINDOW=67108864\n\n      # Performance\n      - FELIX_DISABLE_TIMINGS=false\n      - FELIX_BINARY_SINGLE_EVENT=false\n\n      # Logging\n      - RUST_LOG=info\n</code></pre>"},{"location":"deployment/docker-compose/#config-file-mount","title":"Config File Mount","text":"<p>Use a YAML config file instead:</p> <p><code>config/broker.yml</code>:</p> <pre><code>quic_bind: \"0.0.0.0:5000\"\nmetrics_bind: \"0.0.0.0:8080\"\nevent_batch_max_events: 64\nevent_batch_max_delay_us: 250\ncache_conn_recv_window: 268435456\n</code></pre> <p>Mount in Compose:</p> <pre><code>services:\n  felix-broker:\n    volumes:\n      - ./config/broker.yml:/etc/felix/broker.yml:ro\n    environment:\n      - FELIX_BROKER_CONFIG=/etc/felix/broker.yml\n</code></pre>"},{"location":"deployment/docker-compose/#multi-broker-setup","title":"Multi-Broker Setup","text":"<p>Deploy multiple broker instances for testing clustering behavior:</p> <pre><code>version: '3.8'\n\nservices:\n  felix-broker-1:\n    image: felix/broker:latest\n    build:\n      context: .\n      dockerfile: docker/broker.Dockerfile\n    ports:\n      - \"5001:5000/udp\"\n      - \"8081:8080\"\n    environment:\n      - FELIX_QUIC_BIND=0.0.0.0:5000\n      - FELIX_BROKER_METRICS_BIND=0.0.0.0:8080\n      - RUST_LOG=info\n    hostname: broker-1\n    networks:\n      - felix-net\n\n  felix-broker-2:\n    image: felix/broker:latest\n    ports:\n      - \"5002:5000/udp\"\n      - \"8082:8080\"\n    environment:\n      - FELIX_QUIC_BIND=0.0.0.0:5000\n      - FELIX_BROKER_METRICS_BIND=0.0.0.0:8080\n      - RUST_LOG=info\n    hostname: broker-2\n    networks:\n      - felix-net\n\n  felix-broker-3:\n    image: felix/broker:latest\n    ports:\n      - \"5003:5000/udp\"\n      - \"8083:8080\"\n    environment:\n      - FELIX_QUIC_BIND=0.0.0.0:5000\n      - FELIX_BROKER_METRICS_BIND=0.0.0.0:8080\n      - RUST_LOG=info\n    hostname: broker-3\n    networks:\n      - felix-net\n\nnetworks:\n  felix-net:\n    driver: bridge\n</code></pre> <p>Access each broker:</p> <pre><code># Broker 1\ncurl http://localhost:8081/healthz\n\n# Broker 2\ncurl http://localhost:8082/healthz\n\n# Broker 3\ncurl http://localhost:8083/healthz\n</code></pre>"},{"location":"deployment/docker-compose/#building-images","title":"Building Images","text":""},{"location":"deployment/docker-compose/#building-locally","title":"Building Locally","text":"<p>Build the broker image from source:</p> <pre><code># Build with default settings\ndocker compose build\n\n# Build with specific profile\ndocker compose build --build-arg PROFILE=release\n\n# Build with telemetry enabled\ndocker compose build --build-arg CARGO_FEATURES=\"--features telemetry\"\n\n# Build with custom RUSTFLAGS\ndocker compose build --build-arg RUSTFLAGS=\"-C target-cpu=native\"\n</code></pre>"},{"location":"deployment/docker-compose/#using-pre-built-images","title":"Using Pre-built Images","text":"<p>When official images are available:</p> <pre><code>services:\n  felix-broker:\n    image: ghcr.io/gabloe/felix-broker:latest\n    # Or specific version\n    # image: ghcr.io/gabloe/felix-broker:v0.1.0\n</code></pre>"},{"location":"deployment/docker-compose/#persistence-and-volumes","title":"Persistence and Volumes","text":""},{"location":"deployment/docker-compose/#data-persistence","title":"Data Persistence","text":"<p>Store broker data on persistent volumes:</p> <pre><code>services:\n  felix-broker:\n    volumes:\n      - felix-data:/data\n      - felix-logs:/var/log/felix\n\nvolumes:\n  felix-data:\n    driver: local\n    driver_opts:\n      type: none\n      o: bind\n      device: /path/to/host/data\n\n  felix-logs:\n    driver: local\n</code></pre>"},{"location":"deployment/docker-compose/#backup-strategy","title":"Backup Strategy","text":"<pre><code># Backup volume data\ndocker run --rm -v felix-data:/data -v $(pwd):/backup \\\n  alpine tar czf /backup/felix-data-backup.tar.gz -C /data .\n\n# Restore from backup\ndocker run --rm -v felix-data:/data -v $(pwd):/backup \\\n  alpine tar xzf /backup/felix-data-backup.tar.gz -C /data\n</code></pre>"},{"location":"deployment/docker-compose/#networking","title":"Networking","text":""},{"location":"deployment/docker-compose/#bridge-network-default","title":"Bridge Network (Default)","text":"<p>Services communicate via internal network:</p> <pre><code>networks:\n  felix-net:\n    driver: bridge\n    ipam:\n      config:\n        - subnet: 172.28.0.0/16\n</code></pre>"},{"location":"deployment/docker-compose/#host-network","title":"Host Network","text":"<p>Use host networking for better performance:</p> <pre><code>services:\n  felix-broker:\n    network_mode: host\n    environment:\n      - FELIX_QUIC_BIND=0.0.0.0:5000\n</code></pre> <p>Host Networking Limitations</p> <p>Host networking doesn't work on Docker Desktop for Mac/Windows. Use bridge networking or run on Linux.</p>"},{"location":"deployment/docker-compose/#resource-limits","title":"Resource Limits","text":"<p>Constrain resource usage:</p> <pre><code>services:\n  felix-broker:\n    deploy:\n      resources:\n        limits:\n          cpus: '4'\n          memory: 4G\n        reservations:\n          cpus: '2'\n          memory: 2G\n    ulimits:\n      nofile:\n        soft: 65536\n        hard: 65536\n</code></pre>"},{"location":"deployment/docker-compose/#health-checks","title":"Health Checks","text":"<p>Configure health checks for automatic restart:</p> <pre><code>services:\n  felix-broker:\n    healthcheck:\n      test: [\"CMD\", \"wget\", \"-qO-\", \"http://localhost:8080/healthz\"]\n      interval: 10s\n      timeout: 2s\n      retries: 3\n      start_period: 10s\n</code></pre>"},{"location":"deployment/docker-compose/#common-operations","title":"Common Operations","text":""},{"location":"deployment/docker-compose/#starting-services","title":"Starting Services","text":"<pre><code># Start all services\ndocker compose up -d\n\n# Start specific service\ndocker compose up -d felix-broker\n\n# Start with rebuild\ndocker compose up -d --build\n</code></pre>"},{"location":"deployment/docker-compose/#stopping-services","title":"Stopping Services","text":"<pre><code># Stop all services\ndocker compose stop\n\n# Stop specific service\ndocker compose stop felix-broker\n\n# Stop and remove containers\ndocker compose down\n\n# Stop and remove volumes\ndocker compose down -v\n</code></pre>"},{"location":"deployment/docker-compose/#viewing-logs","title":"Viewing Logs","text":"<pre><code># All services\ndocker compose logs -f\n\n# Specific service\ndocker compose logs -f felix-broker\n\n# Last 100 lines\ndocker compose logs --tail=100 felix-broker\n</code></pre>"},{"location":"deployment/docker-compose/#scaling-services","title":"Scaling Services","text":"<pre><code># Run 3 broker instances\ndocker compose up -d --scale felix-broker=3\n\n# Note: You'll need to configure dynamic ports\n</code></pre>"},{"location":"deployment/docker-compose/#executing-commands","title":"Executing Commands","text":"<pre><code># Shell into container\ndocker compose exec felix-broker /bin/sh\n\n# Run one-off command\ndocker compose exec felix-broker ls -la /data\n</code></pre>"},{"location":"deployment/docker-compose/#development-workflow","title":"Development Workflow","text":""},{"location":"deployment/docker-compose/#live-reloading-setup","title":"Live Reloading Setup","text":"<p>For development with live code updates:</p> <pre><code>services:\n  felix-broker:\n    build:\n      context: .\n      dockerfile: docker/broker.Dockerfile\n      target: builder  # Stop at build stage\n    volumes:\n      - .:/src\n      - cargo-cache:/usr/local/cargo/registry\n    command: cargo watch -x 'run --release -p broker'\n\nvolumes:\n  cargo-cache:\n</code></pre>"},{"location":"deployment/docker-compose/#running-tests-in-docker","title":"Running Tests in Docker","text":"<pre><code># Run tests\ndocker compose run --rm felix-broker cargo test --workspace\n\n# Run specific test\ndocker compose run --rm felix-broker cargo test test_name\n\n# Run with output\ndocker compose run --rm felix-broker cargo test -- --nocapture\n</code></pre>"},{"location":"deployment/docker-compose/#monitoring-and-debugging","title":"Monitoring and Debugging","text":""},{"location":"deployment/docker-compose/#prometheus-queries","title":"Prometheus Queries","text":"<p>Access Prometheus UI at <code>http://localhost:9090</code>:</p> <pre><code># Request rate\nrate(felix_broker_requests_total[1m])\n\n# Error rate\nrate(felix_broker_errors_total[1m])\n\n# Latency p99\nhistogram_quantile(0.99, rate(felix_broker_request_duration_seconds_bucket[5m]))\n</code></pre>"},{"location":"deployment/docker-compose/#container-metrics","title":"Container Metrics","text":"<pre><code># Container stats\ndocker compose stats\n\n# Inspect container\ndocker compose inspect felix-broker\n\n# View container processes\ndocker compose top felix-broker\n</code></pre>"},{"location":"deployment/docker-compose/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/docker-compose/#container-wont-start","title":"Container Won't Start","text":"<pre><code># Check logs\ndocker compose logs felix-broker\n\n# Check exit code\ndocker compose ps felix-broker\n\n# Run interactively\ndocker compose run --rm felix-broker /bin/sh\n</code></pre>"},{"location":"deployment/docker-compose/#port-conflicts","title":"Port Conflicts","text":"<p>Error: <code>port is already allocated</code></p> <p>Solution:</p> <pre><code>ports:\n  - \"5001:5000/udp\"  # Change host port\n  - \"8081:8080\"\n</code></pre>"},{"location":"deployment/docker-compose/#build-failures","title":"Build Failures","text":"<pre><code># Clean build cache\ndocker compose build --no-cache\n\n# Remove old images\ndocker image prune -a\n\n# Check Dockerfile\ndocker compose config\n</code></pre>"},{"location":"deployment/docker-compose/#connection-issues","title":"Connection Issues","text":"<pre><code># Check network\ndocker network inspect felix_felix-net\n\n# Test connectivity between services\ndocker compose exec felix-broker ping prometheus\n\n# Check DNS resolution\ndocker compose exec felix-broker nslookup felix-broker\n</code></pre>"},{"location":"deployment/docker-compose/#performance-issues","title":"Performance Issues","text":"<pre><code># Check resource usage\ndocker compose stats\n\n# Increase resources in docker-compose.yml\ndeploy:\n  resources:\n    limits:\n      memory: 8G\n\n# Use host networking\nnetwork_mode: host\n</code></pre>"},{"location":"deployment/docker-compose/#next-steps","title":"Next Steps","text":"<ul> <li>Production deployment: Kubernetes Guide</li> <li>Performance tuning: Performance Guide</li> <li>Full configuration reference: Configuration Reference</li> <li>Monitoring setup: Observability Guide</li> </ul>"},{"location":"deployment/kubernetes/","title":"Kubernetes Deployment","text":"<p>This guide covers deploying Felix on Kubernetes with high availability, persistence, and production-grade configurations.</p>"},{"location":"deployment/kubernetes/#overview","title":"Overview","text":"<p>Felix is designed as a Kubernetes-native system. This guide demonstrates:</p> <ul> <li>StatefulSet deployment for stable network identity</li> <li>Headless Services for direct broker addressing</li> <li>Persistent storage with StatefulSet volumes</li> <li>Resource management and limits</li> <li>Health checks and readiness probes</li> <li>Horizontal scaling for high availability</li> </ul> <p>Kubernetes Version</p> <p>Felix requires Kubernetes 1.24 or later. Tested on 1.27+.</p>"},{"location":"deployment/kubernetes/#prerequisites","title":"Prerequisites","text":"<ul> <li>Kubernetes cluster: 1.24+ (Minikube, kind, GKE, EKS, AKS, etc.)</li> <li>kubectl: Configured to access your cluster</li> <li>Storage provisioner: For persistent volumes (e.g., <code>gp3</code> on AWS, <code>pd-ssd</code> on GCP)</li> <li>4GB RAM per broker pod: Minimum recommended</li> </ul>"},{"location":"deployment/kubernetes/#verify-cluster-access","title":"Verify Cluster Access","text":"<pre><code>kubectl cluster-info\nkubectl get nodes\n</code></pre>"},{"location":"deployment/kubernetes/#quick-start","title":"Quick Start","text":""},{"location":"deployment/kubernetes/#basic-deployment","title":"Basic Deployment","text":"<p>Deploy a single Felix broker:</p> <pre><code># Create namespace\nkubectl create namespace felix\n\n# Apply manifests\nkubectl apply -f deploy/kubernetes/broker.yaml -n felix\n\n# Check status\nkubectl get pods -n felix\nkubectl logs -f deployment/felix-broker -n felix\n</code></pre> <p>Minimal broker deployment (<code>deploy/kubernetes/broker.yaml</code>):</p> <pre><code>apiVersion: v1\nkind: Namespace\nmetadata:\n  name: felix\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: felix-broker\n  namespace: felix\n  labels:\n    app: felix-broker\nspec:\n  type: ClusterIP\n  ports:\n    - port: 5000\n      targetPort: 5000\n      protocol: UDP\n      name: quic\n    - port: 8080\n      targetPort: 8080\n      protocol: TCP\n      name: metrics\n  selector:\n    app: felix-broker\n\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: felix-broker\n  namespace: felix\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: felix-broker\n  template:\n    metadata:\n      labels:\n        app: felix-broker\n    spec:\n      containers:\n      - name: broker\n        image: felix/broker:latest\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 5000\n          protocol: UDP\n          name: quic\n        - containerPort: 8080\n          protocol: TCP\n          name: metrics\n        env:\n        - name: FELIX_QUIC_BIND\n          value: \"0.0.0.0:5000\"\n        - name: FELIX_BROKER_METRICS_BIND\n          value: \"0.0.0.0:8080\"\n        - name: RUST_LOG\n          value: \"info\"\n        resources:\n          requests:\n            memory: \"2Gi\"\n            cpu: \"1000m\"\n          limits:\n            memory: \"4Gi\"\n            cpu: \"2000m\"\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 5\n</code></pre>"},{"location":"deployment/kubernetes/#statefulset-deployment","title":"StatefulSet Deployment","text":"<p>For production, use StatefulSets for stable network identity and persistent storage:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: felix-broker-headless\n  namespace: felix\n  labels:\n    app: felix-broker\nspec:\n  clusterIP: None\n  ports:\n    - port: 5000\n      protocol: UDP\n      name: quic\n    - port: 8080\n      protocol: TCP\n      name: metrics\n  selector:\n    app: felix-broker\n\n---\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: felix-broker\n  namespace: felix\nspec:\n  serviceName: felix-broker-headless\n  replicas: 3\n  selector:\n    matchLabels:\n      app: felix-broker\n  template:\n    metadata:\n      labels:\n        app: felix-broker\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"8080\"\n        prometheus.io/path: \"/metrics\"\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - felix-broker\n              topologyKey: kubernetes.io/hostname\n      containers:\n      - name: broker\n        image: felix/broker:latest\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 5000\n          protocol: UDP\n          name: quic\n        - containerPort: 8080\n          protocol: TCP\n          name: metrics\n        env:\n        - name: FELIX_QUIC_BIND\n          value: \"0.0.0.0:5000\"\n        - name: FELIX_BROKER_METRICS_BIND\n          value: \"0.0.0.0:8080\"\n        - name: FELIX_EVENT_BATCH_MAX_EVENTS\n          value: \"64\"\n        - name: FELIX_EVENT_BATCH_MAX_DELAY_US\n          value: \"250\"\n        - name: FELIX_CACHE_CONN_POOL\n          value: \"8\"\n        - name: FELIX_CACHE_STREAMS_PER_CONN\n          value: \"4\"\n        - name: FELIX_DISABLE_TIMINGS\n          value: \"false\"\n        - name: RUST_LOG\n          value: \"info\"\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        resources:\n          requests:\n            memory: \"2Gi\"\n            cpu: \"1000m\"\n          limits:\n            memory: \"4Gi\"\n            cpu: \"2000m\"\n        volumeMounts:\n        - name: data\n          mountPath: /data\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 15\n          periodSeconds: 10\n          timeoutSeconds: 2\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          timeoutSeconds: 2\n          failureThreshold: 3\n        lifecycle:\n          preStop:\n            exec:\n              command: [\"/bin/sh\", \"-c\", \"sleep 15\"]\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n    spec:\n      accessModes: [\"ReadWriteOnce\"]\n      storageClassName: fast-ssd\n      resources:\n        requests:\n          storage: 50Gi\n</code></pre> <p>Deploy:</p> <pre><code>kubectl apply -f statefulset.yaml\nkubectl get statefulset -n felix\nkubectl get pods -n felix -l app=felix-broker\n</code></pre>"},{"location":"deployment/kubernetes/#configuration-management","title":"Configuration Management","text":""},{"location":"deployment/kubernetes/#configmap-for-settings","title":"ConfigMap for Settings","text":"<p>Externalize configuration:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: felix-broker-config\n  namespace: felix\ndata:\n  broker.yml: |\n    quic_bind: \"0.0.0.0:5000\"\n    metrics_bind: \"0.0.0.0:8080\"\n    event_batch_max_events: 64\n    event_batch_max_delay_us: 250\n    event_batch_max_bytes: 262144\n    fanout_batch_size: 64\n    cache_conn_recv_window: 268435456\n    cache_stream_recv_window: 67108864\n    cache_send_window: 268435456\n    pub_workers_per_conn: 4\n    pub_queue_depth: 1024\n    event_queue_depth: 1024\n    disable_timings: false\n\n---\n# Mount in StatefulSet\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: felix-broker\n  namespace: felix\nspec:\n  template:\n    spec:\n      containers:\n      - name: broker\n        env:\n        - name: FELIX_BROKER_CONFIG\n          value: /etc/felix/broker.yml\n        volumeMounts:\n        - name: config\n          mountPath: /etc/felix\n          readOnly: true\n      volumes:\n      - name: config\n        configMap:\n          name: felix-broker-config\n</code></pre>"},{"location":"deployment/kubernetes/#secrets-for-sensitive-data","title":"Secrets for Sensitive Data","text":"<p>Store credentials securely:</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: felix-broker-secrets\n  namespace: felix\ntype: Opaque\nstringData:\n  tls-cert.pem: |\n    -----BEGIN CERTIFICATE-----\n    ...\n    -----END CERTIFICATE-----\n  tls-key.pem: |\n    -----BEGIN PRIVATE KEY-----\n    ...\n    -----END PRIVATE KEY-----\n\n---\n# Mount in StatefulSet\nvolumeMounts:\n- name: tls-certs\n  mountPath: /etc/felix/tls\n  readOnly: true\n\nvolumes:\n- name: tls-certs\n  secret:\n    secretName: felix-broker-secrets\n</code></pre>"},{"location":"deployment/kubernetes/#storage-configuration","title":"Storage Configuration","text":""},{"location":"deployment/kubernetes/#storageclass-for-high-performance","title":"StorageClass for High Performance","text":"<p>Create optimized storage class:</p> <pre><code># AWS EBS gp3 with provisioned IOPS\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: felix-fast-ssd\nprovisioner: ebs.csi.aws.com\nparameters:\n  type: gp3\n  iops: \"3000\"\n  throughput: \"125\"\n  fsType: ext4\nvolumeBindingMode: WaitForFirstConsumer\nallowVolumeExpansion: true\n\n---\n# GCP persistent disk SSD\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: felix-fast-ssd\nprovisioner: pd.csi.storage.gke.io\nparameters:\n  type: pd-ssd\n  replication-type: regional-pd\nvolumeBindingMode: WaitForFirstConsumer\nallowVolumeExpansion: true\n</code></pre>"},{"location":"deployment/kubernetes/#persistentvolumeclaim-templates","title":"PersistentVolumeClaim Templates","text":"<p>Define storage requirements in StatefulSet:</p> <pre><code>volumeClaimTemplates:\n- metadata:\n    name: data\n    labels:\n      app: felix-broker\n  spec:\n    accessModes: [\"ReadWriteOnce\"]\n    storageClassName: felix-fast-ssd\n    resources:\n      requests:\n        storage: 100Gi\n</code></pre>"},{"location":"deployment/kubernetes/#networking","title":"Networking","text":""},{"location":"deployment/kubernetes/#service-for-external-access","title":"Service for External Access","text":"<p>Expose broker externally:</p> <pre><code># LoadBalancer (cloud providers)\napiVersion: v1\nkind: Service\nmetadata:\n  name: felix-broker-external\n  namespace: felix\n  annotations:\n    service.beta.kubernetes.io/aws-load-balancer-type: \"nlb\"\nspec:\n  type: LoadBalancer\n  ports:\n    - port: 5000\n      targetPort: 5000\n      protocol: UDP\n      name: quic\n  selector:\n    app: felix-broker\n\n---\n# NodePort (bare metal)\napiVersion: v1\nkind: Service\nmetadata:\n  name: felix-broker-nodeport\n  namespace: felix\nspec:\n  type: NodePort\n  ports:\n    - port: 5000\n      targetPort: 5000\n      nodePort: 30500\n      protocol: UDP\n      name: quic\n  selector:\n    app: felix-broker\n</code></pre>"},{"location":"deployment/kubernetes/#ingress-for-http-metrics","title":"Ingress for HTTP Metrics","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: felix-metrics\n  namespace: felix\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: felix-metrics.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: felix-broker\n            port:\n              number: 8080\n</code></pre>"},{"location":"deployment/kubernetes/#high-availability-setup","title":"High Availability Setup","text":""},{"location":"deployment/kubernetes/#multi-zone-deployment","title":"Multi-Zone Deployment","text":"<pre><code>apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: felix-broker\n  namespace: felix\nspec:\n  replicas: 3\n  template:\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - felix-broker\n            topologyKey: topology.kubernetes.io/zone\n      topologySpreadConstraints:\n      - maxSkew: 1\n        topologyKey: topology.kubernetes.io/zone\n        whenUnsatisfiable: DoNotSchedule\n        labelSelector:\n          matchLabels:\n            app: felix-broker\n</code></pre>"},{"location":"deployment/kubernetes/#pod-disruption-budget","title":"Pod Disruption Budget","text":"<p>Protect against voluntary disruptions:</p> <pre><code>apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: felix-broker-pdb\n  namespace: felix\nspec:\n  minAvailable: 2\n  selector:\n    matchLabels:\n      app: felix-broker\n</code></pre>"},{"location":"deployment/kubernetes/#horizontalpodautoscaler","title":"HorizontalPodAutoscaler","text":"<p>Scale based on metrics:</p> <pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: felix-broker-hpa\n  namespace: felix\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: StatefulSet\n    name: felix-broker\n  minReplicas: 3\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n</code></pre>"},{"location":"deployment/kubernetes/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"deployment/kubernetes/#servicemonitor-for-prometheus","title":"ServiceMonitor for Prometheus","text":"<pre><code>apiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: felix-broker\n  namespace: felix\n  labels:\n    app: felix-broker\nspec:\n  selector:\n    matchLabels:\n      app: felix-broker\n  endpoints:\n  - port: metrics\n    interval: 15s\n    path: /metrics\n</code></pre>"},{"location":"deployment/kubernetes/#grafana-dashboard-configmap","title":"Grafana Dashboard ConfigMap","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: felix-dashboard\n  namespace: monitoring\n  labels:\n    grafana_dashboard: \"1\"\ndata:\n  felix-overview.json: |\n    {\n      \"dashboard\": {\n        \"title\": \"Felix Broker Overview\",\n        \"panels\": [...]\n      }\n    }\n</code></pre>"},{"location":"deployment/kubernetes/#resource-management","title":"Resource Management","text":""},{"location":"deployment/kubernetes/#quality-of-service-classes","title":"Quality of Service Classes","text":"<p>Guaranteed QoS (production):</p> <pre><code>resources:\n  requests:\n    memory: \"4Gi\"\n    cpu: \"2000m\"\n  limits:\n    memory: \"4Gi\"\n    cpu: \"2000m\"\n</code></pre> <p>Burstable QoS (development):</p> <pre><code>resources:\n  requests:\n    memory: \"2Gi\"\n    cpu: \"1000m\"\n  limits:\n    memory: \"4Gi\"\n    cpu: \"2000m\"\n</code></pre>"},{"location":"deployment/kubernetes/#resource-quotas","title":"Resource Quotas","text":"<p>Limit namespace resources:</p> <pre><code>apiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: felix-quota\n  namespace: felix\nspec:\n  hard:\n    requests.cpu: \"20\"\n    requests.memory: \"40Gi\"\n    limits.cpu: \"40\"\n    limits.memory: \"80Gi\"\n    persistentvolumeclaims: \"10\"\n</code></pre>"},{"location":"deployment/kubernetes/#limitrange","title":"LimitRange","text":"<p>Set default resource limits:</p> <pre><code>apiVersion: v1\nkind: LimitRange\nmetadata:\n  name: felix-limits\n  namespace: felix\nspec:\n  limits:\n  - type: Container\n    default:\n      cpu: \"2000m\"\n      memory: \"4Gi\"\n    defaultRequest:\n      cpu: \"1000m\"\n      memory: \"2Gi\"\n    max:\n      cpu: \"4000m\"\n      memory: \"8Gi\"\n    min:\n      cpu: \"500m\"\n      memory: \"1Gi\"\n</code></pre>"},{"location":"deployment/kubernetes/#security","title":"Security","text":""},{"location":"deployment/kubernetes/#network-policies","title":"Network Policies","text":"<p>Restrict network access:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: felix-broker-netpol\n  namespace: felix\nspec:\n  podSelector:\n    matchLabels:\n      app: felix-broker\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: felix-clients\n    ports:\n    - protocol: UDP\n      port: 5000\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: monitoring\n    ports:\n    - protocol: TCP\n      port: 8080\n  egress:\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: felix-controlplane\n    ports:\n    - protocol: TCP\n      port: 8443\n  - to:\n    - podSelector: {}\n</code></pre>"},{"location":"deployment/kubernetes/#pod-security-standards","title":"Pod Security Standards","text":"<pre><code>apiVersion: v1\nkind: Namespace\nmetadata:\n  name: felix\n  labels:\n    pod-security.kubernetes.io/enforce: baseline\n    pod-security.kubernetes.io/audit: restricted\n    pod-security.kubernetes.io/warn: restricted\n</code></pre>"},{"location":"deployment/kubernetes/#security-context","title":"Security Context","text":"<pre><code>spec:\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 10001\n    fsGroup: 10001\n    seccompProfile:\n      type: RuntimeDefault\n  containers:\n  - name: broker\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      capabilities:\n        drop:\n        - ALL\n</code></pre>"},{"location":"deployment/kubernetes/#operations","title":"Operations","text":""},{"location":"deployment/kubernetes/#scaling","title":"Scaling","text":"<pre><code># Scale StatefulSet\nkubectl scale statefulset felix-broker --replicas=5 -n felix\n\n# Check scaling progress\nkubectl rollout status statefulset/felix-broker -n felix\n</code></pre>"},{"location":"deployment/kubernetes/#rolling-updates","title":"Rolling Updates","text":"<pre><code># Update image\nkubectl set image statefulset/felix-broker \\\n  broker=felix/broker:v0.2.0 -n felix\n\n# Watch rollout\nkubectl rollout status statefulset/felix-broker -n felix\n\n# Rollback if needed\nkubectl rollout undo statefulset/felix-broker -n felix\n</code></pre>"},{"location":"deployment/kubernetes/#debugging","title":"Debugging","text":"<pre><code># View logs\nkubectl logs -f felix-broker-0 -n felix\n\n# Shell into pod\nkubectl exec -it felix-broker-0 -n felix -- /bin/sh\n\n# Port forward for local access\nkubectl port-forward felix-broker-0 5000:5000 8080:8080 -n felix\n\n# Check events\nkubectl get events -n felix --sort-by='.lastTimestamp'\n\n# Describe pod\nkubectl describe pod felix-broker-0 -n felix\n</code></pre>"},{"location":"deployment/kubernetes/#backup-and-recovery","title":"Backup and Recovery","text":"<pre><code># Backup PVC data\nkubectl exec felix-broker-0 -n felix -- tar czf - /data &gt; backup.tar.gz\n\n# List PVCs\nkubectl get pvc -n felix\n\n# Restore from backup\ncat backup.tar.gz | kubectl exec -i felix-broker-0 -n felix -- tar xzf - -C /\n</code></pre>"},{"location":"deployment/kubernetes/#complete-production-example","title":"Complete Production Example","text":"<p>Full production-ready manifest:</p> <pre><code># Clone repository\ngit clone https://github.com/gabloe/felix.git\ncd felix/deploy/kubernetes\n\n# Review and customize\n$EDITOR production/values.yaml\n\n# Apply with kustomize\nkubectl apply -k production/\n\n# Or use Helm (when available)\nhelm install felix ./charts/felix -n felix --create-namespace\n</code></pre>"},{"location":"deployment/kubernetes/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/kubernetes/#pod-stuck-in-pending","title":"Pod Stuck in Pending","text":"<pre><code>kubectl describe pod felix-broker-0 -n felix\n# Check for: insufficient resources, PVC binding, node affinity\n</code></pre>"},{"location":"deployment/kubernetes/#crashloopbackoff","title":"CrashLoopBackOff","text":"<pre><code>kubectl logs felix-broker-0 -n felix --previous\n# Check for: config errors, port conflicts, resource limits\n</code></pre>"},{"location":"deployment/kubernetes/#service-not-reachable","title":"Service Not Reachable","text":"<pre><code># Test from within cluster\nkubectl run -it --rm debug --image=busybox --restart=Never -n felix -- sh\nnc -zvu felix-broker-headless 5000\n</code></pre>"},{"location":"deployment/kubernetes/#high-memory-usage","title":"High Memory Usage","text":"<pre><code># Check metrics\nkubectl top pods -n felix\n\n# Adjust resource limits\nkubectl set resources statefulset felix-broker \\\n  --limits=memory=8Gi -n felix\n</code></pre>"},{"location":"deployment/kubernetes/#next-steps","title":"Next Steps","text":"<ul> <li>Monitor deployment: Observability Guide</li> <li>Tune performance: Performance Guide</li> <li>Configure fully: Configuration Reference</li> <li>Secure deployment: Security Guide</li> </ul>"},{"location":"deployment/local/","title":"Local Development Deployment","text":"<p>This guide walks you through setting up Felix for local development, running the broker on your machine, and configuring it for different development scenarios.</p>"},{"location":"deployment/local/#prerequisites","title":"Prerequisites","text":"<p>Before running Felix locally, ensure you have:</p> <ul> <li>Rust 1.92.0 or later: Install via rustup</li> <li>Git: For cloning the repository</li> <li>Optional: Task for convenience commands</li> <li>At least 4GB RAM: Recommended for comfortable development</li> <li>Ports available: Default ports 5000 (QUIC) and 8080 (metrics)</li> </ul>"},{"location":"deployment/local/#quick-start","title":"Quick Start","text":""},{"location":"deployment/local/#clone-and-build","title":"Clone and Build","text":"<pre><code># Clone the repository\ngit clone https://github.com/gabloe/felix.git\ncd felix\n\n# Build the workspace in release mode\ncargo build --workspace --release\n</code></pre> <p>Release vs Debug Builds</p> <p>Always use release builds (<code>--release</code>) for performance testing. Debug builds have significantly higher overhead and can show 10-100x worse latency characteristics. Use debug builds only for debugging with tools like <code>gdb</code> or <code>lldb</code>.</p>"},{"location":"deployment/local/#start-the-broker","title":"Start the Broker","text":"<p>Run the broker with default settings:</p> <pre><code>cargo run --release -p broker\n</code></pre> <p>Expected output:</p> <pre><code>2026-01-25T10:00:00.000Z INFO felix_broker: Starting Felix broker\n2026-01-25T10:00:00.001Z INFO felix_broker: QUIC listening on 0.0.0.0:5000\n2026-01-25T10:00:00.001Z INFO felix_broker: Metrics server on 0.0.0.0:8080\n</code></pre> <p>The broker is now accepting connections on:</p> <ul> <li>QUIC data plane: <code>0.0.0.0:5000</code> (UDP)</li> <li>Metrics/health HTTP: <code>0.0.0.0:8080</code> (TCP)</li> </ul>"},{"location":"deployment/local/#verify-the-broker","title":"Verify the Broker","text":"<p>Check that the broker is running:</p> <pre><code># Check QUIC listener (requires lsof or ss)\nlsof -i UDP:5000\n\n# Check metrics endpoint\ncurl http://localhost:8080/healthz\n</code></pre>"},{"location":"deployment/local/#configuration-methods","title":"Configuration Methods","text":"<p>Felix supports three configuration methods, applied in this order (later sources override earlier ones):</p> <ol> <li>Built-in defaults: Sensible defaults for local development</li> <li>Environment variables: Quick overrides via <code>FELIX_*</code> variables</li> <li>YAML config file: Structured configuration for complex setups</li> </ol>"},{"location":"deployment/local/#using-environment-variables","title":"Using Environment Variables","text":"<p>The simplest way to configure Felix locally:</p> <pre><code># Change broker ports\nexport FELIX_QUIC_BIND=\"0.0.0.0:5001\"\nexport FELIX_BROKER_METRICS_BIND=\"0.0.0.0:8081\"\n\n# Enable publish acknowledgements\nexport FELIX_ACK_ON_COMMIT=\"true\"\n\n# Tune batching for lower latency\nexport FELIX_EVENT_BATCH_MAX_DELAY_US=\"100\"\n\n# Run broker with custom config\ncargo run --release -p broker\n</code></pre>"},{"location":"deployment/local/#using-a-config-file","title":"Using a Config File","text":"<p>For more complex configurations, create a YAML file:</p> <p><code>/tmp/felix-dev.yml</code>:</p> <pre><code># Network bindings\nquic_bind: \"0.0.0.0:5000\"\nmetrics_bind: \"0.0.0.0:8080\"\n\n# Optional control plane\ncontrolplane_url: \"http://localhost:8443\"\ncontrolplane_sync_interval_ms: 2000\n\n# Publishing behavior\nack_on_commit: false\nmax_frame_bytes: 16777216  # 16 MiB\n\n# Timeouts\npublish_queue_wait_timeout_ms: 2000\nack_wait_timeout_ms: 2000\ncontrol_stream_drain_timeout_ms: 50\n\n# Cache flow control\ncache_conn_recv_window: 268435456  # 256 MiB\ncache_stream_recv_window: 67108864 # 64 MiB\ncache_send_window: 268435456       # 256 MiB\n\n# Event batching\nevent_batch_max_events: 64\nevent_batch_max_bytes: 262144      # 256 KiB\nevent_batch_max_delay_us: 250\n\n# Fanout and workers\nfanout_batch_size: 64\npub_workers_per_conn: 4\npub_queue_depth: 1024\nevent_queue_depth: 1024\n\n# Binary encoding for single events\nevent_single_binary_enabled: false\nevent_single_binary_min_bytes: 512\n\n# Performance\ndisable_timings: false\n</code></pre> <p>Run with custom config:</p> <pre><code>FELIX_BROKER_CONFIG=/tmp/felix-dev.yml cargo run --release -p broker\n</code></pre> <p>Config File Priority</p> <p>If <code>FELIX_BROKER_CONFIG</code> is set and the file doesn't exist, the broker will fail to start. Without this variable, the broker looks for <code>/usr/local/felix/config.yml</code> but continues with defaults if not found.</p>"},{"location":"deployment/local/#common-development-scenarios","title":"Common Development Scenarios","text":""},{"location":"deployment/local/#scenario-1-low-latency-testing","title":"Scenario 1: Low-Latency Testing","text":"<p>Optimize for minimum latency (single subscriber, small batches):</p> <pre><code>export FELIX_EVENT_BATCH_MAX_DELAY_US=\"50\"\nexport FELIX_EVENT_BATCH_MAX_EVENTS=\"1\"\nexport FELIX_FANOUT_BATCH=\"1\"\nexport FELIX_DISABLE_TIMINGS=\"1\"\n\ncargo run --release -p broker\n</code></pre>"},{"location":"deployment/local/#scenario-2-high-throughput-testing","title":"Scenario 2: High-Throughput Testing","text":"<p>Optimize for maximum throughput (large batches, higher fanout):</p> <pre><code>export FELIX_EVENT_BATCH_MAX_DELAY_US=\"1000\"\nexport FELIX_EVENT_BATCH_MAX_EVENTS=\"256\"\nexport FELIX_EVENT_BATCH_MAX_BYTES=\"1048576\"  # 1 MiB\nexport FELIX_FANOUT_BATCH=\"128\"\nexport FELIX_BINARY_SINGLE_EVENT=\"true\"\n\ncargo run --release -p broker\n</code></pre>"},{"location":"deployment/local/#scenario-3-multi-client-development","title":"Scenario 3: Multi-Client Development","text":"<p>Run multiple clients connecting to the same broker:</p> <pre><code># Terminal 1: Start broker\ncargo run --release -p broker\n\n# Terminal 2: Run subscriber demo\ncargo run --release -p broker --bin pubsubdemo\n\n# Terminal 3: Run another client\ncargo run --release -p broker --bin cachedemo\n</code></pre>"},{"location":"deployment/local/#scenario-4-testing-control-plane-integration","title":"Scenario 4: Testing Control Plane Integration","text":"<p>Set up broker to connect to a local control plane:</p> <pre><code>export FELIX_CP_URL=\"http://localhost:8443\"\nexport FELIX_CP_SYNC_INTERVAL_MS=\"1000\"\n\ncargo run --release -p broker\n</code></pre>"},{"location":"deployment/local/#performance-profiles","title":"Performance Profiles","text":"<p>Felix includes pre-tuned performance profiles for different use cases:</p>"},{"location":"deployment/local/#balanced-profile-default","title":"Balanced Profile (Default)","text":"<p>Good starting point for mixed workloads:</p> <pre><code>export FELIX_EVENT_CONN_POOL=\"8\"\nexport FELIX_EVENT_CONN_RECV_WINDOW=\"268435456\"\nexport FELIX_EVENT_STREAM_RECV_WINDOW=\"67108864\"\nexport FELIX_EVENT_SEND_WINDOW=\"268435456\"\nexport FELIX_EVENT_BATCH_MAX_DELAY_US=\"250\"\nexport FELIX_CACHE_CONN_POOL=\"8\"\nexport FELIX_CACHE_STREAMS_PER_CONN=\"4\"\n\ncargo run --release -p broker\n</code></pre>"},{"location":"deployment/local/#high-memory-profile","title":"High-Memory Profile","text":"<p>For burst tolerance with more memory:</p> <pre><code>export FELIX_EVENT_CONN_POOL=\"8\"\nexport FELIX_EVENT_CONN_RECV_WINDOW=\"536870912\"   # 512 MiB\nexport FELIX_EVENT_STREAM_RECV_WINDOW=\"134217728\"  # 128 MiB\nexport FELIX_EVENT_SEND_WINDOW=\"536870912\"         # 512 MiB\nexport FELIX_EVENT_BATCH_MAX_DELAY_US=\"250\"\nexport FELIX_CACHE_CONN_POOL=\"8\"\nexport FELIX_CACHE_STREAMS_PER_CONN=\"4\"\nexport FELIX_DISABLE_TIMINGS=\"1\"\n\ncargo run --release -p broker\n</code></pre> <p>Memory vs Performance</p> <p>Larger window sizes allow absorbing traffic bursts without flow-control stalls, but multiply memory usage with connection pools. Monitor actual RSS to understand memory pressure.</p>"},{"location":"deployment/local/#running-demos","title":"Running Demos","text":"<p>Felix includes several demonstration programs:</p>"},{"location":"deployment/local/#pubsub-demo","title":"Pub/Sub Demo","text":"<pre><code>cargo run --release -p broker --bin pubsubdemo\n</code></pre> <p>Demonstrates: - Subscribing to a stream - Publishing messages - Receiving events with fanout</p>"},{"location":"deployment/local/#cache-demo","title":"Cache Demo","text":"<pre><code>cargo run --release -p broker --bin cachedemo\n</code></pre> <p>Benchmarks cache operations: - <code>put</code> with TTL - <code>get_hit</code> (key exists) - <code>get_miss</code> (key doesn't exist)</p>"},{"location":"deployment/local/#latency-demo","title":"Latency Demo","text":"<pre><code># Basic run\ncargo run --release -p broker --bin latencydemo\n\n# Custom configuration\ncargo run --release -p broker --bin latencydemo -- \\\n    --binary \\\n    --fanout 10 \\\n    --batch 64 \\\n    --payload 4096 \\\n    --total 10000 \\\n    --warmup 500\n</code></pre> <p>Parameters:</p> <ul> <li><code>--binary</code>: Use binary batch encoding (higher throughput)</li> <li><code>--fanout N</code>: Number of concurrent subscribers</li> <li><code>--batch N</code>: Messages per batch</li> <li><code>--payload N</code>: Payload size in bytes</li> <li><code>--total N</code>: Total messages to publish</li> <li><code>--warmup N</code>: Warmup messages before measurement</li> </ul>"},{"location":"deployment/local/#using-task-commands","title":"Using Task Commands","text":"<p>If you have Task installed:</p> <pre><code># Build workspace\ntask build\n\n# Run tests\ntask test\n\n# Run linter\ntask lint\n\n# Format code\ntask fmt\n\n# Run demos\ntask demo-pubsub\ntask demo-cache\ntask demo-latency\n\n# Run conformance tests\ntask conformance\n\n# Generate coverage report\ntask coverage\n</code></pre> <p>See <code>Taskfile.yml</code> for all available tasks.</p>"},{"location":"deployment/local/#monitoring-local-development","title":"Monitoring Local Development","text":""},{"location":"deployment/local/#metrics-endpoint","title":"Metrics Endpoint","text":"<p>The broker exposes metrics on the HTTP port:</p> <pre><code># Health check\ncurl http://localhost:8080/healthz\n\n# Prometheus metrics (if enabled)\ncurl http://localhost:8080/metrics\n</code></pre>"},{"location":"deployment/local/#structured-logging","title":"Structured Logging","text":"<p>Felix logs in structured format to stdout:</p> <pre><code>2026-01-25T10:00:01.123Z INFO felix_broker: Connection accepted remote_addr=127.0.0.1:54321\n2026-01-25T10:00:01.456Z INFO felix_broker: Subscription created tenant=dev namespace=test stream=events\n2026-01-25T10:00:02.789Z WARN felix_broker: Publish queue pressure queue_depth=512\n</code></pre> <p>Control log verbosity with <code>RUST_LOG</code>:</p> <pre><code># Debug level (verbose)\nexport RUST_LOG=\"debug\"\n\n# Info level (default)\nexport RUST_LOG=\"info\"\n\n# Specific module\nexport RUST_LOG=\"felix_broker=debug,felix_wire=trace\"\n\ncargo run --release -p broker\n</code></pre>"},{"location":"deployment/local/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/local/#port-already-in-use","title":"Port Already in Use","text":"<p>Error: <code>Address already in use (os error 48)</code></p> <p>Solution: Change the ports:</p> <pre><code>export FELIX_QUIC_BIND=\"0.0.0.0:5001\"\nexport FELIX_BROKER_METRICS_BIND=\"0.0.0.0:8081\"\n</code></pre>"},{"location":"deployment/local/#build-failures","title":"Build Failures","text":"<p>Error: Compilation errors or missing dependencies</p> <p>Solution: Ensure correct Rust version:</p> <pre><code>rustc --version  # Should be 1.92.0 or later\nrustup update\ncargo clean\ncargo build --release\n</code></pre>"},{"location":"deployment/local/#connection-refused","title":"Connection Refused","text":"<p>Error: Client cannot connect to broker</p> <p>Solution: Verify broker is running and listening:</p> <pre><code># Check processes\nps aux | grep broker\n\n# Check UDP listener\nlsof -i UDP:5000\n\n# Check logs\nRUST_LOG=debug cargo run --release -p broker\n</code></pre>"},{"location":"deployment/local/#high-memory-usage","title":"High Memory Usage","text":"<p>Issue: Broker consuming excessive memory</p> <p>Solution: Reduce window sizes:</p> <pre><code>export FELIX_EVENT_CONN_RECV_WINDOW=\"134217728\"   # 128 MiB\nexport FELIX_EVENT_STREAM_RECV_WINDOW=\"33554432\"  # 32 MiB\nexport FELIX_CACHE_CONN_RECV_WINDOW=\"134217728\"\n</code></pre>"},{"location":"deployment/local/#slow-performance","title":"Slow Performance","text":"<p>Issue: Unexpectedly high latency</p> <p>Solution:</p> <ol> <li>Use release builds: Debug builds are 10-100x slower</li> <li>Disable timings: <code>export FELIX_DISABLE_TIMINGS=\"1\"</code></li> <li>Check batching: Increase batch sizes for throughput</li> <li>Profile with <code>perf</code>: Identify hot paths</li> </ol> <pre><code>cargo build --release\nFELIX_DISABLE_TIMINGS=1 cargo run --release -p broker\n</code></pre>"},{"location":"deployment/local/#next-steps","title":"Next Steps","text":"<ul> <li>Learn the client API: Client SDK Guide</li> <li>Deploy with Docker: Docker Compose Setup</li> <li>Production deployment: Kubernetes Guide</li> <li>Tune performance: Performance Guide</li> <li>Configure fully: Configuration Reference</li> </ul>"},{"location":"development/building/","title":"Building &amp; Testing","text":"<p>Complete guide to building, testing, and developing Felix.</p>"},{"location":"development/building/#build-system","title":"Build System","text":"<p>Felix uses Cargo (Rust's build tool) and Task (optional task runner) for builds.</p>"},{"location":"development/building/#prerequisites","title":"Prerequisites","text":"<p>Required:</p> <ul> <li>Rust 1.92.0+: Install via rustup</li> <li>Cargo: Included with Rust</li> </ul> <p>Optional:</p> <ul> <li>Task: Convenience task runner (install)</li> <li>cargo-llvm-cov: Code coverage (install)</li> <li>cargo-deny: Dependency auditing (install)</li> </ul>"},{"location":"development/building/#check-versions","title":"Check Versions","text":"<pre><code># Rust and Cargo\nrustc --version\ncargo --version\n\n# Should show 1.92.0 or later\n</code></pre>"},{"location":"development/building/#building","title":"Building","text":""},{"location":"development/building/#workspace-build","title":"Workspace Build","text":"<p>Felix uses a Cargo workspace with multiple crates:</p> <pre><code># Build entire workspace (debug)\ncargo build --workspace\n\n# Build release (optimized)\ncargo build --workspace --release\n\n# Or with Task\ntask build\n</code></pre> <p>Build profiles:</p> <ul> <li>Debug: Fast compilation, slow runtime, debug symbols</li> <li>Release: Slow compilation, fast runtime, optimized</li> </ul> <p>Always Use Release for Testing</p> <p>Debug builds are 10-100x slower. Use <code>--release</code> for performance testing.</p>"},{"location":"development/building/#building-specific-crates","title":"Building Specific Crates","text":"<pre><code># Build only the broker\ncargo build -p broker --release\n\n# Build only the wire protocol crate\ncargo build -p felix-wire\n\n# Build client SDK\ncargo build -p felix-client\n</code></pre>"},{"location":"development/building/#building-with-features","title":"Building with Features","text":"<pre><code># Build with telemetry enabled\ncargo build --workspace --release --features telemetry\n\n# Build without default features\ncargo build --workspace --no-default-features\n\n# List available features\ncargo metadata --format-version 1 | jq '.packages[0].features'\n</code></pre>"},{"location":"development/building/#build-output","title":"Build Output","text":"<p>Build artifacts go to <code>target/</code>:</p> <pre><code>target/\n  debug/          # Debug builds\n    broker        # Broker binary\n    libfelix_*.so # Library artifacts\n  release/        # Release builds\n    broker        # Optimized binary\n</code></pre>"},{"location":"development/building/#clean-builds","title":"Clean Builds","text":"<pre><code># Remove build artifacts\ncargo clean\n\n# Or with Task\ntask clean\n\n# Remove everything including downloaded crates\ntask clean-all\n# Or: rm -rf target\n</code></pre>"},{"location":"development/building/#running","title":"Running","text":""},{"location":"development/building/#broker-service","title":"Broker Service","text":"<pre><code># Run broker (debug)\ncargo run -p broker\n\n# Run broker (release)\ncargo run --release -p broker\n\n# Run with environment variables\nFELIX_QUIC_BIND=0.0.0.0:5001 cargo run --release -p broker\n</code></pre>"},{"location":"development/building/#demo-applications","title":"Demo Applications","text":"<pre><code># Pub/sub demo\ncargo run --release -p broker --bin pubsubdemo\n\n# Cache demo\ncargo run --release -p broker --bin cachedemo\n\n# Latency benchmark\ncargo run --release -p broker --bin latencydemo\n\n# Or with Task\ntask demo-pubsub\ntask demo-cache\ntask demo-latency\n</code></pre>"},{"location":"development/building/#custom-demo-arguments","title":"Custom Demo Arguments","text":"<pre><code># Latency demo with custom settings\ncargo run --release -p broker --bin latencydemo -- \\\n    --binary \\\n    --fanout 10 \\\n    --batch 64 \\\n    --payload 4096 \\\n    --total 10000 \\\n    --warmup 500\n</code></pre>"},{"location":"development/building/#testing","title":"Testing","text":""},{"location":"development/building/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\ncargo test --workspace\n\n# Run tests for specific crate\ncargo test -p felix-broker\n\n# Run specific test\ncargo test test_name\n\n# Run with output\ncargo test -- --nocapture\n\n# Run with Task\ntask test\n</code></pre>"},{"location":"development/building/#test-organization","title":"Test Organization","text":"<p>Tests are organized in multiple ways:</p> <p>Unit tests (inline): <pre><code>// In src/my_module.rs\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_my_function() {\n        assert_eq!(my_function(1), 2);\n    }\n}\n</code></pre></p> <p>Integration tests (separate files): <pre><code>crates/felix-broker/\n  tests/\n    integration_test.rs\n</code></pre></p> <p>Doc tests (in documentation): <pre><code>/// Example usage:\n/// ```\n/// use felix_broker::Broker;\n/// let broker = Broker::new();\n/// ```\n</code></pre></p>"},{"location":"development/building/#test-patterns","title":"Test Patterns","text":"<p>Async tests:</p> <pre><code>#[tokio::test]\nasync fn test_async_operation() {\n    let result = my_async_fn().await;\n    assert!(result.is_ok());\n}\n</code></pre> <p>Test fixtures:</p> <pre><code>fn setup_test_broker() -&gt; Broker {\n    BrokerBuilder::new()\n        .with_config(test_config())\n        .build()\n        .unwrap()\n}\n\n#[test]\nfn test_with_fixture() {\n    let broker = setup_test_broker();\n    // Test logic\n}\n</code></pre> <p>Test isolation:</p> <pre><code>// Use serial_test for tests that can't run in parallel\nuse serial_test::serial;\n\n#[test]\n#[serial]\nfn test_that_uses_global_state() {\n    // Test logic\n}\n</code></pre>"},{"location":"development/building/#test-filters","title":"Test Filters","text":"<pre><code># Run tests matching pattern\ncargo test broker\n\n# Run tests in specific module\ncargo test broker::tests::\n\n# Exclude slow tests\ncargo test --exclude-tag slow\n</code></pre>"},{"location":"development/building/#code-coverage","title":"Code Coverage","text":""},{"location":"development/building/#installing-cargo-llvm-cov","title":"Installing cargo-llvm-cov","text":"<pre><code>cargo install cargo-llvm-cov\n</code></pre>"},{"location":"development/building/#generating-coverage","title":"Generating Coverage","text":"<pre><code># Generate coverage report\ncargo llvm-cov --all-features --workspace\n\n# Generate HTML report\ncargo llvm-cov --all-features --workspace --html\nopen target/llvm-cov/html/index.html\n\n# Or with Task\ntask coverage\n</code></pre> <p>Configuration (in <code>.cargo/config.toml</code>):</p> <p>The coverage task skips demo binaries: <pre><code>cargo llvm-cov --ignore-filename-regex 'services/broker/src/bin/.*demo.*' \\\n  --skip-functions --all-features --workspace\n</code></pre></p>"},{"location":"development/building/#coverage-targets","title":"Coverage Targets","text":"<ul> <li>Target: &gt;80% code coverage</li> <li>Critical paths: &gt;95% coverage</li> <li>Tested in CI: Coverage tracked in PRs</li> </ul>"},{"location":"development/building/#linting-and-formatting","title":"Linting and Formatting","text":""},{"location":"development/building/#formatting","title":"Formatting","text":"<p>Felix uses <code>rustfmt</code> for consistent code formatting:</p> <pre><code># Format all code\ncargo fmt --all\n\n# Check formatting (CI mode)\ncargo fmt -- --check\n\n# Or with Task\ntask fmt\n</code></pre> <p>Configuration (<code>.rustfmt.toml</code>):</p> <pre><code>edition = \"2021\"\nmax_width = 100\ntab_spaces = 4\n</code></pre>"},{"location":"development/building/#linting-with-clippy","title":"Linting with Clippy","text":"<pre><code># Run clippy\ncargo clippy --workspace --all-targets --all-features -- -D warnings\n\n# Fix automatically where possible\ncargo clippy --fix\n\n# Or with Task\ntask clippy\n</code></pre> <p>Clippy checks:</p> <ul> <li>Common mistakes</li> <li>Performance issues</li> <li>Style violations</li> <li>Idiomatic Rust patterns</li> </ul>"},{"location":"development/building/#combined-lint-check","title":"Combined Lint Check","text":"<pre><code># Format and lint\ncargo fmt --all &amp;&amp; cargo clippy --workspace --all-targets --all-features -- -D warnings\n\n# Or with Task\ntask lint\n</code></pre>"},{"location":"development/building/#dependency-auditing","title":"Dependency Auditing","text":""},{"location":"development/building/#installing-cargo-deny","title":"Installing cargo-deny","text":"<pre><code>cargo install cargo-deny --version 0.19.0 --locked\n</code></pre>"},{"location":"development/building/#running-audit","title":"Running Audit","text":"<pre><code># Check dependencies\ncargo-deny check\n\n# Or with Task\ntask deny\n</code></pre> <p>What it checks:</p> <ul> <li>Security vulnerabilities</li> <li>License compliance</li> <li>Banned dependencies</li> <li>Duplicate dependencies</li> </ul> <p>Configuration (<code>deny.toml</code>):</p> <pre><code>[advisories]\nvulnerability = \"deny\"\nunmaintained = \"warn\"\n\n[licenses]\nunlicensed = \"deny\"\nallow = [\"Apache-2.0\", \"MIT\"]\n\n[bans]\nmultiple-versions = \"warn\"\n</code></pre>"},{"location":"development/building/#continuous-integration","title":"Continuous Integration","text":""},{"location":"development/building/#github-actions-workflows","title":"GitHub Actions Workflows","text":"<p>Felix uses GitHub Actions for CI:</p> <p>.github/workflows/ci.yml: - Build on Linux, macOS, Windows - Run tests - Check formatting - Run clippy - Verify documentation builds</p> <p>.github/workflows/coverage.yml: - Generate code coverage - Upload to coverage service - Update coverage badge</p>"},{"location":"development/building/#running-ci-locally","title":"Running CI Locally","text":"<p>Replicate CI checks locally:</p> <pre><code># Format check\ncargo fmt -- --check\n\n# Clippy\ncargo clippy --workspace --all-targets --all-features -- -D warnings\n\n# Tests\ncargo test --workspace\n\n# Build\ncargo build --workspace --release\n\n# Or run all checks\ntask lint &amp;&amp; task test &amp;&amp; task build\n</code></pre>"},{"location":"development/building/#ci-requirements-for-prs","title":"CI Requirements for PRs","text":"<p>All PRs must pass:</p> <ul> <li>\u2705 Formatting check</li> <li>\u2705 Clippy with no warnings</li> <li>\u2705 All tests passing</li> <li>\u2705 Documentation builds</li> <li>\u2705 No new security vulnerabilities</li> </ul>"},{"location":"development/building/#performance-testing","title":"Performance Testing","text":""},{"location":"development/building/#latency-benchmarks","title":"Latency Benchmarks","text":"<p>Basic run:</p> <pre><code>cargo run --release -p broker --bin latencydemo\n</code></pre> <p>Custom configuration:</p> <pre><code>cargo run --release -p broker --bin latencydemo -- \\\n    --binary \\\n    --fanout 10 \\\n    --batch 64 \\\n    --payload 4096 \\\n    --total 10000 \\\n    --warmup 500\n</code></pre> <p>Batch latency matrix:</p> <pre><code># Run full benchmark matrix\ntask perf:latency-matrix\n\n# Or manually\npython3 scripts/perf/run_latency_matrix.py\npython3 scripts/perf/normalize_and_aggregate.py\npython3 scripts/perf/make_charts.py\npython3 scripts/perf/render_markdown_snippets.py\n</code></pre>"},{"location":"development/building/#cache-benchmarks","title":"Cache Benchmarks","text":"<pre><code># Run cache benchmarks\ncargo run --release -p broker --bin cachedemo\n\n# Or with Task\ntask demo-cache\n</code></pre> <p>Configurable parameters:</p> <pre><code>export FELIX_CACHE_CONN_POOL=8\nexport FELIX_CACHE_STREAMS_PER_CONN=4\nexport FELIX_CACHE_BENCH_CONCURRENCY=32\nexport FELIX_CACHE_BENCH_KEYS=1024\n\ncargo run --release -p broker --bin cachedemo\n</code></pre>"},{"location":"development/building/#profiling","title":"Profiling","text":""},{"location":"development/building/#cpu-profiling","title":"CPU Profiling","text":"<p>Linux (perf):</p> <pre><code># Record profile\nsudo perf record -g --call-graph dwarf cargo run --release -p broker\n\n# View report\nsudo perf report\n\n# Generate flamegraph\ncargo install flamegraph\ncargo flamegraph -p broker\n</code></pre> <p>macOS (Instruments):</p> <pre><code># Build with debug symbols\ncargo build --profile release-with-debug -p broker\n\n# Profile with Instruments\ninstruments -t \"Time Profiler\" ./target/release-with-debug/broker\n</code></pre>"},{"location":"development/building/#memory-profiling","title":"Memory Profiling","text":"<p>Valgrind (Linux):</p> <pre><code># Build debug\ncargo build -p broker\n\n# Run with valgrind\nvalgrind --leak-check=full --show-leak-kinds=all ./target/debug/broker\n</code></pre> <p>Heaptrack (Linux):</p> <pre><code># Install heaptrack\nsudo apt install heaptrack heaptrack-gui\n\n# Profile\nheaptrack cargo run --release -p broker\n\n# Analyze\nheaptrack_gui heaptrack.broker.*.gz\n</code></pre>"},{"location":"development/building/#documentation","title":"Documentation","text":""},{"location":"development/building/#api-documentation","title":"API Documentation","text":"<p>Build and view:</p> <pre><code># Build docs\ncargo doc --workspace --no-deps\n\n# Open in browser\ncargo doc --open --no-deps\n</code></pre> <p>Document private items:</p> <pre><code>cargo doc --workspace --document-private-items\n</code></pre>"},{"location":"development/building/#user-documentation","title":"User Documentation","text":"<p>Install MkDocs:</p> <pre><code>pip install mkdocs mkdocs-material pymdown-extensions\n</code></pre> <p>Build and serve:</p> <pre><code>cd docs-site\n\n# Serve locally (live reload)\nmkdocs serve\n\n# Build static site\nmkdocs build\n\n# Output to site/ directory\n</code></pre> <p>Open documentation:</p> <pre><code>http://127.0.0.1:8000\n</code></pre>"},{"location":"development/building/#task-reference","title":"Task Reference","text":"<p>Felix includes a <code>Taskfile.yml</code> for common tasks:</p>"},{"location":"development/building/#available-tasks","title":"Available Tasks","text":"<pre><code># Build\ntask build          # Build workspace\ntask clean          # Clean artifacts\ntask clean-all      # Remove target/ directory\n\n# Code quality\ntask fmt            # Format code\ntask lint           # Format check + clippy\ntask clippy         # Run clippy\n\n# Testing\ntask test           # Run tests\ntask coverage       # Generate coverage report\n\n# Security\ntask deny           # Audit dependencies\n\n# Demos\ntask demo           # Run pubsub demo\ntask demo-pubsub    # Run pubsub demo\ntask demo-cache     # Run cache demo\ntask demo-latency   # Run latency demo\n\n# Benchmarking\ntask perf:latency-matrix  # Run full latency benchmark matrix\n\n# Wire protocol\ntask conformance    # Run wire protocol conformance tests\n</code></pre>"},{"location":"development/building/#using-task","title":"Using Task","text":"<pre><code># List all tasks\ntask --list\n\n# Run task\ntask build\n\n# Chain tasks\ntask lint &amp;&amp; task test\n</code></pre>"},{"location":"development/building/#troubleshooting-builds","title":"Troubleshooting Builds","text":""},{"location":"development/building/#rust-version-issues","title":"Rust Version Issues","text":"<pre><code># Check version\nrustc --version\n\n# Update Rust\nrustup update\n\n# Override for project\nrustup override set 1.92.0\n</code></pre>"},{"location":"development/building/#dependency-issues","title":"Dependency Issues","text":"<pre><code># Update dependencies\ncargo update\n\n# Clear registry cache\nrm -rf ~/.cargo/registry\n\n# Rebuild from scratch\ncargo clean\ncargo build --workspace\n</code></pre>"},{"location":"development/building/#linker-errors","title":"Linker Errors","text":"<p>Linux: <pre><code>sudo apt-get install build-essential pkg-config libssl-dev\n</code></pre></p> <p>macOS: <pre><code>xcode-select --install\n</code></pre></p>"},{"location":"development/building/#out-of-disk-space","title":"Out of Disk Space","text":"<pre><code># Clean build artifacts\ncargo clean\n\n# Remove old builds\nrm -rf target\n\n# Check disk usage\ndu -sh target\n</code></pre>"},{"location":"development/building/#slow-builds","title":"Slow Builds","text":"<pre><code># Limit parallel jobs\ncargo build -j 2\n\n# Use faster linker (Linux)\nsudo apt install lld\nexport RUSTFLAGS=\"-C link-arg=-fuse-ld=lld\"\n\n# Or use mold\nexport RUSTFLAGS=\"-C link-arg=-fuse-ld=mold\"\n</code></pre>"},{"location":"development/building/#best-practices","title":"Best Practices","text":""},{"location":"development/building/#development-workflow","title":"Development Workflow","text":"<ol> <li>Start with tests: Write test first (TDD)</li> <li>Format often: Run <code>cargo fmt</code> frequently</li> <li>Check clippy: Fix warnings as you go</li> <li>Run tests: Before committing</li> <li>Build release: Test performance changes</li> </ol>"},{"location":"development/building/#before-committing","title":"Before Committing","text":"<pre><code># Pre-commit checklist\ntask fmt           # Format code\ntask lint          # Check style\ntask test          # Run tests\ntask build         # Verify build\n</code></pre>"},{"location":"development/building/#performance-testing_1","title":"Performance Testing","text":"<ol> <li>Always use release builds: <code>--release</code></li> <li>Warm up: Run warmup iterations</li> <li>Multiple runs: Average results</li> <li>Isolate variables: Change one thing at a time</li> <li>Document environment: Hardware, OS, config</li> </ol>"},{"location":"development/building/#next-steps","title":"Next Steps","text":"<ul> <li>Contributing guide: Contributing</li> <li>Project structure: Project Structure</li> <li>Architecture: System Design</li> </ul>"},{"location":"development/contributing/","title":"Contributing to Felix","text":"<p>Thank you for your interest in contributing to Felix! This guide will help you get started.</p>"},{"location":"development/contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>Felix is an open and welcoming project. We expect all contributors to:</p> <ul> <li>Be respectful and considerate</li> <li>Focus on constructive feedback</li> <li>Help create a positive community</li> <li>Report unacceptable behavior to project maintainers</li> </ul>"},{"location":"development/contributing/#ways-to-contribute","title":"Ways to Contribute","text":""},{"location":"development/contributing/#reporting-bugs","title":"Reporting Bugs","text":"<p>Found a bug? Please open an issue with:</p> <ol> <li>Clear title: Summarize the issue</li> <li>Description: What happened vs what you expected</li> <li>Reproduction steps: Minimal steps to reproduce</li> <li>Environment: OS, Rust version, Felix version</li> <li>Logs/errors: Relevant error messages or stack traces</li> </ol> <p>Template: <pre><code>**Bug Description**\nA clear description of the bug.\n\n**To Reproduce**\n1. Start broker with config X\n2. Run client command Y\n3. Observe error Z\n\n**Expected Behavior**\nWhat should have happened.\n\n**Environment**\n- OS: Ubuntu 22.04\n- Rust: 1.92.0\n- Felix: main branch, commit abc123\n\n**Logs**\n</code></pre> Paste relevant logs here <pre><code>\n</code></pre></p>"},{"location":"development/contributing/#suggesting-features","title":"Suggesting Features","text":"<p>Have an idea? Open an issue with:</p> <ol> <li>Problem statement: What problem does this solve?</li> <li>Proposed solution: How would it work?</li> <li>Alternatives considered: Other approaches you've thought about</li> <li>Additional context: Use cases, examples</li> </ol> <p>Template: <pre><code>**Problem**\nDescribe the problem or limitation.\n\n**Proposed Solution**\nHow this feature would work.\n\n**Alternatives**\nOther solutions considered and why they're less ideal.\n\n**Use Case**\nReal-world scenario where this would help.\n</code></pre></p>"},{"location":"development/contributing/#improving-documentation","title":"Improving Documentation","text":"<p>Documentation is always welcome! You can:</p> <ul> <li>Fix typos or clarify existing docs</li> <li>Add examples or tutorials</li> <li>Improve API documentation</li> <li>Write guides for common scenarios</li> </ul> <p>See Building the Docs below.</p>"},{"location":"development/contributing/#contributing-code","title":"Contributing Code","text":"<p>See Development Workflow for details.</p>"},{"location":"development/contributing/#getting-started","title":"Getting Started","text":""},{"location":"development/contributing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Rust 1.92.0+: Install via rustup</li> <li>Git: For version control</li> <li>Task (optional): Install from taskfile.dev</li> <li>Development tools: <code>cargo-fmt</code>, <code>cargo-clippy</code></li> </ul>"},{"location":"development/contributing/#fork-and-clone","title":"Fork and Clone","text":"<pre><code># Fork repository on GitHub\n# Then clone your fork\ngit clone https://github.com/YOUR_USERNAME/felix.git\ncd felix\n\n# Add upstream remote\ngit remote add upstream https://github.com/gabloe/felix.git\n</code></pre>"},{"location":"development/contributing/#build-and-test","title":"Build and Test","text":"<pre><code># Build everything\ncargo build --workspace\n\n# Run tests\ncargo test --workspace\n\n# Or use Task\ntask build\ntask test\n</code></pre>"},{"location":"development/contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"development/contributing/#1-create-a-branch","title":"1. Create a Branch","text":"<pre><code># Sync with upstream\ngit fetch upstream\ngit checkout main\ngit merge upstream/main\n\n# Create feature branch\ngit checkout -b feature/my-feature\n\n# Or bugfix branch\ngit checkout -b fix/issue-123\n</code></pre> <p>Branch naming: - <code>feature/description</code>: New features - <code>fix/description</code>: Bug fixes - <code>docs/description</code>: Documentation changes - <code>refactor/description</code>: Code refactoring - <code>test/description</code>: Test additions/improvements</p>"},{"location":"development/contributing/#2-make-changes","title":"2. Make Changes","text":"<p>Code style:</p> <p>Felix follows standard Rust style guidelines:</p> <pre><code># Format code\ncargo fmt --all\n\n# Or with Task\ntask fmt\n</code></pre> <p>Run linter:</p> <pre><code># Check formatting\ncargo fmt -- --check\n\n# Run clippy\ncargo clippy --workspace --all-targets --all-features -- -D warnings\n\n# Or with Task\ntask lint\n</code></pre> <p>Writing tests:</p> <p>All new code should include tests:</p> <pre><code>#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_my_feature() {\n        // Arrange\n        let input = setup_test_data();\n\n        // Act\n        let result = my_function(input);\n\n        // Assert\n        assert_eq!(result, expected_value);\n    }\n}\n</code></pre> <p>Test async code:</p> <pre><code>#[tokio::test]\nasync fn test_async_feature() {\n    let result = my_async_function().await;\n    assert!(result.is_ok());\n}\n</code></pre>"},{"location":"development/contributing/#3-commit-changes","title":"3. Commit Changes","text":"<p>Commit message format:</p> <pre><code>&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;\n\n&lt;body&gt;\n\n&lt;footer&gt;\n</code></pre> <p>Types: - <code>feat</code>: New feature - <code>fix</code>: Bug fix - <code>docs</code>: Documentation changes - <code>style</code>: Code style changes (formatting, etc.) - <code>refactor</code>: Code refactoring - <code>test</code>: Adding or modifying tests - <code>chore</code>: Build process or tooling changes</p> <p>Example:</p> <pre><code>git add .\ngit commit -m \"feat(broker): add configurable batch timeout\n\nAdds FELIX_EVENT_BATCH_MAX_DELAY_US configuration to control\nthe maximum delay before flushing event batches. This allows\nusers to tune the latency vs throughput trade-off.\n\nCloses #123\"\n</code></pre> <p>Guidelines: - Use present tense (\"add\" not \"added\") - Keep subject line under 72 characters - Reference issues in footer (<code>Closes #123</code>, <code>Fixes #456</code>) - Add breaking changes in footer: <code>BREAKING CHANGE: description</code></p>"},{"location":"development/contributing/#4-push-and-create-pr","title":"4. Push and Create PR","text":"<pre><code># Push to your fork\ngit push origin feature/my-feature\n\n# Create pull request on GitHub\n</code></pre> <p>Pull request template:</p> <pre><code>## Description\nBrief description of changes.\n\n## Motivation\nWhy is this change needed?\n\n## Changes\n- List of changes made\n\n## Testing\nHow was this tested?\n\n## Checklist\n- [ ] Tests added/updated\n- [ ] Documentation updated\n- [ ] Ran `task lint`\n- [ ] Ran `task test`\n- [ ] No breaking changes (or documented in commit)\n</code></pre>"},{"location":"development/contributing/#5-code-review","title":"5. Code Review","text":"<ul> <li>Respond to feedback promptly</li> <li>Make requested changes in new commits</li> <li>Push updates to the same branch</li> <li>Request re-review when ready</li> </ul>"},{"location":"development/contributing/#6-merge","title":"6. Merge","text":"<p>Once approved: - Maintainers will merge your PR - Delete your feature branch after merge</p> <pre><code>git checkout main\ngit pull upstream main\ngit branch -d feature/my-feature\n</code></pre>"},{"location":"development/contributing/#code-style-guidelines","title":"Code Style Guidelines","text":""},{"location":"development/contributing/#rust-style","title":"Rust Style","text":"<p>Follow standard conventions:</p> <pre><code>// Use descriptive names\nfn calculate_batch_size(events: &amp;[Event]) -&gt; usize { ... }\n\n// Document public APIs\n/// Publishes an event to the specified stream.\n///\n/// # Arguments\n/// * `stream` - The target stream name\n/// * `payload` - The event payload\n///\n/// # Returns\n/// Result indicating success or error\npub async fn publish(&amp;self, stream: &amp;str, payload: &amp;[u8]) -&gt; Result&lt;()&gt; { ... }\n\n// Use Result for errors\nfn parse_config(path: &amp;str) -&gt; Result&lt;Config&gt; { ... }\n\n// Prefer ? operator over unwrap()\nlet config = parse_config(path)?;\n\n// Use meaningful error messages\nreturn Err(anyhow!(\"Failed to bind to {}: {}\", addr, err));\n</code></pre>"},{"location":"development/contributing/#formatting","title":"Formatting","text":"<pre><code># Format all code\ncargo fmt --all\n\n# Check formatting in CI\ncargo fmt -- --check\n</code></pre>"},{"location":"development/contributing/#linting","title":"Linting","text":"<pre><code># Run clippy\ncargo clippy --workspace --all-targets --all-features -- -D warnings\n\n# Fix automatically where possible\ncargo clippy --fix\n</code></pre>"},{"location":"development/contributing/#comments","title":"Comments","text":"<p>When to comment: - Complex algorithms - Non-obvious design decisions - Performance-critical sections - Workarounds for external issues</p> <p>When not to comment: - Obvious code - What the code does (code should be self-documenting)</p> <pre><code>// Good: Explains why\n// We batch events to amortize framing overhead across multiple messages.\n// Empirical testing shows 64 events per batch optimizes for 1-4KB payloads.\nconst DEFAULT_BATCH_SIZE: usize = 64;\n\n// Bad: Restates the obvious\n// Set the batch size to 64\nconst DEFAULT_BATCH_SIZE: usize = 64;\n</code></pre>"},{"location":"development/contributing/#error-handling","title":"Error Handling","text":"<pre><code>// Use anyhow for application code\nuse anyhow::{Context, Result};\n\nfn load_config(path: &amp;str) -&gt; Result&lt;Config&gt; {\n    let contents = fs::read_to_string(path)\n        .with_context(|| format!(\"Failed to read config from {}\", path))?;\n    let config: Config = serde_yaml::from_str(&amp;contents)\n        .context(\"Failed to parse config YAML\")?;\n    Ok(config)\n}\n\n// Use custom error types for libraries\n#[derive(Debug, thiserror::Error)]\npub enum BrokerError {\n    #[error(\"Connection closed\")]\n    ConnectionClosed,\n    #[error(\"Invalid frame: {0}\")]\n    InvalidFrame(String),\n}\n</code></pre>"},{"location":"development/contributing/#testing-guidelines","title":"Testing Guidelines","text":""},{"location":"development/contributing/#test-coverage","title":"Test Coverage","text":"<ul> <li>All public APIs must have tests</li> <li>Bug fixes must include regression tests</li> <li>Aim for &gt;80% code coverage</li> </ul>"},{"location":"development/contributing/#test-organization","title":"Test Organization","text":"<pre><code>#[cfg(test)]\nmod tests {\n    use super::*;\n\n    // Unit tests for internal functions\n    #[test]\n    fn test_parse_frame() { ... }\n\n    // Integration tests for APIs\n    #[tokio::test]\n    async fn test_publish_subscribe_flow() { ... }\n}\n</code></pre>"},{"location":"development/contributing/#running-tests","title":"Running Tests","text":"<pre><code># All tests\ncargo test --workspace\n\n# Specific test\ncargo test test_name\n\n# With output\ncargo test -- --nocapture\n\n# With coverage\ntask coverage\n</code></pre>"},{"location":"development/contributing/#test-fixtures","title":"Test Fixtures","text":"<pre><code>// Create reusable test helpers\nfn create_test_broker() -&gt; Broker {\n    BrokerBuilder::new()\n        .with_config(test_config())\n        .build()\n        .unwrap()\n}\n\n#[tokio::test]\nasync fn test_feature() {\n    let broker = create_test_broker();\n    // Test code\n}\n</code></pre>"},{"location":"development/contributing/#documentation","title":"Documentation","text":""},{"location":"development/contributing/#code-documentation","title":"Code Documentation","text":"<pre><code>/// A brief one-line summary.\n///\n/// More detailed description if needed. Can span multiple paragraphs.\n///\n/// # Arguments\n/// * `arg1` - Description of arg1\n/// * `arg2` - Description of arg2\n///\n/// # Returns\n/// Description of return value\n///\n/// # Errors\n/// Description of error conditions\n///\n/// # Examples\n/// ```\n/// use felix_broker::Broker;\n///\n/// let broker = Broker::new();\n/// broker.start().await?;\n/// ```\npub async fn my_function(arg1: Type1, arg2: Type2) -&gt; Result&lt;Type3&gt; {\n    // Implementation\n}\n</code></pre>"},{"location":"development/contributing/#building-documentation","title":"Building Documentation","text":"<p>API docs:</p> <pre><code># Build and open docs\ncargo doc --open --no-deps\n\n# Build all docs\ncargo doc --workspace\n</code></pre> <p>User documentation:</p> <pre><code># Install mkdocs\npip install mkdocs mkdocs-material\n\n# Serve locally\ncd docs-site\nmkdocs serve\n# Open http://127.0.0.1:8000\n\n# Build static site\nmkdocs build\n</code></pre>"},{"location":"development/contributing/#performance-considerations","title":"Performance Considerations","text":""},{"location":"development/contributing/#benchmarking","title":"Benchmarking","text":"<pre><code># Run latency benchmarks\ncargo run --release -p broker --bin latencydemo -- \\\n    --binary --fanout 10 --batch 64 --payload 4096\n\n# Run cache benchmarks\ncargo run --release -p broker --bin cachedemo\n</code></pre>"},{"location":"development/contributing/#profiling","title":"Profiling","text":"<p>CPU profiling:</p> <pre><code># Linux perf\nsudo perf record -g cargo run --release -p broker\nsudo perf report\n\n# Flamegraph\ncargo install flamegraph\ncargo flamegraph -p broker\n</code></pre> <p>Memory profiling:</p> <pre><code># Valgrind (debug build)\nvalgrind --leak-check=full ./target/debug/broker\n\n# Heaptrack (Linux)\nheaptrack cargo run --release -p broker\n</code></pre>"},{"location":"development/contributing/#release-process","title":"Release Process","text":"<p>(For maintainers)</p> <ol> <li>Update version in <code>Cargo.toml</code></li> <li>Update <code>CHANGELOG.md</code></li> <li>Create git tag: <code>git tag -a v0.1.0 -m \"Release v0.1.0\"</code></li> <li>Push tag: <code>git push origin v0.1.0</code></li> <li>GitHub Actions builds and publishes release</li> </ol>"},{"location":"development/contributing/#getting-help","title":"Getting Help","text":"<p>Stuck?</p> <ul> <li>GitHub Discussions: Ask questions</li> <li>GitHub Issues: Bug reports and feature requests</li> <li>Documentation: docs-site/</li> </ul> <p>Before asking:</p> <ol> <li>Check existing issues/discussions</li> <li>Review documentation</li> <li>Try to create a minimal reproduction</li> </ol>"},{"location":"development/contributing/#recognition","title":"Recognition","text":"<p>Contributors are recognized in:</p> <ul> <li><code>CONTRIBUTORS.md</code> (added on first merged PR)</li> <li>Release notes</li> <li>GitHub contributors graph</li> </ul> <p>Thank you for contributing to Felix! \ud83c\udf89</p>"},{"location":"development/contributing/#next-steps","title":"Next Steps","text":"<ul> <li>Build system: Building &amp; Testing Guide</li> <li>Project structure: Project Structure</li> <li>Architecture: System Design</li> </ul>"},{"location":"development/project-structure/","title":"Project Structure","text":"<p>Understanding Felix's repository layout, crate organization, and architectural conventions.</p>"},{"location":"development/project-structure/#repository-overview","title":"Repository Overview","text":"<pre><code>felix/\n\u251c\u2500\u2500 crates/              # Rust crates (libraries)\n\u251c\u2500\u2500 services/            # Runnable services (binaries)\n\u251c\u2500\u2500 docs/                # Design and architecture docs\n\u251c\u2500\u2500 docs-site/           # User documentation (MkDocs)\n\u251c\u2500\u2500 scripts/             # Build and automation scripts\n\u251c\u2500\u2500 docker/              # Docker configuration\n\u251c\u2500\u2500 .github/             # GitHub Actions workflows\n\u251c\u2500\u2500 githooks/            # Git hooks for development\n\u251c\u2500\u2500 Cargo.toml           # Workspace manifest\n\u251c\u2500\u2500 Cargo.lock           # Dependency lock file\n\u251c\u2500\u2500 Taskfile.yml         # Task runner configuration\n\u251c\u2500\u2500 deny.toml            # Dependency audit rules\n\u251c\u2500\u2500 mkdocs.yml           # Documentation site config\n\u2514\u2500\u2500 rust-toolchain.toml  # Rust version specification\n</code></pre>"},{"location":"development/project-structure/#crates-directory","title":"Crates Directory","text":"<p>The <code>crates/</code> directory contains all library crates following a modular architecture:</p> <pre><code>crates/\n\u251c\u2500\u2500 felix-broker/        # Broker core (pub/sub, cache, fanout)\n\u251c\u2500\u2500 felix-wire/          # Wire protocol and framing\n\u251c\u2500\u2500 felix-transport/     # QUIC transport abstraction\n\u251c\u2500\u2500 felix-storage/       # Storage layer (ephemeral + durable)\n\u251c\u2500\u2500 felix-client/        # Client SDK\n\u251c\u2500\u2500 felix-common/        # Shared types and utilities\n\u251c\u2500\u2500 felix-metadata/      # Metadata abstractions\n\u251c\u2500\u2500 felix-router/        # Region-aware routing\n\u251c\u2500\u2500 felix-crypto/        # Encryption and key handling\n\u251c\u2500\u2500 felix-authz/         # Authentication and authorization\n\u251c\u2500\u2500 felix-consensus/     # Consensus coordination (Raft)\n\u2514\u2500\u2500 felix-conformance/   # Wire protocol conformance tests\n</code></pre>"},{"location":"development/project-structure/#core-crates","title":"Core Crates","text":""},{"location":"development/project-structure/#felix-broker","title":"felix-broker","text":"<p>Purpose: Broker core logic for pub/sub and cache.</p> <p>Responsibilities: - Stream registry and subscription management - Event fanout and batching - Cache storage with TTL - Backpressure and flow control - Connection lifecycle management</p> <p>Key modules: - <code>broker.rs</code>: Main broker type - <code>subscription.rs</code>: Subscription handling - <code>cache.rs</code>: Cache implementation - <code>fanout.rs</code>: Fanout engine</p> <p>Dependencies: - <code>felix-wire</code>: Protocol framing - <code>felix-transport</code>: QUIC abstraction - <code>felix-storage</code>: Data persistence - <code>felix-common</code>: Shared types</p>"},{"location":"development/project-structure/#felix-wire","title":"felix-wire","text":"<p>Purpose: Wire protocol definition and frame encoding/decoding.</p> <p>Responsibilities: - Frame type definitions - JSON control message encoding - Binary batch encoding/decoding - Protocol versioning - Frame validation</p> <p>Key types: - <code>Frame</code>: Top-level frame enum - <code>ControlFrame</code>: JSON control messages - <code>BinaryBatch</code>: Batch frame format - <code>FrameCodec</code>: Encode/decode implementation</p> <p>Protocol layers: 1. Envelope: Version, type, length 2. Control frames: JSON for human readability 3. Binary frames: Zero-copy fast paths</p>"},{"location":"development/project-structure/#felix-transport","title":"felix-transport","text":"<p>Purpose: QUIC transport abstraction and connection pooling.</p> <p>Responsibilities: - QUIC client/server setup - Connection lifecycle - Stream management - TLS certificate handling - Flow control configuration</p> <p>Key types: - <code>QuicClient</code>: Client-side connection - <code>QuicServer</code>: Server-side listener - <code>StreamPool</code>: Connection pooling - <code>QuicConfig</code>: Transport configuration</p> <p>Based on: <code>quinn</code> (QUIC implementation)</p>"},{"location":"development/project-structure/#felix-storage","title":"felix-storage","text":"<p>Purpose: Storage layer abstraction for ephemeral and durable data.</p> <p>Responsibilities: - Ephemeral in-memory storage - Durable WAL and log segments - TTL management - Retention policies - Compaction (future)</p> <p>Storage types: - <code>EphemeralStore</code>: In-memory with TTL - <code>DurableStore</code>: Persistent log (planned) - <code>CacheStore</code>: Key-value with expiration</p>"},{"location":"development/project-structure/#felix-client","title":"felix-client","text":"<p>Purpose: Rust client SDK for Felix.</p> <p>Responsibilities: - Publish API - Subscribe API - Cache operations (put/get) - Connection management - Stream pooling - Error handling</p> <p>Key types: - <code>FelixClient</code>: Main client interface - <code>Publisher</code>: Publishing handle - <code>Subscriber</code>: Subscription handle - <code>CacheClient</code>: Cache operations - <code>ClientConfig</code>: Client configuration</p> <p>Example usage: <pre><code>use felix_client::{FelixClient, ClientConfig};\n\nlet config = ClientConfig {\n    broker_addr: \"127.0.0.1:5000\".parse()?,\n    ..Default::default()\n};\n\nlet client = FelixClient::connect(config).await?;\nclient.publish(\"tenant\", \"namespace\", \"stream\", b\"data\").await?;\n</code></pre></p>"},{"location":"development/project-structure/#supporting-crates","title":"Supporting Crates","text":""},{"location":"development/project-structure/#felix-common","title":"felix-common","text":"<p>Purpose: Shared types and utilities used across crates.</p> <p>Contents: - <code>types.rs</code>: Common type definitions - <code>error.rs</code>: Error types - <code>ids.rs</code>: ID types (TenantId, StreamId, etc.) - <code>config.rs</code>: Configuration types - <code>time.rs</code>: Time utilities</p> <p>Principle: Minimal dependencies, stable API.</p>"},{"location":"development/project-structure/#felix-metadata","title":"felix-metadata","text":"<p>Purpose: Metadata abstractions for streams, tenants, and routing.</p> <p>Responsibilities: - Stream metadata - Tenant configuration - Routing policies - Shard placement - Region configuration</p> <p>Key types: - <code>StreamMetadata</code>: Stream definition - <code>TenantConfig</code>: Tenant settings - <code>ShardInfo</code>: Shard placement - <code>RoutingPolicy</code>: Region-aware routing</p>"},{"location":"development/project-structure/#felix-router","title":"felix-router","text":"<p>Purpose: Region-aware routing and locality policies.</p> <p>Responsibilities: - Region topology - Locality-based routing - Cross-region bridge configuration - Request routing logic</p> <p>Future: Control plane integration for dynamic routing.</p>"},{"location":"development/project-structure/#felix-crypto","title":"felix-crypto","text":"<p>Purpose: Encryption and key management.</p> <p>Responsibilities: - TLS certificate handling - Key derivation - End-to-end encryption (planned) - Key rotation (planned)</p>"},{"location":"development/project-structure/#felix-authz","title":"felix-authz","text":"<p>Purpose: Authentication and authorization.</p> <p>Responsibilities: - mTLS authentication (planned) - Token-based auth (planned) - RBAC policies (planned) - Tenant isolation enforcement</p>"},{"location":"development/project-structure/#felix-consensus","title":"felix-consensus","text":"<p>Purpose: Consensus and coordination for clustering.</p> <p>Responsibilities: - Raft implementation (planned) - Leader election - Log replication - Membership management</p> <p>Status: Placeholder for future clustering.</p>"},{"location":"development/project-structure/#felix-conformance","title":"felix-conformance","text":"<p>Purpose: Wire protocol conformance test suite.</p> <p>Responsibilities: - Test vector validation - Cross-implementation testing - Protocol regression tests</p> <p>Usage: <pre><code>cargo run -p felix-conformance\n</code></pre></p>"},{"location":"development/project-structure/#services-directory","title":"Services Directory","text":"<p>The <code>services/</code> directory contains runnable binaries:</p> <pre><code>services/\n\u251c\u2500\u2500 broker/              # Broker service\n\u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u251c\u2500\u2500 main.rs      # Broker entrypoint\n\u2502   \u2502   \u251c\u2500\u2500 config.rs    # Configuration loading\n\u2502   \u2502   \u2514\u2500\u2500 bin/         # Demo applications\n\u2502   \u2502       \u251c\u2500\u2500 pubsubdemo.rs\n\u2502   \u2502       \u251c\u2500\u2500 cachedemo.rs\n\u2502   \u2502       \u2514\u2500\u2500 latencydemo.rs\n\u2502   \u251c\u2500\u2500 Cargo.toml\n\u2502   \u2514\u2500\u2500 README.md        # Performance profiles\n\u251c\u2500\u2500 controlplane/        # Control plane (future)\n\u2514\u2500\u2500 agent/               # Infrastructure agent (future)\n</code></pre>"},{"location":"development/project-structure/#broker-service","title":"Broker Service","text":"<p>Location: <code>services/broker/</code></p> <p>Entrypoint: <code>src/main.rs</code></p> <p>Responsibilities: - Load configuration from env/YAML - Initialize broker runtime - Start QUIC listener - Expose metrics endpoint - Handle graceful shutdown</p> <p>Demo binaries:</p> <ul> <li><code>pubsubdemo.rs</code>: Pub/sub demonstration</li> <li><code>cachedemo.rs</code>: Cache benchmark</li> <li><code>latencydemo.rs</code>: Latency measurement tool</li> </ul>"},{"location":"development/project-structure/#documentation","title":"Documentation","text":""},{"location":"development/project-structure/#design-docs-docs","title":"Design Docs (<code>docs/</code>)","text":"<p>Architecture and design documentation:</p> <pre><code>docs/\n\u251c\u2500\u2500 architecture.md      # System architecture overview\n\u251c\u2500\u2500 protocol.md          # Wire protocol specification\n\u251c\u2500\u2500 control-plane.md     # Control plane design\n\u251c\u2500\u2500 semantics.md         # Delivery semantics\n\u251c\u2500\u2500 design.md            # Product design notes\n\u251c\u2500\u2500 broker-config.md     # Broker configuration\n\u251c\u2500\u2500 client-config.md     # Client configuration\n\u251c\u2500\u2500 todos.md             # Implementation checklist\n\u2514\u2500\u2500 assets/              # Diagrams and images\n    \u2514\u2500\u2500 logo.PNG\n</code></pre> <p>Purpose: Technical design for contributors.</p>"},{"location":"development/project-structure/#user-docs-docs-site","title":"User Docs (<code>docs-site/</code>)","text":"<p>User-facing documentation (MkDocs):</p> <pre><code>docs-site/\n\u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 index.md\n\u2502   \u251c\u2500\u2500 getting-started/\n\u2502   \u251c\u2500\u2500 architecture/\n\u2502   \u251c\u2500\u2500 api/\n\u2502   \u251c\u2500\u2500 features/\n\u2502   \u251c\u2500\u2500 deployment/\n\u2502   \u251c\u2500\u2500 reference/\n\u2502   \u2514\u2500\u2500 development/\n\u2514\u2500\u2500 mkdocs.yml           # Site configuration\n</code></pre> <p>Purpose: End-user guides and API references.</p> <p>Build: <pre><code>cd docs-site\nmkdocs serve\n</code></pre></p>"},{"location":"development/project-structure/#scripts-directory","title":"Scripts Directory","text":"<p>Automation and utility scripts:</p> <pre><code>scripts/\n\u2514\u2500\u2500 perf/                # Performance benchmarking\n    \u251c\u2500\u2500 run_latency_matrix.py\n    \u251c\u2500\u2500 normalize_and_aggregate.py\n    \u251c\u2500\u2500 make_charts.py\n    \u251c\u2500\u2500 render_markdown_snippets.py\n    \u2514\u2500\u2500 presets.yml      # Benchmark configurations\n</code></pre>"},{"location":"development/project-structure/#docker-directory","title":"Docker Directory","text":"<p>Docker build configuration:</p> <pre><code>docker/\n\u251c\u2500\u2500 broker.Dockerfile           # Multi-stage broker build\n\u251c\u2500\u2500 controlplane.Dockerfile     # Control plane (future)\n\u251c\u2500\u2500 prometheus/\n\u2502   \u251c\u2500\u2500 prometheus.yml          # Prometheus config\n\u2502   \u2514\u2500\u2500 prometheus.Dockerfile\n\u2514\u2500\u2500 otel-collector/\n    \u251c\u2500\u2500 config.yml              # OTEL config\n    \u2514\u2500\u2500 otel-collector.Dockerfile\n</code></pre>"},{"location":"development/project-structure/#github-workflows","title":"GitHub Workflows","text":"<p>CI/CD configuration:</p> <pre><code>.github/\n\u251c\u2500\u2500 workflows/\n\u2502   \u251c\u2500\u2500 ci.yml           # Main CI pipeline\n\u2502   \u2514\u2500\u2500 coverage.yml     # Code coverage\n\u2514\u2500\u2500 dependabot.yml       # Dependency updates\n</code></pre>"},{"location":"development/project-structure/#configuration-files","title":"Configuration Files","text":""},{"location":"development/project-structure/#cargotoml-workspace","title":"Cargo.toml (Workspace)","text":"<p>Purpose: Define workspace and shared dependencies.</p> <pre><code>[workspace]\nmembers = [\n    \"crates/*\",\n    \"services/*\",\n]\nresolver = \"2\"\n\n[workspace.dependencies]\ntokio = { version = \"1.35\", features = [\"full\"] }\nanyhow = \"1.0\"\n# ... shared dependencies\n</code></pre>"},{"location":"development/project-structure/#rust-toolchaintoml","title":"rust-toolchain.toml","text":"<p>Purpose: Pin Rust version for consistency.</p> <pre><code>[toolchain]\nchannel = \"1.92.0\"\ncomponents = [\"rustfmt\", \"clippy\"]\n</code></pre>"},{"location":"development/project-structure/#denytoml","title":"deny.toml","text":"<p>Purpose: Configure cargo-deny for dependency auditing.</p> <p>Checks: - Security vulnerabilities - License compliance - Banned crates - Duplicate dependencies</p>"},{"location":"development/project-structure/#taskfileyml","title":"Taskfile.yml","text":"<p>Purpose: Define common development tasks.</p> <p>Tasks: build, test, lint, fmt, coverage, demos, etc.</p>"},{"location":"development/project-structure/#naming-conventions","title":"Naming Conventions","text":""},{"location":"development/project-structure/#crate-names","title":"Crate Names","text":"<ul> <li>Library crates: <code>felix-&lt;component&gt;</code> (e.g., <code>felix-broker</code>)</li> <li>Binary crates: Service name (e.g., <code>broker</code>)</li> <li>All lowercase, hyphen-separated</li> </ul>"},{"location":"development/project-structure/#module-structure","title":"Module Structure","text":"<pre><code>crate_root/\n\u251c\u2500\u2500 lib.rs              # Public API (library)\n\u251c\u2500\u2500 main.rs             # Entrypoint (binary)\n\u251c\u2500\u2500 module_name.rs      # Single-file module\n\u2514\u2500\u2500 module_name/        # Multi-file module\n    \u251c\u2500\u2500 mod.rs          # Module root\n    \u251c\u2500\u2500 submodule.rs\n    \u2514\u2500\u2500 tests.rs        # Module tests\n</code></pre>"},{"location":"development/project-structure/#file-naming","title":"File Naming","text":"<ul> <li>Snake_case: <code>my_module.rs</code></li> <li>Tests: <code>mod_tests.rs</code> or <code>tests/</code></li> <li>Binaries: <code>bin/my_app.rs</code></li> </ul>"},{"location":"development/project-structure/#type-naming","title":"Type Naming","text":"<ul> <li>PascalCase: Structs, enums, traits (<code>BrokerConfig</code>, <code>FrameType</code>)</li> <li>snake_case: Functions, methods, variables (<code>publish_event</code>, <code>config_value</code>)</li> <li>SCREAMING_SNAKE_CASE: Constants (<code>DEFAULT_PORT</code>, <code>MAX_BATCH_SIZE</code>)</li> </ul>"},{"location":"development/project-structure/#dependency-management","title":"Dependency Management","text":""},{"location":"development/project-structure/#dependency-categories","title":"Dependency Categories","text":"<p>Core dependencies: - <code>tokio</code>: Async runtime - <code>quinn</code>: QUIC implementation - <code>serde</code>: Serialization - <code>anyhow</code>/<code>thiserror</code>: Error handling</p> <p>Development dependencies: - <code>serial_test</code>: Test isolation - <code>tempfile</code>: Temporary files in tests - <code>criterion</code>: Benchmarking</p>"},{"location":"development/project-structure/#dependency-rules","title":"Dependency Rules","text":"<ol> <li>Minimize dependencies: Only add when necessary</li> <li>Pin versions: Use exact versions in workspace</li> <li>Audit regularly: Run <code>cargo-deny check</code></li> <li>No unmaintained crates: Check maintenance status</li> <li>License compliance: Only Apache-2.0 / MIT</li> </ol>"},{"location":"development/project-structure/#adding-dependencies","title":"Adding Dependencies","text":"<pre><code># Add to workspace\ncargo add --workspace &lt;crate&gt;\n\n# Add to specific crate\ncargo add -p felix-broker &lt;crate&gt;\n\n# Add dev dependency\ncargo add --dev &lt;crate&gt;\n</code></pre>"},{"location":"development/project-structure/#testing-structure","title":"Testing Structure","text":""},{"location":"development/project-structure/#test-organization","title":"Test Organization","text":"<p>Unit tests: Inline in source files <pre><code>#[cfg(test)]\nmod tests {\n    use super::*;\n    // Tests here\n}\n</code></pre></p> <p>Integration tests: <code>tests/</code> directory <pre><code>crate/\n  tests/\n    integration_test.rs\n    common/\n      mod.rs           # Shared test utilities\n</code></pre></p> <p>Conformance tests: Separate crate (<code>felix-conformance</code>)</p>"},{"location":"development/project-structure/#test-naming","title":"Test Naming","text":"<ul> <li>Functions: <code>test_&lt;what_it_does&gt;</code></li> <li>Modules: <code>tests</code> or <code>&lt;module&gt;_tests</code></li> <li>Files: <code>integration_test.rs</code>, <code>e2e_test.rs</code></li> </ul>"},{"location":"development/project-structure/#build-artifacts","title":"Build Artifacts","text":""},{"location":"development/project-structure/#target-directory","title":"Target Directory","text":"<pre><code>target/\n\u251c\u2500\u2500 debug/              # Debug builds\n\u2502   \u251c\u2500\u2500 broker          # Binary\n\u2502   \u251c\u2500\u2500 deps/           # Dependencies\n\u2502   \u2514\u2500\u2500 build/          # Build scripts\n\u251c\u2500\u2500 release/            # Release builds\n\u2514\u2500\u2500 doc/                # Generated docs\n</code></pre>"},{"location":"development/project-structure/#cargo-cache","title":"Cargo Cache","text":"<pre><code>~/.cargo/\n\u251c\u2500\u2500 registry/           # Downloaded crate sources\n\u251c\u2500\u2500 git/                # Git dependencies\n\u2514\u2500\u2500 bin/                # Installed binaries\n</code></pre>"},{"location":"development/project-structure/#development-environment","title":"Development Environment","text":""},{"location":"development/project-structure/#recommended-setup","title":"Recommended Setup","text":"<p>Editor: VS Code with rust-analyzer</p> <p>Extensions: - rust-analyzer: IntelliSense - CodeLLDB: Debugging - Better TOML: TOML syntax</p> <p>.vscode/settings.json: <pre><code>{\n    \"rust-analyzer.cargo.features\": \"all\",\n    \"rust-analyzer.checkOnSave.command\": \"clippy\"\n}\n</code></pre></p>"},{"location":"development/project-structure/#git-hooks","title":"Git Hooks","text":"<pre><code># Install pre-commit hook\ncp githooks/pre-commit .git/hooks/\nchmod +x .git/hooks/pre-commit\n</code></pre> <p>Pre-commit hook: - Format check - Clippy warnings - Run tests</p>"},{"location":"development/project-structure/#code-organization-principles","title":"Code Organization Principles","text":""},{"location":"development/project-structure/#modularity","title":"Modularity","text":"<ul> <li>Small, focused crates: Each crate has a single purpose</li> <li>Clear boundaries: Minimal cross-crate dependencies</li> <li>Public API: Carefully designed, stable interfaces</li> </ul>"},{"location":"development/project-structure/#layering","title":"Layering","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Services (binaries)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    Application Layer    \u2502\n\u2502  (broker, client, etc)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     Protocol Layer      \u2502\n\u2502   (wire, transport)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    Foundation Layer     \u2502\n\u2502  (common, storage)      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"development/project-structure/#dependency-direction","title":"Dependency Direction","text":"<p>Dependencies flow downward: - Services depend on applications - Applications depend on protocol - Protocol depends on foundation - Foundation has minimal dependencies</p> <p>Never: Lower layers depend on upper layers.</p>"},{"location":"development/project-structure/#future-structure-changes","title":"Future Structure Changes","text":"<p>As Felix evolves:</p> <ul> <li>More crates: New features may add crates</li> <li>Service separation: Control plane, agents</li> <li>Language clients: SDKs in other languages</li> <li>Deployment: Helm charts, Kubernetes operators</li> </ul> <p>The core structure (crates/services separation) will remain stable.</p>"},{"location":"development/project-structure/#next-steps","title":"Next Steps","text":"<ul> <li>Contributing: Contributing Guide</li> <li>Building: Building &amp; Testing</li> <li>Architecture: System Design</li> </ul>"},{"location":"features/cache/","title":"Cache Features","text":"<p>Felix provides a low-latency distributed cache built on top of the same QUIC transport and wire protocol used for pub/sub. The cache is designed for session management, configuration storage, and high-concurrency read/write workloads where sub-millisecond latency matters.</p>"},{"location":"features/cache/#overview","title":"Overview","text":"<p>The Felix cache is:</p> <ul> <li>Key-value store with optional TTL (time-to-live)</li> <li>Scoped to <code>(tenant_id, namespace, cache_name, key)</code></li> <li>In-memory for lowest latency (ephemeral in MVP)</li> <li>Multiplexed over pooled QUIC streams</li> <li>Highly concurrent with request pipelining</li> </ul> <pre><code>graph LR\n    subgraph Clients\n        C1[Client 1]\n        C2[Client 2]\n        C3[Client 3]\n    end\n\n    subgraph Broker[\"Broker Cache Engine\"]\n        CM[Cache Manager]\n        HM[HashMap Storage]\n        TTL[TTL Tracker]\n    end\n\n    C1 --&gt;|cache_put/get| CM\n    C2 --&gt;|cache_put/get| CM\n    C3 --&gt;|cache_put/get| CM\n\n    CM --&gt; HM\n    CM --&gt; TTL\n\n    style CM fill:#fff3e0\n    style HM fill:#e3f2fd\n    style TTL fill:#f3e5f5</code></pre>"},{"location":"features/cache/#core-features","title":"Core Features","text":""},{"location":"features/cache/#1-low-latency-operations","title":"1. Low-Latency Operations","text":"<p>Felix cache is optimized for microsecond-level latency:</p> <p>Localhost performance (concurrency=32):</p> Operation Payload p50 Latency p99 Latency Throughput put 0 B 158 \u00b5s 350 \u00b5s 184k ops/sec put 256 B 179 \u00b5s 380 \u00b5s 155k ops/sec put 4 KB 260 \u00b5s 480 \u00b5s 78k ops/sec get (hit) 256 B 177 \u00b5s 360 \u00b5s 166k ops/sec get (miss) - 165 \u00b5s 340 \u00b5s 179k ops/sec <p>Comparison with other systems (approximate, localhost):</p> System get p50 put p50 Notes Felix 165 \u00b5s 165 \u00b5s QUIC, in-memory Redis 100 \u00b5s 110 \u00b5s TCP, in-memory Memcached 90 \u00b5s 95 \u00b5s TCP, in-memory etcd 2-5 ms 3-8 ms RAFT consistency <p>Felix trades ~50-70 \u00b5s for QUIC's benefits (encryption, multiplexing, flow control).</p>"},{"location":"features/cache/#2-time-to-live-ttl","title":"2. Time-to-Live (TTL)","text":"<p>Store entries with automatic expiration:</p> <pre><code>// Store session with 1-hour TTL\nclient.cache_put(\n    \"sessions\",\n    \"user-abc\",\n    session_data,\n    Some(3600_000)  // 60 minutes in milliseconds\n).await?;\n\n// After 1 hour, entry automatically expires\ntokio::time::sleep(Duration::from_secs(3601)).await;\n\n// Returns None (expired)\nassert_eq!(client.cache_get(\"sessions\", \"user-abc\").await?, None);\n</code></pre> <p>TTL semantics:</p> <ul> <li>Countdown starts: When <code>cache_put</code> completes</li> <li>Expiration checking: Lazy (on access)</li> <li>Precision: Best-effort, typically &lt; 100 ms variance</li> <li>Updates: Each <code>cache_put</code> resets TTL</li> </ul> <p>Common TTL patterns:</p> <pre><code>// Short-lived session (5 minutes)\nclient.cache_put(\"sessions\", key, data, Some(300_000)).await?;\n\n// Medium-lived cache (1 hour)\nclient.cache_put(\"user-profiles\", key, data, Some(3600_000)).await?;\n\n// Long-lived config (24 hours)\nclient.cache_put(\"config\", key, data, Some(86400_000)).await?;\n\n// Permanent (until restart or eviction)\nclient.cache_put(\"static-data\", key, data, None).await?;\n</code></pre>"},{"location":"features/cache/#3-namespace-scoping","title":"3. Namespace Scoping","text":"<p>Cache entries are scoped to prevent collisions:</p> <p>Scope hierarchy:</p> <pre><code>(tenant_id, namespace, cache_name, key)\n</code></pre> <p>Example:</p> <pre><code>// These are completely independent entries\nclient.cache_put_scoped(\"acme\", \"prod\", \"sessions\", \"user-123\", data1, ttl).await?;\nclient.cache_put_scoped(\"acme\", \"staging\", \"sessions\", \"user-123\", data2, ttl).await?;\nclient.cache_put_scoped(\"acme\", \"prod\", \"profiles\", \"user-123\", data3, ttl).await?;\nclient.cache_put_scoped(\"other-tenant\", \"prod\", \"sessions\", \"user-123\", data4, ttl).await?;\n</code></pre> <p>Benefits:</p> <ol> <li>Isolation: Tenants can't access each other's data</li> <li>Organization: Group related entries by cache name</li> <li>Flexibility: Different TTLs/eviction per cache</li> <li>Multi-tenancy: Safe shared infrastructure</li> </ol>"},{"location":"features/cache/#4-request-pipelining","title":"4. Request Pipelining","text":"<p>Send multiple cache requests without waiting for responses:</p> <pre><code>use futures::future::join_all;\n\n// Issue 10 concurrent gets\nlet futures = (0..10).map(|i| {\n    let key = format!(\"key-{}\", i);\n    client.cache_get(\"config\", &amp;key)\n});\n\n// Await all responses\nlet results: Vec&lt;Option&lt;Vec&lt;u8&gt;&gt;&gt; = join_all(futures).await\n    .into_iter()\n    .collect::&lt;Result&lt;Vec&lt;_&gt;&gt;&gt;()?;\n</code></pre> <p>Performance benefit:</p> Pattern Latency (10 ops) Throughput Sequential 1.7 ms 5.9k ops/sec Pipelined 350 \u00b5s 28.6k ops/sec <p>Pipelining works because:</p> <ul> <li>Each request has unique <code>request_id</code></li> <li>Broker may respond out of order</li> <li>Client correlates responses using <code>request_id</code></li> <li>QUIC multiplexing eliminates HOL blocking</li> </ul>"},{"location":"features/cache/#5-stream-pooling","title":"5. Stream Pooling","text":"<p>Felix uses stream pooling for high-concurrency cache workloads:</p> <pre><code># Client configuration\ncache_conn_pool: 8              # QUIC connections\ncache_streams_per_conn: 4       # Streams per connection\n# Total concurrent operations: 8 \u00d7 4 = 32\n</code></pre> <p>Why pooling matters:</p> <p>Without pooling (single stream): - All requests serialize on one stream - HOL blocking if any request is slow - Limited throughput</p> <p>With pooling: - Requests distributed across streams - Independent flow control per stream - 10-20x throughput improvement</p> <p>Performance comparison:</p> Config Concurrency p50 p99 Throughput 1 conn, 1 stream 1 165 \u00b5s 320 \u00b5s 6k ops/sec 4 conn, 2 streams 8 170 \u00b5s 380 \u00b5s 45k ops/sec 8 conn, 4 streams 32 175 \u00b5s 400 \u00b5s 180k ops/sec 16 conn, 8 streams 128 190 \u00b5s 480 \u00b5s 650k ops/sec"},{"location":"features/cache/#6-consistency-model","title":"6. Consistency Model","text":"<p>Felix cache provides read-your-writes consistency:</p> <pre><code>// Put value\nclient.cache_put(\"data\", \"key\", b\"value-1\", None).await?;\n\n// Immediately read (same client)\nassert_eq!(\n    client.cache_get(\"data\", \"key\").await?,\n    Some(b\"value-1\".to_vec())\n);\n</code></pre> <p>Consistency guarantees:</p> <ol> <li>Read-your-writes: Client sees its own writes immediately</li> <li>Monotonic reads: Never see older value after newer one (same session)</li> <li>Eventual consistency: All clients eventually see latest value</li> <li>No torn writes: Writes are atomic</li> </ol> <p>No linearizability: Concurrent writes from different clients may see inconsistent ordering.</p> <pre><code>sequenceDiagram\n    participant C1 as Client 1\n    participant C2 as Client 2\n    participant B as Broker\n\n    par Concurrent writes\n        C1-&gt;&gt;B: put(key=X, value=A)\n    and\n        C2-&gt;&gt;B: put(key=X, value=B)\n    end\n\n    Note over B: Last write wins (order undefined)\n\n    C1-&gt;&gt;B: get(key=X)\n    B--&gt;&gt;C1: value=A or B (undefined)</code></pre>"},{"location":"features/cache/#7-eviction-mvp-best-effort","title":"7. Eviction (MVP: Best-Effort)","text":"<p>Current eviction policy: Best-effort under memory pressure.</p> <ul> <li>No guaranteed LRU or LFU</li> <li>Eviction is opportunistic</li> <li>Applications should not rely on specific eviction order</li> </ul> <p>Planned eviction policies (future):</p> <pre><code>caches:\n  - tenant: acme\n    namespace: prod\n    cache: sessions\n    max_entries: 100000\n    max_bytes: 1GB\n    eviction_policy: lru  # or lfu, random, ttl_only\n</code></pre> <p>Eviction strategies:</p> <ul> <li>LRU (Least Recently Used): Evict oldest accessed entry</li> <li>LFU (Least Frequently Used): Evict least accessed entry</li> <li>TTL-only: Never evict, rely on expiration</li> <li>Random: Random eviction (fastest, good for large caches)</li> </ul>"},{"location":"features/cache/#api-reference","title":"API Reference","text":""},{"location":"features/cache/#cache_put","title":"cache_put","text":"<p>Store a key-value pair with optional TTL.</p> <p>Signature:</p> <pre><code>async fn cache_put(\n    &amp;self,\n    cache_name: &amp;str,\n    key: &amp;str,\n    value: impl AsRef&lt;[u8]&gt;,\n    ttl_ms: Option&lt;u64&gt;\n) -&gt; Result&lt;()&gt;\n</code></pre> <p>Parameters:</p> <ul> <li><code>cache_name</code>: Cache namespace (e.g., \"sessions\", \"config\")</li> <li><code>key</code>: Cache key (arbitrary string)</li> <li><code>value</code>: Value to store (binary data)</li> <li><code>ttl_ms</code>: Optional TTL in milliseconds (None = no expiration)</li> </ul> <p>Returns: <code>Ok(())</code> on success, error on failure</p> <p>Example:</p> <pre><code>// Store with 30-minute TTL\nclient.cache_put(\n    \"sessions\",\n    \"session-xyz\",\n    &amp;session_data,\n    Some(1800_000)\n).await?;\n</code></pre>"},{"location":"features/cache/#cache_get","title":"cache_get","text":"<p>Retrieve a value from the cache.</p> <p>Signature:</p> <pre><code>async fn cache_get(\n    &amp;self,\n    cache_name: &amp;str,\n    key: &amp;str\n) -&gt; Result&lt;Option&lt;Vec&lt;u8&gt;&gt;&gt;\n</code></pre> <p>Parameters:</p> <ul> <li><code>cache_name</code>: Cache namespace</li> <li><code>key</code>: Cache key to retrieve</li> </ul> <p>Returns:</p> <ul> <li><code>Ok(Some(value))</code>: Key found, value returned</li> <li><code>Ok(None)</code>: Key not found or expired</li> <li><code>Err(e)</code>: Operation failed</li> </ul> <p>Example:</p> <pre><code>match client.cache_get(\"sessions\", \"session-xyz\").await? {\n    Some(data) =&gt; {\n        let session: Session = deserialize(&amp;data)?;\n        // Use session\n    }\n    None =&gt; {\n        return Err(\"Session expired or not found\");\n    }\n}\n</code></pre>"},{"location":"features/cache/#use-cases","title":"Use Cases","text":""},{"location":"features/cache/#1-session-management","title":"1. Session Management","text":"<p>Store user sessions with automatic expiration:</p> <pre><code>struct SessionStore {\n    client: Arc&lt;Client&gt;,\n}\n\nimpl SessionStore {\n    async fn create_session(&amp;self, user_id: &amp;str) -&gt; Result&lt;String&gt; {\n        let session_id = generate_session_id();\n        let session = Session {\n            user_id: user_id.to_string(),\n            created_at: Utc::now(),\n            expires_at: Utc::now() + Duration::minutes(30),\n        };\n\n        // Store with 30-minute TTL\n        self.client.cache_put(\n            \"sessions\",\n            &amp;session_id,\n            &amp;serialize(&amp;session)?,\n            Some(1800_000)\n        ).await?;\n\n        Ok(session_id)\n    }\n\n    async fn get_session(&amp;self, session_id: &amp;str) -&gt; Result&lt;Option&lt;Session&gt;&gt; {\n        match self.client.cache_get(\"sessions\", session_id).await? {\n            Some(data) =&gt; Ok(Some(deserialize(&amp;data)?)),\n            None =&gt; Ok(None),\n        }\n    }\n\n    async fn extend_session(&amp;self, session_id: &amp;str) -&gt; Result&lt;()&gt; {\n        if let Some(mut session) = self.get_session(session_id).await? {\n            session.expires_at = Utc::now() + Duration::minutes(30);\n            self.client.cache_put(\n                \"sessions\",\n                session_id,\n                &amp;serialize(&amp;session)?,\n                Some(1800_000)\n            ).await?;\n        }\n        Ok(())\n    }\n}\n</code></pre>"},{"location":"features/cache/#2-configuration-cache","title":"2. Configuration Cache","text":"<p>Cache application configuration with refresh:</p> <pre><code>struct ConfigCache {\n    client: Arc&lt;Client&gt;,\n}\n\nimpl ConfigCache {\n    async fn get_config(&amp;self, key: &amp;str) -&gt; Result&lt;Config&gt; {\n        // Try cache first\n        if let Some(data) = self.client.cache_get(\"config\", key).await? {\n            return Ok(deserialize(&amp;data)?);\n        }\n\n        // Cache miss: load from database\n        let config = self.load_from_db(key).await?;\n\n        // Store in cache with 1-hour TTL\n        self.client.cache_put(\n            \"config\",\n            key,\n            &amp;serialize(&amp;config)?,\n            Some(3600_000)\n        ).await?;\n\n        Ok(config)\n    }\n\n    async fn update_config(&amp;self, key: &amp;str, config: &amp;Config) -&gt; Result&lt;()&gt; {\n        // Update database\n        self.save_to_db(key, config).await?;\n\n        // Invalidate cache (put with 0 TTL or delete when available)\n        self.client.cache_put(\n            \"config\",\n            key,\n            &amp;serialize(config)?,\n            Some(0)  // Immediate expiration\n        ).await?;\n\n        Ok(())\n    }\n}\n</code></pre>"},{"location":"features/cache/#3-rate-limiting","title":"3. Rate Limiting","text":"<p>Simple rate limiting with TTL:</p> <pre><code>struct RateLimiter {\n    client: Arc&lt;Client&gt;,\n    limit: u32,\n    window_ms: u64,\n}\n\nimpl RateLimiter {\n    async fn check_rate_limit(&amp;self, user_id: &amp;str) -&gt; Result&lt;bool&gt; {\n        let key = format!(\"rate-limit:{}\", user_id);\n\n        // Try to get current count\n        let count = match self.client.cache_get(\"rate-limits\", &amp;key).await? {\n            Some(data) =&gt; u32::from_be_bytes(data.try_into().unwrap()),\n            None =&gt; 0,\n        };\n\n        if count &gt;= self.limit {\n            return Ok(false);  // Rate limit exceeded\n        }\n\n        // Increment count\n        let new_count = count + 1;\n        self.client.cache_put(\n            \"rate-limits\",\n            &amp;key,\n            &amp;new_count.to_be_bytes(),\n            Some(self.window_ms)\n        ).await?;\n\n        Ok(true)  // Allow request\n    }\n}\n</code></pre> <p>Better Rate Limiting</p> <p>For production rate limiting, atomic increment operations (planned) will avoid race conditions. Current approach is best-effort.</p>"},{"location":"features/cache/#4-temporary-data-storage","title":"4. Temporary Data Storage","text":"<p>Store temporary computation results:</p> <pre><code>async fn expensive_computation(\n    client: &amp;Client,\n    input: &amp;str\n) -&gt; Result&lt;String&gt; {\n    let cache_key = format!(\"computation:{}\", hash(input));\n\n    // Check cache\n    if let Some(cached) = client.cache_get(\"temp\", &amp;cache_key).await? {\n        return Ok(String::from_utf8(cached)?);\n    }\n\n    // Perform computation\n    let result = perform_expensive_work(input)?;\n\n    // Cache for 5 minutes\n    client.cache_put(\n        \"temp\",\n        &amp;cache_key,\n        result.as_bytes(),\n        Some(300_000)\n    ).await?;\n\n    Ok(result)\n}\n</code></pre>"},{"location":"features/cache/#performance-tuning","title":"Performance Tuning","text":""},{"location":"features/cache/#client-configuration","title":"Client Configuration","text":"<p>Latency-optimized (low concurrency):</p> <pre><code>let config = ClientConfig {\n    cache_conn_pool: 2,\n    cache_streams_per_conn: 2,\n    cache_queue_size: 256,\n    ..Default::default()\n};\n</code></pre> <p>Throughput-optimized (high concurrency):</p> <pre><code>let config = ClientConfig {\n    cache_conn_pool: 16,\n    cache_streams_per_conn: 8,\n    cache_queue_size: 4096,\n    ..Default::default()\n};\n</code></pre>"},{"location":"features/cache/#broker-configuration","title":"Broker Configuration","text":"<pre><code># QUIC flow control\ncache_conn_recv_window: 268435456    # 256 MiB per connection\ncache_stream_recv_window: 67108864   # 64 MiB per stream\ncache_send_window: 268435456         # Send window\n\n# Capacity (future)\ncache_max_entries: 10000000          # 10M entries\ncache_max_bytes: 10737418240         # 10 GB\n</code></pre>"},{"location":"features/cache/#limitations-and-planned-features","title":"Limitations and Planned Features","text":""},{"location":"features/cache/#current-limitations-mvp","title":"Current Limitations (MVP)","text":"<ol> <li>No persistence: Cache is ephemeral, lost on broker restart</li> <li>No atomic operations: No compare-and-swap, increment</li> <li>No multi-key operations: No transactions</li> <li>No explicit delete: Use TTL=0 as workaround</li> <li>Best-effort eviction: No guaranteed LRU/LFU</li> <li>No cache invalidation broadcast: Manual coordination needed</li> </ol>"},{"location":"features/cache/#planned-features","title":"Planned Features","text":"<p>Atomic operations:</p> <pre><code>// Increment counter\nclient.cache_increment(\"counters\", \"page-views\", 1).await?;\n\n// Compare-and-swap\nclient.cache_cas(\n    \"locks\",\n    \"resource-a\",\n    expected_value,\n    new_value\n).await?;\n</code></pre> <p>Watch and notify:</p> <pre><code>// Watch for changes\nlet mut watch = client.cache_watch(\"config\", \"app-settings\").await?;\nwhile let Some(update) = watch.next().await {\n    reload_config(update.value);\n}\n</code></pre> <p>Multi-key operations:</p> <pre><code>// Batch get\nlet keys = vec![\"key1\", \"key2\", \"key3\"];\nlet values = client.cache_get_batch(\"data\", &amp;keys).await?;\n\n// Transaction\nclient.cache_transaction()\n    .put(\"accounts\", \"alice\", decrease(100))\n    .put(\"accounts\", \"bob\", increase(100))\n    .commit()\n    .await?;\n</code></pre> <p>Explicit delete:</p> <pre><code>client.cache_delete(\"sessions\", \"expired-session\").await?;\n</code></pre>"},{"location":"features/cache/#best-practices","title":"Best Practices","text":"<ol> <li>Choose appropriate TTLs: Match data staleness tolerance</li> <li>Use namespaces: Organize by data type and lifetime</li> <li>Handle misses gracefully: Cache is best-effort, not guaranteed</li> <li>Don't cache huge values: Keep values &lt; 1 MB for best performance</li> <li>Pipeline requests: Send multiple requests concurrently</li> <li>Monitor hit rates: Track effectiveness of caching strategy</li> <li>Design for cache failures: Always have fallback to source of truth</li> </ol>"},{"location":"features/cache/#monitoring","title":"Monitoring","text":"<p>Key metrics to track:</p> <ul> <li>Hit rate (gets that return data / total gets)</li> <li>Miss rate (gets that return None / total gets)</li> <li>Put rate (puts per second)</li> <li>Get rate (gets per second)</li> <li>Average latency (p50, p99, p999)</li> <li>Cache size (entries, bytes)</li> <li>Eviction rate</li> </ul> <p>Example monitoring (future API):</p> <pre><code>let stats = client.cache_stats(\"sessions\").await?;\nprintln!(\"Hit rate: {:.2}%\", stats.hit_rate * 100.0);\nprintln!(\"Size: {} entries, {} MB\", stats.entry_count, stats.size_bytes / 1_000_000);\nprintln!(\"p99 get latency: {:?}\", stats.get_p99);\n</code></pre> <p>Cache as Acceleration, Not Truth</p> <p>Design systems to work without the cache (loading from database). Use cache purely for performance improvement. This makes failures and evictions non-critical.</p>"},{"location":"features/observability/","title":"Observability","text":"<p>Felix provides comprehensive observability through structured logging, optional telemetry, and metrics exposure. This document covers logging configuration, performance telemetry, monitoring integration, and operational debugging.</p>"},{"location":"features/observability/#logging","title":"Logging","text":"<p>Felix uses structured logging for all operational events, making it easy to parse, filter, and analyze logs in production environments.</p>"},{"location":"features/observability/#log-levels","title":"Log Levels","text":"<p>Felix supports standard log levels:</p> <ul> <li>ERROR: Critical failures requiring immediate attention</li> <li>WARN: Degraded behavior or approaching limits</li> <li>INFO: Normal operational events (default)</li> <li>DEBUG: Detailed diagnostic information</li> <li>TRACE: Very verbose, includes per-request details</li> </ul>"},{"location":"features/observability/#configuration","title":"Configuration","text":"<p>Environment variable:</p> <pre><code>RUST_LOG=info                         # Default: info level for all modules\nRUST_LOG=felix_broker=debug           # Debug level for broker only\nRUST_LOG=felix_broker=trace,felix_wire=debug  # Multiple modules\n</code></pre> <p>Structured output (JSON):</p> <pre><code>FELIX_LOG_FORMAT=json                 # JSON structured logs\n</code></pre> <p>Example JSON log:</p> <pre><code>{\n  \"timestamp\": \"2026-01-15T10:30:45.123Z\",\n  \"level\": \"INFO\",\n  \"target\": \"felix_broker\",\n  \"message\": \"Subscription created\",\n  \"fields\": {\n    \"tenant_id\": \"acme-corp\",\n    \"namespace\": \"production\",\n    \"stream\": \"orders\",\n    \"subscription_id\": \"sub-abc-123\",\n    \"subscriber_addr\": \"10.0.1.45:52341\"\n  }\n}\n</code></pre>"},{"location":"features/observability/#key-log-events","title":"Key Log Events","text":"<p>Broker startup:</p> <pre><code>INFO felix_broker: Broker starting\nINFO felix_broker: QUIC listening on 0.0.0.0:5000\nINFO felix_broker: Control plane sync disabled (MVP mode)\nINFO felix_broker: Broker ready\n</code></pre> <p>Connection events:</p> <pre><code>INFO felix_broker: New connection from 10.0.1.45:52341\nDEBUG felix_broker: Control stream opened stream_id=0\nINFO felix_broker: Connection closed duration=45.2s\n</code></pre> <p>Publish events:</p> <pre><code>DEBUG felix_broker: Publish received tenant=acme ns=prod stream=orders batch_size=64\nDEBUG felix_broker: Fanout complete stream=orders subscribers=12 duration_us=180\n</code></pre> <p>Subscribe events:</p> <pre><code>INFO felix_broker: Subscription created tenant=acme ns=prod stream=orders subscription_id=sub-123\nWARN felix_broker: Subscriber falling behind subscription_id=sub-123 queue_depth=980/1024\nWARN felix_broker: Events dropped for subscriber subscription_id=sub-123 dropped=15\n</code></pre> <p>Cache events:</p> <pre><code>DEBUG felix_broker: Cache put key=session:user-abc ttl_ms=3600000\nDEBUG felix_broker: Cache get key=session:user-abc result=hit\nDEBUG felix_broker: Cache get key=session:user-xyz result=miss\n</code></pre> <p>Error events:</p> <pre><code>ERROR felix_broker: Unknown tenant in publish request tenant=unknown-tenant\nERROR felix_broker: Publish queue timeout after 2000ms\nWARN felix_broker: QUIC connection error error=\"connection lost\"\n</code></pre>"},{"location":"features/observability/#log-aggregation","title":"Log Aggregation","text":"<p>Felix logs integrate seamlessly with log aggregation systems:</p> <p>Fluentd/Fluent Bit:</p> <pre><code>&lt;source&gt;\n  @type tail\n  path /var/log/felix/broker.log\n  pos_file /var/log/felix/broker.log.pos\n  tag felix.broker\n  &lt;parse&gt;\n    @type json\n    time_key timestamp\n    time_format %Y-%m-%dT%H:%M:%S.%LZ\n  &lt;/parse&gt;\n&lt;/source&gt;\n\n&lt;match felix.**&gt;\n  @type elasticsearch\n  host elasticsearch.example.com\n  port 9200\n  index_name felix\n&lt;/match&gt;\n</code></pre> <p>Promtail/Loki:</p> <pre><code>clients:\n  - url: http://loki:3100/loki/api/v1/push\n\nscrape_configs:\n  - job_name: felix\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: felix-broker\n          __path__: /var/log/felix/*.log\n    pipeline_stages:\n      - json:\n          expressions:\n            level: level\n            message: message\n            tenant_id: fields.tenant_id\n</code></pre>"},{"location":"features/observability/#telemetry","title":"Telemetry","text":"<p>Felix supports optional telemetry for detailed performance profiling. Telemetry is disabled by default to avoid overhead.</p>"},{"location":"features/observability/#enabling-telemetry","title":"Enabling Telemetry","text":"<p>Compile-time:</p> <pre><code>[dependencies]\nfelix-broker = { version = \"0.1\", features = [\"telemetry\"] }\nfelix-client = { version = \"0.1\", features = [\"telemetry\"] }\n</code></pre> <p>Runtime (broker):</p> <pre><code># Broker config\ndisable_timings: false                 # Enable timing measurements\n</code></pre> <p>Performance Impact</p> <p>Telemetry adds 5-15% overhead in high-throughput scenarios. Use for profiling and debugging only, not in production hot paths.</p>"},{"location":"features/observability/#telemetry-metrics","title":"Telemetry Metrics","text":"<p>Client-side metrics:</p> <pre><code>use felix_client::{frame_counters_snapshot, timings};\n\n// Frame counters\nlet counters = frame_counters_snapshot();\nprintln!(\"Publish frames sent: {}\", counters.publish_frames);\nprintln!(\"Event frames received: {}\", counters.event_frames);\nprintln!(\"Cache put frames: {}\", counters.cache_put_frames);\nprintln!(\"Cache get frames: {}\", counters.cache_get_frames);\n\n// Timing histograms\nlet publish_timings = timings::publish_timings_snapshot();\nprintln!(\"Publish p50: {:?}\", publish_timings.p50);\nprintln!(\"Publish p99: {:?}\", publish_timings.p99);\nprintln!(\"Publish p999: {:?}\", publish_timings.p999);\n</code></pre> <p>Broker-side metrics (future):</p> <ul> <li>Per-stream publish rate</li> <li>Per-subscription delivery rate</li> <li>Queue depth samples</li> <li>Fanout timing breakdown</li> <li>QUIC flow control events</li> </ul>"},{"location":"features/observability/#telemetry-use-cases","title":"Telemetry Use Cases","text":"<p>Profiling publish latency:</p> <pre><code>// Enable telemetry\nlet config = ClientConfig::default();\nlet client = Client::connect(\"https://broker:5000\", config).await?;\n\n// Run workload\nfor _ in 0..10000 {\n    client.publish(\"tenant\", \"ns\", \"stream\", data).await?;\n}\n\n// Analyze results\nlet timings = felix_client::timings::publish_timings_snapshot();\nprintln!(\"Publish latency:\");\nprintln!(\"  p50:  {:?}\", timings.p50);\nprintln!(\"  p95:  {:?}\", timings.p95);\nprintln!(\"  p99:  {:?}\", timings.p99);\nprintln!(\"  p999: {:?}\", timings.p999);\n</code></pre> <p>Identifying bottlenecks:</p> <pre><code>// Instrument different stages\n// (requires broker-side telemetry support)\n\n// Stage 1: Wire encode\nlet encode_timings = telemetry::encode_timings();\n\n// Stage 2: QUIC send\nlet quic_timings = telemetry::quic_send_timings();\n\n// Stage 3: Broker enqueue\nlet enqueue_timings = telemetry::enqueue_timings();\n\n// Stage 4: Fanout processing\nlet fanout_timings = telemetry::fanout_timings();\n\n// Find slowest stage\n</code></pre>"},{"location":"features/observability/#metrics-planned","title":"Metrics (Planned)","text":"<p>Felix will expose metrics in Prometheus format for integration with standard monitoring stacks.</p>"},{"location":"features/observability/#metrics-endpoint","title":"Metrics Endpoint","text":"<pre><code># Broker config\nmetrics_bind: \"0.0.0.0:8080\"           # Prometheus metrics endpoint\n</code></pre> <p>Scrape configuration:</p> <pre><code># prometheus.yml\nscrape_configs:\n  - job_name: 'felix-broker'\n    static_configs:\n      - targets: ['broker-1:8080', 'broker-2:8080', 'broker-3:8080']\n</code></pre>"},{"location":"features/observability/#metric-types","title":"Metric Types","text":"<p>Pub/Sub metrics:</p> <pre><code># Publish operations\nfelix_publish_total{tenant, namespace, stream}              # Counter\nfelix_publish_bytes_total{tenant, namespace, stream}        # Counter\nfelix_publish_latency_seconds{tenant, namespace, stream}    # Histogram\nfelix_publish_errors_total{tenant, namespace, stream, error_type}  # Counter\n\n# Subscribe operations\nfelix_subscriptions_active{tenant, namespace, stream}       # Gauge\nfelix_events_delivered_total{tenant, namespace, stream}     # Counter\nfelix_events_dropped_total{tenant, namespace, stream}       # Counter\nfelix_subscriber_lag_messages{subscription_id}              # Gauge\n\n# Queue depths\nfelix_publish_queue_depth                                   # Gauge\nfelix_event_queue_depth{subscription_id}                    # Gauge\n</code></pre> <p>Cache metrics:</p> <pre><code># Cache operations\nfelix_cache_puts_total{tenant, namespace, cache}            # Counter\nfelix_cache_gets_total{tenant, namespace, cache, result}    # Counter (hit/miss)\nfelix_cache_latency_seconds{operation, tenant, namespace}   # Histogram\n\n# Cache state\nfelix_cache_entries{tenant, namespace, cache}               # Gauge\nfelix_cache_bytes{tenant, namespace, cache}                 # Gauge\nfelix_cache_evictions_total{tenant, namespace, cache}       # Counter\n</code></pre> <p>System metrics:</p> <pre><code># Connections\nfelix_connections_active                                    # Gauge\nfelix_connections_total                                     # Counter\nfelix_connection_errors_total{error_type}                   # Counter\n\n# QUIC metrics\nfelix_quic_streams_active{stream_type}                      # Gauge\nfelix_quic_packets_sent_total                               # Counter\nfelix_quic_packets_lost_total                               # Counter\nfelix_quic_flow_control_blocked_total                       # Counter\n\n# Resource usage\nfelix_memory_bytes{type}                                    # Gauge (heap, stack, mmap)\nfelix_cpu_seconds_total                                     # Counter\nfelix_goroutines                                            # Gauge\n</code></pre>"},{"location":"features/observability/#grafana-dashboards","title":"Grafana Dashboards","text":"<p>Example dashboard queries:</p> <pre><code># Publish rate\nrate(felix_publish_total[1m])\n\n# p99 publish latency\nhistogram_quantile(0.99, rate(felix_publish_latency_seconds_bucket[5m]))\n\n# Cache hit rate\nrate(felix_cache_gets_total{result=\"hit\"}[5m]) / \n  rate(felix_cache_gets_total[5m])\n\n# Subscriber lag\nfelix_subscriber_lag_messages\n\n# Dropped events\nrate(felix_events_dropped_total[5m])\n</code></pre> <p>Pre-built dashboards (planned):</p> <ul> <li>Felix Overview (system health, throughput, latency)</li> <li>Pub/Sub Deep Dive (per-stream metrics, fanout performance)</li> <li>Cache Performance (hit rates, latency, size)</li> <li>System Resources (CPU, memory, network, QUIC metrics)</li> </ul>"},{"location":"features/observability/#health-checks","title":"Health Checks","text":"<p>HTTP health endpoint:</p> <pre><code>curl http://broker:8080/health\n</code></pre> <p>Response:</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"version\": \"0.1.0\",\n  \"uptime_seconds\": 3600,\n  \"checks\": {\n    \"quic_listener\": \"ok\",\n    \"memory_usage\": \"ok\",\n    \"queue_depths\": \"ok\"\n  }\n}\n</code></pre> <p>Kubernetes liveness probe:</p> <pre><code>livenessProbe:\n  httpGet:\n    path: /health\n    port: 8080\n  initialDelaySeconds: 10\n  periodSeconds: 30\n</code></pre> <p>Readiness probe:</p> <pre><code>readinessProbe:\n  httpGet:\n    path: /ready\n    port: 8080\n  initialDelaySeconds: 5\n  periodSeconds: 10\n</code></pre>"},{"location":"features/observability/#distributed-tracing-future","title":"Distributed Tracing (Future)","text":"<p>Felix will support OpenTelemetry for distributed tracing:</p> <p>Configuration:</p> <pre><code>tracing:\n  enabled: true\n  exporter: otlp\n  endpoint: http://otel-collector:4317\n  sample_rate: 0.1                     # Sample 10% of requests\n</code></pre> <p>Example trace:</p> <pre><code>Publish Request (trace_id: abc123)\n\u251c\u2500 Wire Encode         120 \u00b5s\n\u251c\u2500 QUIC Send           80 \u00b5s\n\u251c\u2500 Broker Receive      50 \u00b5s\n\u251c\u2500 Enqueue             30 \u00b5s\n\u251c\u2500 Fanout Processing   150 \u00b5s\n\u2502  \u251c\u2500 Subscriber 1     45 \u00b5s\n\u2502  \u251c\u2500 Subscriber 2     48 \u00b5s\n\u2502  \u2514\u2500 Subscriber 3     43 \u00b5s\n\u2514\u2500 Ack Send            40 \u00b5s\nTotal: 470 \u00b5s\n</code></pre>"},{"location":"features/observability/#alerting","title":"Alerting","text":""},{"location":"features/observability/#recommended-alerts","title":"Recommended Alerts","text":"<p>Critical alerts (page immediately):</p> <pre><code>- alert: BrokerDown\n  expr: up{job=\"felix-broker\"} == 0\n  for: 1m\n\n- alert: HighPublishErrorRate\n  expr: rate(felix_publish_errors_total[5m]) &gt; 10\n  for: 2m\n\n- alert: MemoryExhaustion\n  expr: felix_memory_bytes{type=\"heap\"} &gt; 0.9 * felix_memory_limit_bytes\n  for: 5m\n</code></pre> <p>Warning alerts (investigate soon):</p> <pre><code>- alert: HighP99Latency\n  expr: histogram_quantile(0.99, rate(felix_publish_latency_seconds_bucket[5m])) &gt; 0.01\n  for: 10m\n\n- alert: HighDropRate\n  expr: rate(felix_events_dropped_total[5m]) / rate(felix_publish_total[5m]) &gt; 0.001\n  for: 5m\n\n- alert: HighQueueDepth\n  expr: felix_publish_queue_depth &gt; 0.8 * felix_publish_queue_capacity\n  for: 5m\n</code></pre>"},{"location":"features/observability/#on-call-runbooks","title":"On-Call Runbooks","text":"<p>High latency:</p> <ol> <li>Check Grafana dashboard for bottleneck</li> <li>Check queue depths - are they filling?</li> <li>Check subscriber lag - slow subscribers?</li> <li>Check CPU/memory - resource exhausted?</li> <li>Consider scaling horizontally or tuning config</li> </ol> <p>Dropped events:</p> <ol> <li>Identify which subscriptions are dropping</li> <li>Check subscriber lag for those subscriptions</li> <li>Check subscriber application logs - slow processing?</li> <li>Consider increasing <code>event_queue_depth</code> or fixing subscriber performance</li> </ol> <p>Memory pressure:</p> <ol> <li>Check cache size - growing unbounded?</li> <li>Check queue depths - deep queues holding large payloads?</li> <li>Check connection count - too many connections?</li> <li>Consider reducing flow control windows or adding memory</li> </ol>"},{"location":"features/observability/#operational-debugging","title":"Operational Debugging","text":""},{"location":"features/observability/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"<p>Issue: Subscribers not receiving events</p> <p>Debug steps:</p> <ol> <li>Check broker logs for subscription creation</li> <li>Verify tenant/namespace/stream exist</li> <li>Check network connectivity from subscriber</li> <li>Check subscriber application is calling <code>subscription.next()</code></li> <li>Enable DEBUG logging to see event delivery</li> </ol> <p>Issue: High publish latency</p> <p>Debug steps:</p> <ol> <li>Enable telemetry on client</li> <li>Check where time is spent (encode, send, ack)</li> <li>Check broker queue depth - backing up?</li> <li>Check CPU usage on broker - saturated?</li> <li>Consider tuning <code>pub_workers_per_conn</code> or batching</li> </ol> <p>Issue: Cache misses unexpectedly</p> <p>Debug steps:</p> <ol> <li>Check TTL - has entry expired?</li> <li>Check broker restart - cache is ephemeral</li> <li>Check key spelling - exact match required</li> <li>Enable DEBUG logging to see cache lookups</li> <li>Verify tenant/namespace/cache scope is correct</li> </ol>"},{"location":"features/observability/#diagnostic-tools","title":"Diagnostic Tools","text":"<p>Connection debugging:</p> <pre><code># Check QUIC connectivity\nnc -uz broker-ip 5000\n\n# Check TLS certificate\nopenssl s_client -connect broker-ip:5000 -showcerts\n</code></pre> <p>Log analysis:</p> <pre><code># Filter by level\ncat broker.log | jq 'select(.level == \"ERROR\")'\n\n# Filter by tenant\ncat broker.log | jq 'select(.fields.tenant_id == \"acme-corp\")'\n\n# Count errors by type\ncat broker.log | jq -r 'select(.level == \"ERROR\") | .message' | sort | uniq -c\n</code></pre> <p>Performance profiling:</p> <pre><code># CPU profiling (future)\ncurl http://broker:8080/debug/pprof/profile?seconds=30 &gt; cpu.prof\n\n# Memory profiling (future)\ncurl http://broker:8080/debug/pprof/heap &gt; heap.prof\n</code></pre>"},{"location":"features/observability/#best-practices","title":"Best Practices","text":"<ol> <li>\u2713 Use INFO level in production</li> <li>\u2713 Enable JSON logs for structured parsing</li> <li>\u2713 Centralize logs in aggregation system</li> <li>\u2713 Monitor key metrics (latency, throughput, errors)</li> <li>\u2713 Set up alerts for critical conditions</li> <li>\u2713 Enable telemetry only for debugging</li> <li>\u2713 Document baseline performance metrics</li> <li>\u2713 Create runbooks for common issues</li> <li>\u2713 Test monitoring and alerting before production</li> <li>\u2713 Review logs and metrics weekly</li> </ol> <p>Observability is Essential</p> <p>Felix is designed to be observable. Structured logs, metrics, and telemetry make it possible to understand system behavior, debug issues quickly, and optimize performance with confidence.</p>"},{"location":"features/performance/","title":"Performance Tuning","text":"<p>Felix is designed for predictable low-latency performance with tunable trade-offs between latency, throughput, and memory usage. This guide provides comprehensive performance tuning guidance based on real benchmarks and production-tested configurations.</p>"},{"location":"features/performance/#understanding-felix-performance","title":"Understanding Felix Performance","text":"<p>Felix performance is determined by several interconnected factors:</p> <ol> <li>Network transport: QUIC connection and stream configuration</li> <li>Batching: Message aggregation at publish and delivery stages</li> <li>Parallelism: Connection pools and worker threads</li> <li>Buffering: Queue depths and flow control windows</li> <li>Encoding: JSON vs binary wire format</li> </ol>"},{"location":"features/performance/#performance-profiles","title":"Performance Profiles","text":"<p>Felix provides three pre-configured profiles as starting points.</p>"},{"location":"features/performance/#balanced-profile-default","title":"Balanced Profile (Default)","text":"<p>General-purpose settings for mixed workloads:</p> <p>Broker configuration:</p> <pre><code># Connection pools\npub_conn_pool: 4\npub_streams_per_conn: 2\nevent_conn_pool: 8\ncache_conn_pool: 8\ncache_streams_per_conn: 4\n\n# QUIC flow control\nevent_conn_recv_window: 268435456      # 256 MiB\nevent_stream_recv_window: 67108864     # 64 MiB\nevent_send_window: 268435456           # 256 MiB\n\n# Batching\nevent_batch_max_events: 64\nevent_batch_max_delay_us: 250\nfanout_batch_size: 64\n\n# Queue depths\npub_queue_depth: 1024\nevent_queue_depth: 1024\n\n# Binary mode\nevent_single_binary_enabled: false\npublish_chunk_bytes: 16384\n</code></pre> <p>Expected performance (fanout=10, batch=64, payload=4KB):</p> <ul> <li>p50 latency: 400-800 \u00b5s</li> <li>p99 latency: 2-4 ms  </li> <li>Throughput: 150-200k msg/sec per broker</li> <li>Memory: ~2-4 GB working set</li> </ul> <p>Best for: - Mixed pub/sub and cache workloads - Moderate fanout (1-20 subscribers) - General application development - Starting point for tuning</p>"},{"location":"features/performance/#latency-optimized-profile","title":"Latency-Optimized Profile","text":"<p>Minimize tail latency at the cost of throughput:</p> <p>Broker configuration:</p> <pre><code># Smaller pools\npub_conn_pool: 2\npub_streams_per_conn: 1\nevent_conn_pool: 4\n\n# Smaller windows\nevent_conn_recv_window: 67108864       # 64 MiB\nevent_stream_recv_window: 16777216     # 16 MiB\nevent_send_window: 67108864            # 64 MiB\n\n# Minimal batching\nevent_batch_max_events: 8\nevent_batch_max_delay_us: 100\nfanout_batch_size: 8\n\n# Fast acknowledgements\nack_on_commit: true\n\n# Shallow queues\npub_queue_depth: 512\nevent_queue_depth: 512\n\n# No binary mode (JSON is faster for small batches)\nevent_single_binary_enabled: false\n</code></pre> <p>Expected performance:</p> <ul> <li>p50 latency: 150-300 \u00b5s</li> <li>p99 latency: 500-1000 \u00b5s</li> <li>Throughput: 50-80k msg/sec per broker</li> <li>Memory: ~1-2 GB working set</li> </ul> <p>Best for: - Real-time interactive applications - Trading systems, gaming - Sensor data with immediate processing - Low fanout (1-5 subscribers)</p>"},{"location":"features/performance/#throughput-optimized-profile","title":"Throughput-Optimized Profile","text":"<p>Maximize throughput and burst tolerance:</p> <p>Broker configuration:</p> <pre><code># Large pools\npub_conn_pool: 8\npub_streams_per_conn: 4\nevent_conn_pool: 16\ncache_conn_pool: 16\ncache_streams_per_conn: 8\n\n# Large windows\nevent_conn_recv_window: 536870912      # 512 MiB\nevent_stream_recv_window: 134217728    # 128 MiB\nevent_send_window: 536870912           # 512 MiB\n\n# Aggressive batching\nevent_batch_max_events: 256\nevent_batch_max_delay_us: 2000\nfanout_batch_size: 256\n\n# Async acknowledgements\nack_on_commit: false\n\n# Deep queues\npub_queue_depth: 4096\nevent_queue_depth: 4096\n\n# Binary mode enabled\nevent_single_binary_enabled: true\nevent_single_binary_min_bytes: 256\npublish_chunk_bytes: 32768\n</code></pre> <p>Expected performance:</p> <ul> <li>p50 latency: 1-3 ms</li> <li>p99 latency: 5-15 ms</li> <li>Throughput: 300-500k msg/sec per broker</li> <li>Memory: ~8-16 GB working set</li> </ul> <p>Best for: - High-throughput data pipelines - Log aggregation, metrics collection - High fanout (20-100+ subscribers) - Batch processing workflows</p>"},{"location":"features/performance/#configuration-parameters","title":"Configuration Parameters","text":""},{"location":"features/performance/#pubsub-parameters","title":"Pub/Sub Parameters","text":""},{"location":"features/performance/#connection-pooling","title":"Connection Pooling","text":"<pre><code>event_conn_pool: 8              # QUIC connections for events\npub_conn_pool: 4                # QUIC connections for publishing\npub_streams_per_conn: 2         # Publish streams per connection\n</code></pre> <p>Tuning guidance:</p> Workload event_conn_pool pub_conn_pool streams_per_conn Light 2-4 2 1-2 Medium 4-8 2-4 2 Heavy 8-16 4-8 2-4 Very heavy 16-32 8-16 4-8 <p>Worker Sizing</p> <p>Set <code>pub_workers_per_conn</code> \u2264 <code>pub_streams_per_conn</code>. Excess workers create contention without benefit.</p>"},{"location":"features/performance/#flow-control-windows","title":"Flow Control Windows","text":"<pre><code>event_conn_recv_window: 268435456      # Per-connection receive window\nevent_stream_recv_window: 67108864     # Per-stream receive window\nevent_send_window: 268435456           # Per-connection send window\n</code></pre> <p>Memory impact calculation:</p> <pre><code>Worst-case memory = (conn_window \u00d7 conn_pool) + \n                    (stream_window \u00d7 avg_streams \u00d7 conn_pool)\n</code></pre> <p>Example: - <code>conn_pool=8</code>, <code>conn_window=256MB</code>, <code>stream_window=64MB</code>, <code>avg_streams=10</code> - Memory \u2248 (256MB \u00d7 8) + (64MB \u00d7 10 \u00d7 8) = 2GB + 5.1GB = 7.1GB</p> <p>Tuning guidance:</p> <ul> <li>Low latency, limited bursts: Use smaller windows (64-128 MiB)</li> <li>High throughput, bursty: Use larger windows (256-512 MiB)</li> <li>Memory constrained: Reduce pool size before reducing windows</li> </ul>"},{"location":"features/performance/#batching-parameters","title":"Batching Parameters","text":"<pre><code>event_batch_max_events: 64             # Max events per batch\nevent_batch_max_bytes: 262144          # Max batch size (256 KB)\nevent_batch_max_delay_us: 250          # Max batching delay (250 \u00b5s)\nfanout_batch_size: 64                  # Fanout batch size\n</code></pre> <p>Batch triggers: Event batch is sent when any condition is met.</p> <p>Trade-off analysis:</p> Parameter \u2191 Increase Effect \u2193 Decrease Effect <code>max_events</code> Higher throughput, higher latency Lower latency, lower throughput <code>max_delay_us</code> Higher throughput, higher latency Lower latency, lower throughput <code>max_bytes</code> Fewer frames, more efficiency More frames, less efficiency <code>fanout_batch_size</code> Better fanout efficiency Lower fanout latency <p>Recommended settings by workload:</p> <pre><code># Ultra-low latency\nevent_batch_max_events: 4\nevent_batch_max_delay_us: 50\n\n# Low latency\nevent_batch_max_events: 8\nevent_batch_max_delay_us: 100\n\n# Balanced (default)\nevent_batch_max_events: 64\nevent_batch_max_delay_us: 250\n\n# High throughput\nevent_batch_max_events: 128\nevent_batch_max_delay_us: 1000\n\n# Maximum throughput\nevent_batch_max_events: 256\nevent_batch_max_delay_us: 2000\n</code></pre>"},{"location":"features/performance/#queue-depths","title":"Queue Depths","text":"<pre><code>pub_queue_depth: 1024                  # Publish pipeline queue\nevent_queue_depth: 1024                # Per-subscriber event queue\npub_workers_per_conn: 4                # Publish workers per connection\n</code></pre> <p>Queue depth impact:</p> <ul> <li>Shallow queues (256-512): Lower memory, fail-fast backpressure, lower burst tolerance</li> <li>Medium queues (1024-2048): Balanced, good burst tolerance</li> <li>Deep queues (4096-8192): High memory, high burst tolerance, slower failure detection</li> </ul> <p>Memory per queue:</p> <pre><code>Queue memory \u2248 queue_depth \u00d7 avg_message_size\n\nExample: 1024 \u00d7 4KB = 4MB per queue\nWith 100 subscribers: 100 \u00d7 4MB = 400MB\n</code></pre>"},{"location":"features/performance/#cache-parameters","title":"Cache Parameters","text":"<pre><code>cache_conn_pool: 8                     # QUIC connections for cache\ncache_streams_per_conn: 4              # Streams per connection\ncache_conn_recv_window: 268435456      # 256 MiB per connection\ncache_stream_recv_window: 67108864     # 64 MiB per stream\n</code></pre> <p>Concurrency calculation:</p> <pre><code>Max concurrent cache ops = cache_conn_pool \u00d7 cache_streams_per_conn\n</code></pre> <p>Recommended by workload:</p> Workload conn_pool streams_per_conn Max Concurrency Low 4 2 8 Medium 8 4 32 High 16 8 128 Very high 32 16 512"},{"location":"features/performance/#binary-encoding","title":"Binary Encoding","text":"<pre><code>event_single_binary_enabled: true      # Enable binary encoding\nevent_single_binary_min_bytes: 512     # Min payload size for binary\n</code></pre> <p>Binary vs JSON performance (batch=64, fanout=10):</p> Payload Size JSON Throughput Binary Throughput Improvement 64 B 180k msg/sec 190k msg/sec +5% 256 B 170k msg/sec 205k msg/sec +20% 1 KB 140k msg/sec 195k msg/sec +39% 4 KB 80k msg/sec 115k msg/sec +44% <p>When to enable:</p> <p>\u2713 Payload sizes &gt; 512 bytes \u2713 High throughput priority \u2713 High fanout workloads \u2713 Validated binary encoding implementation  </p> <p>\u2717 Ultra-low latency priority (JSON is faster for tiny batches) \u2717 Debugging (JSON is human-readable) \u2717 Small payloads &lt; 256 bytes  </p>"},{"location":"features/performance/#benchmark-results","title":"Benchmark Results","text":""},{"location":"features/performance/#pubsub-latency-localhost","title":"Pub/Sub Latency (Localhost)","text":"<p>Configuration: Balanced profile, binary mode, fanout=10, batch=64, payload=4KB</p> Metric p50 p95 p99 p999 Publish ack 200 \u00b5s 380 \u00b5s 520 \u00b5s 850 \u00b5s End-to-end 450 \u00b5s 980 \u00b5s 1.8 ms 3.2 ms Fanout processing 120 \u00b5s 240 \u00b5s 380 \u00b5s 680 \u00b5s"},{"location":"features/performance/#pubsub-throughput","title":"Pub/Sub Throughput","text":"Fanout Batch Payload Throughput Notes 1 1 256 B 85k msg/sec Single publishes 1 64 256 B 240k msg/sec Batched 1 64 4 KB 180k msg/sec Large payloads 10 64 4 KB 170k msg/sec High fanout 100 64 4 KB 120k msg/sec Very high fanout"},{"location":"features/performance/#cache-performance-localhost","title":"Cache Performance (Localhost)","text":"<p>Configuration: 8 connections, 4 streams/conn, concurrency=32</p> Operation Payload p50 p99 Throughput put 0 B 158 \u00b5s 350 \u00b5s 184k ops/sec put 256 B 179 \u00b5s 380 \u00b5s 155k ops/sec put 4 KB 260 \u00b5s 480 \u00b5s 78k ops/sec get (hit) 256 B 177 \u00b5s 360 \u00b5s 166k ops/sec get (miss) - 165 \u00b5s 340 \u00b5s 179k ops/sec"},{"location":"features/performance/#profiling-and-diagnostics","title":"Profiling and Diagnostics","text":""},{"location":"features/performance/#telemetry-feature","title":"Telemetry Feature","text":"<p>Enable detailed performance telemetry:</p> <pre><code>[dependencies]\nfelix-client = { version = \"0.1\", features = [\"telemetry\"] }\nfelix-broker = { version = \"0.1\", features = [\"telemetry\"] }\n</code></pre> <pre><code># Broker config\ndisable_timings: false                 # Enable timing measurements\n</code></pre> <p>Metrics collected:</p> <ul> <li>Per-operation latency histograms (publish, subscribe, cache)</li> <li>Frame counters (publish frames, event frames, cache frames)</li> <li>Queue depth samples</li> <li>Flow control events</li> </ul> <p>Overhead: 5-15% throughput reduction in high-load scenarios.</p> <p>Production Use</p> <p>Disable telemetry in production for maximum throughput. Enable only for profiling and debugging specific issues.</p>"},{"location":"features/performance/#performance-debugging","title":"Performance Debugging","text":"<p>High publish latency:</p> <ol> <li>Check <code>pub_queue_depth</code> - is queue filling up?</li> <li>Check <code>pub_workers_per_conn</code> - enough workers?</li> <li>Check broker CPU usage - saturated?</li> <li>Enable telemetry - where is time spent?</li> </ol> <p>High subscribe latency:</p> <ol> <li>Check <code>event_queue_depth</code> - subscribers falling behind?</li> <li>Check <code>event_batch_delay_us</code> - batching too aggressive?</li> <li>Check QUIC flow control - windows exhausted?</li> <li>Check subscriber processing time - bottleneck in application?</li> </ol> <p>Low throughput:</p> <ol> <li>Increase <code>event_batch_max_events</code> - more aggressive batching</li> <li>Increase connection pools - more parallelism</li> <li>Enable binary mode - reduce encoding overhead</li> <li>Check network bandwidth - saturated?</li> <li>Increase <code>pub_workers_per_conn</code> - more publish parallelism</li> </ol> <p>High memory usage:</p> <ol> <li>Reduce flow control windows</li> <li>Reduce queue depths</li> <li>Reduce connection pool sizes</li> <li>Check for slow subscribers - filling buffers?</li> </ol>"},{"location":"features/performance/#production-recommendations","title":"Production Recommendations","text":""},{"location":"features/performance/#sizing-guidelines","title":"Sizing Guidelines","text":"<p>Small deployment (&lt; 10k msg/sec):</p> <pre><code>pub_conn_pool: 2\nevent_conn_pool: 4\ncache_conn_pool: 4\nevent_batch_max_events: 32\npub_queue_depth: 512\nevent_queue_depth: 512\n</code></pre> <p>Expected resources: 2 CPU cores, 2-4 GB RAM</p> <p>Medium deployment (10k-100k msg/sec):</p> <pre><code>pub_conn_pool: 4\nevent_conn_pool: 8\ncache_conn_pool: 8\nevent_batch_max_events: 64\npub_queue_depth: 1024\nevent_queue_depth: 1024\n</code></pre> <p>Expected resources: 4-8 CPU cores, 4-8 GB RAM</p> <p>Large deployment (100k-500k msg/sec):</p> <pre><code>pub_conn_pool: 8\nevent_conn_pool: 16\ncache_conn_pool: 16\nevent_batch_max_events: 128\npub_queue_depth: 2048\nevent_queue_depth: 2048\nevent_single_binary_enabled: true\n</code></pre> <p>Expected resources: 16-32 CPU cores, 16-32 GB RAM</p>"},{"location":"features/performance/#tuning-workflow","title":"Tuning Workflow","text":"<ol> <li>Start with balanced profile: Use defaults</li> <li>Measure baseline: Run realistic workload, measure latency/throughput</li> <li>Identify bottleneck: CPU? Memory? Network? Queue depths?</li> <li>Tune one parameter: Change single parameter</li> <li>Re-measure: Verify improvement</li> <li>Iterate: Repeat until requirements met</li> </ol> <p>Measure, Don't Guess</p> <p>Performance tuning without measurement leads to worse performance. Always benchmark before and after changes.</p>"},{"location":"features/performance/#monitoring-in-production","title":"Monitoring in Production","text":"<p>Key metrics to track:</p> <ul> <li>Publish rate and latency (p50, p99, p999)</li> <li>Subscribe rate and latency</li> <li>Queue depths (publish, event)</li> <li>Connection count</li> <li>CPU and memory usage</li> <li>Network bandwidth</li> <li>Dropped event count</li> <li>Slow subscriber count</li> </ul> <p>Alerting thresholds:</p> <ul> <li>p99 latency &gt; 2\u00d7 baseline</li> <li>Queue depth &gt; 80% of max</li> <li>Dropped events &gt; 0.1% of published</li> <li>CPU usage &gt; 80%</li> <li>Memory usage &gt; 85%</li> </ul>"},{"location":"features/performance/#hardware-recommendations","title":"Hardware Recommendations","text":""},{"location":"features/performance/#cpu","title":"CPU","text":"<ul> <li>Minimum: 2 cores</li> <li>Recommended: 4-8 cores for medium workloads</li> <li>High performance: 16-32 cores for high throughput</li> </ul> <p>Felix is CPU-bound for: - JSON encoding/decoding - QUIC encryption - Message batching and fanout</p>"},{"location":"features/performance/#memory","title":"Memory","text":"<ul> <li>Minimum: 2 GB</li> <li>Recommended: 4-8 GB for medium workloads</li> <li>High performance: 16-32 GB for high throughput with large queues</li> </ul> <p>Memory usage scales with: - Connection pool sizes \u00d7 flow control windows - Queue depths \u00d7 subscriber count - Cache size</p>"},{"location":"features/performance/#network","title":"Network","text":"<ul> <li>Minimum: 1 Gbps</li> <li>Recommended: 10 Gbps for high throughput</li> <li>Ideal: 25+ Gbps for very high throughput</li> </ul> <p>QUIC benefits from: - Low latency networks (&lt; 1 ms RTT) - High bandwidth - Low packet loss (&lt; 0.1%)</p>"},{"location":"features/performance/#disk","title":"Disk","text":"<ul> <li>MVP: Not used (ephemeral only)</li> <li>Future (durable mode): NVMe SSD for WAL and segments</li> </ul>"},{"location":"features/performance/#best-practices-summary","title":"Best Practices Summary","text":"<ol> <li>\u2713 Start with balanced profile, measure, then tune</li> <li>\u2713 Size connection pools for your parallelism needs</li> <li>\u2713 Use batching for throughput, minimize batching for latency</li> <li>\u2713 Enable binary mode for large payloads (&gt; 512 bytes)</li> <li>\u2713 Monitor queue depths - they reveal backpressure</li> <li>\u2713 Disable telemetry in production for maximum throughput</li> <li>\u2713 Profile before optimizing - don't guess</li> <li>\u2713 Test with realistic workloads, not synthetic benchmarks</li> <li>\u2713 Plan for 2-3\u00d7 headroom above expected load</li> <li>\u2713 Document your tuning decisions and benchmark results</li> </ol> <p>Predictable Performance</p> <p>Felix is designed for predictable p99/p999 latency under load. Tuning trades off between latency, throughput, and memory\u2014but tail latency remains controlled with proper configuration.</p>"},{"location":"features/pubsub/","title":"Publish/Subscribe Features","text":"<p>Felix provides a high-performance publish/subscribe system designed for real-time event distribution with predictable latency, high fanout, and strong isolation guarantees. This document covers the pub/sub features, delivery semantics, batching strategies, and performance characteristics.</p>"},{"location":"features/pubsub/#overview","title":"Overview","text":"<p>Felix pub/sub is built around a simple model:</p> <ul> <li>Publishers send messages to streams</li> <li>Subscribers receive all messages from streams they subscribe to</li> <li>Streams are scoped to <code>(tenant_id, namespace, stream_name)</code></li> <li>Fanout is handled efficiently by the broker</li> </ul> <pre><code>graph LR\n    P1[Publisher 1]\n    P2[Publisher 2]\n    P3[Publisher 3]\n\n    B[Broker&lt;br/&gt;Stream: orders]\n\n    S1[Subscriber 1]\n    S2[Subscriber 2]\n    S3[Subscriber 3]\n    S4[Subscriber 4]\n\n    P1 --&gt; B\n    P2 --&gt; B\n    P3 --&gt; B\n\n    B --&gt; S1\n    B --&gt; S2\n    B --&gt; S3\n    B --&gt; S4\n\n    style B fill:#fff3e0\n    style P1 fill:#e3f2fd\n    style P2 fill:#e3f2fd\n    style P3 fill:#e3f2fd\n    style S1 fill:#c8e6c9\n    style S2 fill:#c8e6c9\n    style S3 fill:#c8e6c9\n    style S4 fill:#c8e6c9</code></pre>"},{"location":"features/pubsub/#core-features","title":"Core Features","text":""},{"location":"features/pubsub/#1-high-fanout","title":"1. High Fanout","text":"<p>Felix excels at high-fanout workloads where one message must be delivered to many subscribers.</p> <p>Fanout efficiency:</p> Fanout Throughput (msg/sec) p99 Latency 1 200k 2.5 ms 10 180k 3.8 ms 100 140k 6.2 ms 1000 85k 12.5 ms <p>Fanout isolation: Slow subscribers never block fast subscribers.</p> <pre><code>// Even with 1000 subscribers, adding a slow one doesn't impact others\nlet mut fast_sub = client.subscribe(\"tenant\", \"ns\", \"stream\").await?;\nlet mut slow_sub = client.subscribe(\"tenant\", \"ns\", \"stream\").await?;\n\n// Fast subscriber continues at full rate\ntokio::spawn(async move {\n    while let Some(event) = fast_sub.next().await {\n        process_fast(event).await;  // ~1ms\n    }\n});\n\n// Slow subscriber falls behind, drops messages (at-most-once semantics)\ntokio::spawn(async move {\n    while let Some(event) = slow_sub.next().await {\n        process_slow(event).await;  // ~100ms\n    }\n});\n</code></pre>"},{"location":"features/pubsub/#2-message-batching","title":"2. Message Batching","text":"<p>Felix supports batching at multiple levels for improved throughput.</p>"},{"location":"features/pubsub/#publisher-side-batching","title":"Publisher-Side Batching","text":"<p>Batch multiple messages into a single publish operation:</p> <pre><code>// Collect messages\nlet mut batch = Vec::new();\nfor i in 0..64 {\n    batch.push(format!(\"Event {}\", i).into_bytes());\n}\n\n// Publish as batch\nclient.publish_batch(\"tenant\", \"ns\", \"stream\", batch).await?;\n</code></pre> <p>Throughput improvement:</p> Batch Size Throughput vs Single Latency 1 (single) 1x 150 \u00b5s 8 4x 180 \u00b5s 32 12x 250 \u00b5s 64 18x 350 \u00b5s 128 22x 600 \u00b5s"},{"location":"features/pubsub/#broker-side-batching","title":"Broker-Side Batching","text":"<p>The broker automatically batches events for delivery to subscribers:</p> <pre><code># Broker configuration\nevent_batch_max_events: 64         # Max events per batch\nevent_batch_max_bytes: 262144      # Max batch size (256 KB)\nevent_batch_max_delay_us: 250      # Max batching delay (250 \u00b5s)\n</code></pre> <p>Batching triggers:</p> <p>Events are sent when any condition is met: 1. <code>event_batch_max_events</code> accumulated 2. <code>event_batch_max_bytes</code> reached 3. <code>event_batch_max_delay_us</code> elapsed since first event</p> <p>Example:</p> <pre><code>gantt\n    title Event Batching Timeline\n    dateFormat SSS\n    axisFormat %L ms\n\n    section Publisher\n    Publish events       :active, 000, 050\n\n    section Broker\n    Accumulate (250\u00b5s)   :active, 050, 300\n    Flush batch          :milestone, 300, 0ms\n    Deliver to subs      :active, 300, 400</code></pre>"},{"location":"features/pubsub/#binary-batching","title":"Binary Batching","text":"<p>For maximum throughput, use binary batch encoding:</p> <pre><code># Broker configuration\nevent_single_binary_enabled: true\nevent_single_binary_min_bytes: 512\n</code></pre> <p>When enabled, events exceeding <code>event_single_binary_min_bytes</code> are encoded with the binary batch format, even for single events.</p> <p>Performance gain: 30-40% throughput improvement for large payloads.</p>"},{"location":"features/pubsub/#3-stream-ordering","title":"3. Stream Ordering","text":"<p>Felix guarantees ordering within a stream:</p> <p>Within-stream ordering:</p> <pre><code>// Publisher sends in order\nclient.publish_batch(\"tenant\", \"ns\", \"orders\", vec![\n    b\"order-1\".to_vec(),\n    b\"order-2\".to_vec(),\n    b\"order-3\".to_vec(),\n]).await?;\n\n// Subscriber receives in order\nlet mut sub = client.subscribe(\"tenant\", \"ns\", \"orders\").await?;\nassert_eq!(sub.next().await.unwrap().payload, b\"order-1\");\nassert_eq!(sub.next().await.unwrap().payload, b\"order-2\");\nassert_eq!(sub.next().await.unwrap().payload, b\"order-3\");\n</code></pre> <p>Across-stream ordering: No guarantees.</p> <pre><code>// These may arrive in any relative order\nclient.publish(\"tenant\", \"ns\", \"stream-a\", b\"msg-a\").await?;\nclient.publish(\"tenant\", \"ns\", \"stream-b\", b\"msg-b\").await?;\n</code></pre>"},{"location":"features/pubsub/#4-subscriber-isolation","title":"4. Subscriber Isolation","text":"<p>Each subscription maintains independent state:</p> <p>Per-subscription buffers:</p> <pre><code>pub struct Subscription {\n    buffer: BoundedQueue&lt;Event&gt;,  // Isolated buffer\n    event_stream: UnidirectionalStream,  // Dedicated QUIC stream\n}\n</code></pre> <p>Buffer configuration:</p> <pre><code># Broker: per-subscription buffer\nevent_queue_depth: 1024  # Default\n\n# Client: additional client-side buffer\nevent_buffer_size: 1024  # Default\n</code></pre> <p>Isolation behavior:</p> <pre><code>sequenceDiagram\n    participant P as Publisher\n    participant B as Broker\n    participant S1 as Fast Sub (buffer: 10/1024)\n    participant S2 as Slow Sub (buffer: 1024/1024 FULL)\n\n    P-&gt;&gt;B: Publish event\n\n    par Fanout\n        B-&gt;&gt;S1: Deliver (success)\n    and\n        B-xS2: Drop (buffer full)\n    end\n\n    Note over S1: Continues receiving\n    Note over S2: Drops messages until catches up</code></pre>"},{"location":"features/pubsub/#5-backpressure","title":"5. Backpressure","text":"<p>Felix applies backpressure at multiple levels:</p>"},{"location":"features/pubsub/#quic-flow-control","title":"QUIC Flow Control","text":"<p>Connection-level:</p> <pre><code>event_conn_recv_window: 268435456  # 256 MiB\n</code></pre> <p>When connection window exhausted: - Broker stops sending on that connection - Other subscriptions on other connections unaffected</p> <p>Stream-level:</p> <pre><code>event_stream_recv_window: 67108864  # 64 MiB\n</code></pre> <p>When stream window exhausted: - Broker stops sending on that stream only - Other streams continue</p>"},{"location":"features/pubsub/#application-level-buffering","title":"Application-Level Buffering","text":"<p>Publisher queue:</p> <pre><code>pub_queue_depth: 1024\npublish_queue_wait_timeout_ms: 2000\n</code></pre> <p>When publish queue full: - New publishes block up to timeout - After timeout, publish fails with error - Indicates broker overload</p> <p>Subscriber queue:</p> <pre><code>event_queue_depth: 1024\n</code></pre> <p>When subscriber queue full: - New events are dropped for that subscriber - Other subscribers unaffected</p> <p>At-Most-Once Semantics</p> <p>In MVP, dropped events are not recovered. Subscribers may miss messages if they fall behind. Future: at-least-once delivery with acknowledgements.</p>"},{"location":"features/pubsub/#delivery-semantics","title":"Delivery Semantics","text":""},{"location":"features/pubsub/#at-most-once-current-mvp","title":"At-Most-Once (Current MVP)","text":"<p>Messages are delivered zero or one time:</p> <p>Characteristics: - No acknowledgements from subscribers - No retries or redelivery - Lowest latency - Suitable for real-time signals, metrics, telemetry</p> <p>Message loss scenarios: - Subscriber falls behind buffer capacity - Network partition - Broker restart (ephemeral storage)</p> <p>Example use case:</p> <pre><code>// Real-time dashboard updates where latest value matters\nlet mut sub = client.subscribe(\"tenant\", \"ns\", \"sensor-data\").await?;\n\nwhile let Some(event) = sub.next().await {\n    let reading: SensorReading = parse(event.payload)?;\n    update_dashboard(reading);  // Latest value is what matters\n}\n</code></pre>"},{"location":"features/pubsub/#at-least-once-planned","title":"At-Least-Once (Planned)","text":"<p>Messages delivered one or more times:</p> <p>Planned features: - Subscriber acknowledgements - Broker retries unacknowledged messages - Requires durable storage - Higher latency than at-most-once</p> <p>Example (future API):</p> <pre><code>let mut sub = client.subscribe_with_acks(\"tenant\", \"ns\", \"orders\").await?;\n\nwhile let Some(event) = sub.next().await {\n    process_order(event.payload)?;\n    event.ack().await?;  // Acknowledge processing\n}\n</code></pre>"},{"location":"features/pubsub/#exactly-once-future","title":"Exactly-Once (Future)","text":"<p>Messages delivered exactly one time (from application perspective):</p> <p>Planned approach: - Idempotent producers with sequence numbers - Broker deduplication - Transactional coordination - Highest latency</p>"},{"location":"features/pubsub/#performance-tuning","title":"Performance Tuning","text":""},{"location":"features/pubsub/#latency-optimized-configuration","title":"Latency-Optimized Configuration","text":"<p>Minimize end-to-end latency:</p> <p>Broker config:</p> <pre><code># Small batches, low delays\nevent_batch_max_events: 8\nevent_batch_max_delay_us: 100\nfanout_batch_size: 8\n\n# Fast acknowledgements\nack_on_commit: true\n\n# Minimal buffering\npub_queue_depth: 512\nevent_queue_depth: 512\n</code></pre> <p>Client config:</p> <pre><code>let config = ClientConfig {\n    event_conn_pool: 4,\n    event_buffer_size: 256,\n    ..Default::default()\n};\n</code></pre> <p>Expected performance: - p50 latency: 200-400 \u00b5s - p99 latency: 800-1200 \u00b5s - Throughput: 50-80k msg/sec per connection</p>"},{"location":"features/pubsub/#throughput-optimized-configuration","title":"Throughput-Optimized Configuration","text":"<p>Maximize message throughput:</p> <p>Broker config:</p> <pre><code># Large batches, higher delays\nevent_batch_max_events: 256\nevent_batch_max_delay_us: 2000\nfanout_batch_size: 256\n\n# Async acknowledgements\nack_on_commit: false\n\n# Deep buffering\npub_queue_depth: 4096\nevent_queue_depth: 4096\n\n# Binary mode\nevent_single_binary_enabled: true\nevent_single_binary_min_bytes: 256\n</code></pre> <p>Client config:</p> <pre><code>let config = ClientConfig {\n    event_conn_pool: 16,\n    event_buffer_size: 4096,\n    binary_mode_enabled: true,\n    ..Default::default()\n};\n</code></pre> <p>Expected performance: - p50 latency: 1-3 ms - p99 latency: 5-10 ms - Throughput: 200-300k msg/sec per connection</p>"},{"location":"features/pubsub/#balanced-configuration-default","title":"Balanced Configuration (Default)","text":"<p>General-purpose settings:</p> <p>Broker config:</p> <pre><code>event_batch_max_events: 64\nevent_batch_max_delay_us: 250\nfanout_batch_size: 64\npub_queue_depth: 1024\nevent_queue_depth: 1024\n</code></pre> <p>Client config:</p> <pre><code>let config = ClientConfig::default();  // Uses balanced defaults\n</code></pre> <p>Expected performance: - p50 latency: 400-800 \u00b5s - p99 latency: 2-4 ms - Throughput: 150-200k msg/sec per connection</p>"},{"location":"features/pubsub/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"features/pubsub/#fan-in-multiple-publishers","title":"Fan-In (Multiple Publishers)","text":"<p>Multiple publishers to one stream:</p> <pre><code>// Publisher 1\ntokio::spawn(async move {\n    let client = Client::connect(broker_url, config).await?;\n    loop {\n        client.publish(\"tenant\", \"ns\", \"logs\", generate_log()).await?;\n    }\n});\n\n// Publisher 2\ntokio::spawn(async move {\n    let client = Client::connect(broker_url, config).await?;\n    loop {\n        client.publish(\"tenant\", \"ns\", \"logs\", generate_log()).await?;\n    }\n});\n\n// Subscriber receives from both\nlet mut sub = client.subscribe(\"tenant\", \"ns\", \"logs\").await?;\nwhile let Some(event) = sub.next().await {\n    process_log(event);\n}\n</code></pre> <p>Ordering: No cross-publisher ordering guarantees.</p>"},{"location":"features/pubsub/#fan-out-multiple-subscribers","title":"Fan-Out (Multiple Subscribers)","text":"<p>One publisher, many subscribers:</p> <pre><code>// Single publisher\nlet publisher = client.create_publisher(\"tenant\", \"ns\", \"events\", config).await?;\nfor event in events {\n    publisher.publish(&amp;event).await?;\n}\n\n// Many subscribers\nfor i in 0..100 {\n    let mut sub = client.subscribe(\"tenant\", \"ns\", \"events\").await?;\n    tokio::spawn(async move {\n        while let Some(event) = sub.next().await {\n            process(event);\n        }\n    });\n}\n</code></pre> <p>Isolation: Each subscriber progresses independently.</p>"},{"location":"features/pubsub/#broadcast-pattern","title":"Broadcast Pattern","text":"<p>Efficiently broadcast to all subscribers:</p> <pre><code>graph TB\n    P[Publisher]\n    B[Broker]\n\n    subgraph \"Subscribers (100+)\"\n        S1[Sub 1]\n        S2[Sub 2]\n        S3[Sub 3]\n        SN[Sub N]\n    end\n\n    P --&gt;|1 publish| B\n    B --&gt;|fanout to all| S1\n    B --&gt; S2\n    B --&gt; S3\n    B --&gt; SN\n\n    style P fill:#e3f2fd\n    style B fill:#fff3e0\n    style S1 fill:#c8e6c9\n    style S2 fill:#c8e6c9\n    style S3 fill:#c8e6c9\n    style SN fill:#c8e6c9</code></pre> <p>Felix handles fanout efficiently at the broker, so one publish reaches all subscribers.</p>"},{"location":"features/pubsub/#work-queue-pattern-future","title":"Work Queue Pattern (Future)","text":"<p>Consumer groups for load distribution:</p> <pre><code>// Future API\nlet mut consumer = client.consume_group(\n    \"tenant\",\n    \"ns\",\n    \"jobs\",\n    \"worker-group\",  // Consumer group name\n).await?;\n\n// Messages distributed across group members\nwhile let Some(job) = consumer.next().await {\n    process_job(job).await?;\n    job.ack().await?;\n}\n</code></pre> <p>Characteristics: - Shared cursor across group - Each message delivered to one consumer - Load balancing across consumers</p>"},{"location":"features/pubsub/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"features/pubsub/#key-metrics","title":"Key Metrics","text":"<p>Publish metrics: - Publish rate (msg/sec) - Publish latency (p50, p99, p999) - Publish queue depth - Publish failures</p> <p>Subscribe metrics: - Subscriber count per stream - Event delivery rate per subscriber - Subscriber lag (events behind) - Dropped events per subscriber</p> <p>Broker metrics: - Active streams - Fanout operations per second - Queue depths (publish, event) - Memory usage</p>"},{"location":"features/pubsub/#example-monitoring","title":"Example Monitoring","text":"<pre><code>// Future API (not yet implemented)\nlet stats = client.stream_stats(\"tenant\", \"ns\", \"stream\").await?;\nprintln!(\"Publishers: {}\", stats.publisher_count);\nprintln!(\"Subscribers: {}\", stats.subscriber_count);\nprintln!(\"Publish rate: {} msg/sec\", stats.publish_rate);\nprintln!(\"Total delivered: {}\", stats.total_delivered);\n</code></pre>"},{"location":"features/pubsub/#best-practices","title":"Best Practices","text":""},{"location":"features/pubsub/#publishing","title":"Publishing","text":"<ol> <li>Batch when possible: 10-100x throughput improvement</li> <li>Use binary mode: For payloads &gt; 512 bytes</li> <li>Monitor queue depth: High depth indicates overload</li> <li>Handle errors: Implement retry logic for important messages</li> <li>Spread across connections: Use connection pooling</li> </ol>"},{"location":"features/pubsub/#subscribing","title":"Subscribing","text":"<ol> <li>Process async: Don't block subscription loop</li> <li>Handle reconnection: Auto-reconnect on connection loss</li> <li>Monitor lag: Track how far behind subscriber is</li> <li>Size buffers appropriately: Match processing variance</li> <li>Use multiple connections: For isolation and parallelism</li> </ol>"},{"location":"features/pubsub/#stream-design","title":"Stream Design","text":"<ol> <li>Scope appropriately: Tenant \u2192 Namespace \u2192 Stream</li> <li>Partition by use case: Separate streams for different semantics</li> <li>Consider fanout: High fanout benefits from batching</li> <li>Plan for growth: Monitor stream count and subscriber count</li> </ol> <p>Start Simple</p> <p>Begin with default configuration and measure. Tune only when you have profiling data showing a specific bottleneck.</p>"},{"location":"features/pubsub/#comparison-with-other-systems","title":"Comparison with Other Systems","text":"Feature Felix Kafka Redis Pub/Sub NATS Delivery At-most-once (MVP) At-least-once At-most-once At-most-once Ordering Per-stream Per-partition No No Persistence Ephemeral (MVP) Durable Ephemeral Optional Fanout Excellent Good Excellent Excellent Latency 200-800 \u00b5s 2-10 ms 100-500 \u00b5s 100-400 \u00b5s Throughput 150-250k/conn 100k-1M/broker 100-500k/conn 100-300k/conn Backpressure Built-in (QUIC) Client-side None Optional <p>Felix occupies a middle ground: lower latency than Kafka, more features than Redis Pub/Sub, with QUIC's modern networking benefits.</p>"},{"location":"features/quic-transport/","title":"QUIC Transport","text":"<p>Felix uses QUIC as its exclusive transport protocol, providing modern networking features that enable low-latency, secure, and reliable communication between clients and brokers. This document explores QUIC's features, benefits, and how Felix leverages them for optimal performance.</p>"},{"location":"features/quic-transport/#why-quic","title":"Why QUIC?","text":"<p>QUIC (Quick UDP Internet Connections) is a modern transport protocol designed by Google and standardized as IETF RFC 9000. Felix chose QUIC over traditional TCP+TLS for several compelling reasons:</p>"},{"location":"features/quic-transport/#1-encryption-by-default","title":"1. Encryption by Default","text":"<p>QUIC integrates TLS 1.3 directly into the protocol:</p> <ul> <li>No unencrypted mode: All QUIC connections are encrypted</li> <li>Faster handshake: 0-RTT or 1-RTT connection establishment</li> <li>Modern cipher suites: ChaCha20-Poly1305, AES-GCM</li> <li>Forward secrecy: Perfect forward secrecy built-in</li> </ul> <pre><code>sequenceDiagram\n    participant C as Client\n    participant S as Server\n\n    Note over C,S: QUIC 1-RTT Handshake\n    C-&gt;&gt;S: Initial (ClientHello + Crypto)\n    S-&gt;&gt;C: Initial (ServerHello + Crypto)\n    C-&gt;&gt;S: Handshake (Finished)\n    S-&gt;&gt;C: Handshake (Finished)\n    Note over C,S: Connection ready\n\n    Note over C,S: Compare to TCP+TLS: 2-3 RTTs</code></pre>"},{"location":"features/quic-transport/#2-multiplexing-without-head-of-line-blocking","title":"2. Multiplexing Without Head-of-Line Blocking","text":"<p>Traditional TCP suffers from head-of-line (HOL) blocking: packet loss on one stream blocks all streams. QUIC eliminates this:</p> <pre><code>graph LR\n    subgraph \"TCP (HTTP/2)\"\n        S1[Stream 1: blocked]\n        S2[Stream 2: blocked]\n        S3[Stream 3: blocked]\n        Loss[Packet Loss] --&gt;|blocks| S1\n        Loss --&gt;|blocks| S2\n        Loss --&gt;|blocks| S3\n    end\n\n    subgraph \"QUIC\"\n        Q1[Stream 1: continues]\n        Q2[Stream 2: blocked]\n        Q3[Stream 3: continues]\n        Loss2[Packet Loss] --&gt;|blocks only| Q2\n    end\n\n    style S1 fill:#ffccbc\n    style S2 fill:#ffccbc\n    style S3 fill:#ffccbc\n    style Q1 fill:#c8e6c9\n    style Q2 fill:#ffccbc\n    style Q3 fill:#c8e6c9</code></pre> <p>Felix benefit: Slow subscribers on one stream don't impact other subscribers' event delivery.</p>"},{"location":"features/quic-transport/#3-connection-migration","title":"3. Connection Migration","text":"<p>QUIC connections survive network changes:</p> <ul> <li>IP address changes (mobile networks, VPN switches)</li> <li>Network interface changes (WiFi \u2192 cellular)</li> <li>Load balancer re-routing</li> </ul> <p>Connection ID: Each QUIC connection has a unique identifier independent of IP/port tuple.</p> <pre><code>// QUIC connection survives IP change\nlet conn = client.connect(\"https://broker:5000\").await?;\n\n// Network switches from WiFi to cellular\n// Connection automatically migrates to new IP\n\n// Publish continues without interruption\nclient.publish(\"tenant\", \"ns\", \"stream\", data).await?;\n</code></pre> <p>Future Enhancement</p> <p>Felix will leverage connection migration for seamless client mobility and zero-downtime broker migrations.</p>"},{"location":"features/quic-transport/#4-built-in-flow-control","title":"4. Built-in Flow Control","text":"<p>QUIC provides multi-level flow control:</p> <p>Connection-level flow control: - Prevents receiver buffer overflow at connection level - Configurable receive window per connection</p> <p>Stream-level flow control: - Independent flow control per stream - Prevents one stream from consuming all connection capacity</p> <p>Felix configuration:</p> <pre><code># Broker config\nevent_conn_recv_window: 268435456    # 256 MiB per connection\nevent_stream_recv_window: 67108864   # 64 MiB per stream\nevent_send_window: 268435456         # 256 MiB send window\n</code></pre>"},{"location":"features/quic-transport/#5-reduced-latency","title":"5. Reduced Latency","text":"<p>0-RTT resumption:</p> <p>For returning clients, QUIC can send application data in the first packet:</p> <pre><code>sequenceDiagram\n    participant C as Client (returning)\n    participant S as Server\n\n    Note over C: Has resumption token\n    C-&gt;&gt;S: Initial (0-RTT data + publish)\n    S-&gt;&gt;C: Process publish immediately\n    S-&gt;&gt;C: Handshake (Finished)\n    Note over C,S: No wait for handshake!</code></pre> <p>Faster connection establishment:</p> Protocol Handshake RTTs TLS Version TCP + TLS 1.2 3 RTTs 1.2 TCP + TLS 1.3 2 RTTs 1.3 QUIC 1 RTT 1.3 (integrated) QUIC (0-RTT) 0 RTTs 1.3 (resumption)"},{"location":"features/quic-transport/#quic-streams-in-felix","title":"QUIC Streams in Felix","text":"<p>Felix leverages QUIC's stream model for different traffic patterns:</p>"},{"location":"features/quic-transport/#bidirectional-streams","title":"Bidirectional Streams","text":"<p>Used for request/response patterns:</p> <p>Control streams: - Client initiates publish, subscribe, cache operations - Server responds with acknowledgements - Long-lived or short-lived depending on usage</p> <p>Cache streams: - Client sends cache_get/cache_put with request_id - Server responds on same stream - Multiple requests multiplexed per stream</p> <pre><code>sequenceDiagram\n    participant C as Client\n    participant B as Broker\n\n    Note over C,B: Bidirectional stream\n    C-&gt;&gt;B: publish_batch (request)\n    B-&gt;&gt;C: ok (response)\n    C-&gt;&gt;B: cache_put (request)\n    B-&gt;&gt;C: ok (response)\n    C-&gt;&gt;B: cache_get (request)\n    B-&gt;&gt;C: cache_value (response)</code></pre>"},{"location":"features/quic-transport/#unidirectional-streams","title":"Unidirectional Streams","text":"<p>Used for one-way data flow:</p> <p>Event streams (server \u2192 client): - Broker opens stream after successful subscribe - Streams events continuously - One stream per subscription for isolation - Client cannot send data on these streams</p> <pre><code>sequenceDiagram\n    participant C as Client\n    participant B as Broker\n\n    C-&gt;&gt;B: subscribe (on bidirectional control stream)\n    B--&gt;&gt;C: ok\n    Note over B: Open unidirectional stream\n    B-&gt;&gt;C: event_stream_hello\n    loop Event delivery\n        B-&gt;&gt;C: event\n        B-&gt;&gt;C: event\n        B-&gt;&gt;C: event_batch\n    end</code></pre> <p>Benefits of unidirectional streams:</p> <ol> <li>Performance: No reverse path overhead</li> <li>Isolation: Each subscription has dedicated stream</li> <li>Flow control: Independent per-subscription backpressure</li> <li>Simplicity: Clear data flow direction</li> </ol>"},{"location":"features/quic-transport/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"features/quic-transport/#latency","title":"Latency","text":"<p>Connection establishment (localhost, cold start):</p> Scenario Latency First connection 1-2 ms TLS resumption 500-800 \u00b5s 0-RTT (future) 0 \u00b5s (data in first packet) <p>Single message round-trip (publish + ack):</p> Workload p50 p99 Small payload (100B) 150 \u00b5s 300 \u00b5s Medium payload (1KB) 200 \u00b5s 400 \u00b5s Large payload (4KB) 300 \u00b5s 600 \u00b5s"},{"location":"features/quic-transport/#throughput","title":"Throughput","text":"<p>Single connection throughput:</p> <ul> <li>Publish: 50-100k msg/sec (single publishes)</li> <li>Publish batch: 150-250k msg/sec (batch=64)</li> <li>Event delivery: 200-300k msg/sec per subscriber</li> <li>Cache operations: 125-185k ops/sec</li> </ul> <p>Scaling with connection pools:</p> <p>Throughput scales nearly linearly with connection count (up to CPU/network limits):</p> Connections Publish Throughput Event Delivery 1 150k msg/sec 250k msg/sec 4 580k msg/sec 950k msg/sec 8 1.1M msg/sec 1.8M msg/sec 16 2.0M msg/sec 3.2M msg/sec"},{"location":"features/quic-transport/#packet-loss-resilience","title":"Packet Loss Resilience","text":"<p>QUIC handles packet loss better than TCP:</p> <p>TCP behavior: - Packet loss triggers retransmission - All streams blocked until retransmission completes (HOL blocking) - RTT spike affects all traffic</p> <p>QUIC behavior: - Packet loss only affects streams with data in lost packet - Other streams continue normally - Faster recovery via improved congestion control</p> <p>Measured impact (1% packet loss, fanout=10):</p> Metric TCP + TLS QUIC p50 latency +15% +5% p99 latency +120% +25% Throughput -40% -8%"},{"location":"features/quic-transport/#security-features","title":"Security Features","text":""},{"location":"features/quic-transport/#transport-layer-security","title":"Transport Layer Security","text":"<p>QUIC provides comprehensive transport security:</p> <p>Encryption: - All packets encrypted (header + payload) - Only connection ID visible to network observers - No plaintext data ever transmitted</p> <p>Authentication: - Server certificate validation (X.509) - Optional client certificates (mTLS) - Certificate pinning supported</p> <p>Cipher suites: <pre><code>TLS_AES_128_GCM_SHA256\nTLS_AES_256_GCM_SHA384\nTLS_CHACHA20_POLY1305_SHA256\n</code></pre></p>"},{"location":"features/quic-transport/#connection-security","title":"Connection Security","text":"<p>Amplification attack prevention: - QUIC requires address validation before sending large responses - Prevents using Felix as DDoS amplification vector</p> <p>Connection ID obfuscation: - Connection IDs are opaque, random identifiers - No correlation possible from network observation</p> <p>Retry mechanism: - Stateless retry tokens prevent resource exhaustion - Broker can validate clients before allocating resources</p>"},{"location":"features/quic-transport/#future-security-features","title":"Future Security Features","text":"<p>End-to-end encryption (planned):</p> <pre><code>stream:\n  name: sensitive-data\n  encryption: end_to_end\n  key_id: stream-key-v1\n</code></pre> <p>Data encrypted by publisher, broker routes ciphertext only, decrypted by subscriber.</p> <p>mTLS for broker-to-broker:</p> <pre><code>broker:\n  mtls_enabled: true\n  client_cert_path: /certs/broker.crt\n  client_key_path: /certs/broker.key\n</code></pre>"},{"location":"features/quic-transport/#configuration-and-tuning","title":"Configuration and Tuning","text":""},{"location":"features/quic-transport/#connection-pooling","title":"Connection Pooling","text":"<p>Configure pools based on workload:</p> <p>Client configuration:</p> <pre><code>let config = ClientConfig {\n    event_conn_pool: 8,        // For pub/sub\n    cache_conn_pool: 8,        // For cache\n    publish_conn_pool: 4,      // For publishing\n    ..Default::default()\n};\n</code></pre> <p>Tuning guidance:</p> <ul> <li>Light workload: 2-4 connections per type</li> <li>Medium workload: 4-8 connections per type</li> <li>Heavy workload: 8-16 connections per type</li> <li>Very heavy workload: 16-32 connections per type</li> </ul> <p>Connection Limits</p> <p>Each connection consumes memory (buffers, state). Monitor broker memory usage when scaling connection pools. A broker can typically handle 10,000+ concurrent connections with 16 GB RAM.</p>"},{"location":"features/quic-transport/#flow-control-windows","title":"Flow Control Windows","text":"<p>Tune window sizes for workload characteristics:</p> <p>Latency-optimized (minimize buffering):</p> <pre><code>event_conn_recv_window: 67108864     # 64 MiB\nevent_stream_recv_window: 16777216   # 16 MiB\nevent_send_window: 67108864          # 64 MiB\n</code></pre> <p>Throughput-optimized (maximize buffers):</p> <pre><code>event_conn_recv_window: 536870912    # 512 MiB\nevent_stream_recv_window: 134217728  # 128 MiB\nevent_send_window: 536870912         # 512 MiB\n</code></pre> <p>Memory impact:</p> <pre><code>Total memory \u2248 (conn_window \u00d7 conn_pool) + (stream_window \u00d7 streams \u00d7 conn_pool)\n</code></pre> <p>For <code>conn_pool=8</code>, <code>stream_window=64MB</code>, <code>streams_per_conn=10</code>:</p> <pre><code>Memory \u2248 (256MB \u00d7 8) + (64MB \u00d7 10 \u00d7 8) = 2GB + 5.1GB = 7.1GB\n</code></pre>"},{"location":"features/quic-transport/#congestion-control","title":"Congestion Control","text":"<p>QUIC uses modern congestion control algorithms:</p> <p>BBR (Bottleneck Bandwidth and RTT): - Default in quinn QUIC implementation - Optimizes for throughput and latency - Adapts to network conditions</p> <p>CUBIC: - Alternative congestion control - More conservative than BBR - Better for shared networks</p> <p>Tuning Congestion Control</p> <p>For dedicated networks (data center, cloud VPC), BBR provides better performance. For shared networks, CUBIC may be more friendly to competing traffic.</p>"},{"location":"features/quic-transport/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"features/quic-transport/#quic-metrics","title":"QUIC Metrics","text":"<p>Key metrics to monitor:</p> <p>Connection metrics: - Active connections - Connection establishment rate - Connection errors - TLS handshake failures</p> <p>Stream metrics: - Active streams per connection - Stream creation rate - Stream close rate - Stream errors</p> <p>Flow control metrics: - Blocked time per stream - Window updates frequency - Credit exhaustion events</p> <p>Packet loss metrics: - Loss rate - Retransmission rate - RTT variance</p>"},{"location":"features/quic-transport/#example-metrics-collection","title":"Example Metrics Collection","text":"<pre><code>// Hypothetical metrics API (not yet implemented)\nlet metrics = client.quic_metrics().await?;\nprintln!(\"Active connections: {}\", metrics.active_connections);\nprintln!(\"Packet loss rate: {:.2}%\", metrics.loss_rate * 100.0);\nprintln!(\"Average RTT: {:?}\", metrics.avg_rtt);\n</code></pre>"},{"location":"features/quic-transport/#troubleshooting","title":"Troubleshooting","text":""},{"location":"features/quic-transport/#common-issues","title":"Common Issues","text":"<p>Connection timeout:</p> <pre><code>Error: Connection timeout after 5000ms\n</code></pre> <p>Causes: - Network firewall blocking UDP - Broker not listening on expected port - Incorrect server address</p> <p>Resolution: - Verify UDP port 5000 is open - Check broker is running and bound to correct interface - Test connectivity with <code>netcat -u broker-ip 5000</code></p> <p>TLS certificate validation failure:</p> <pre><code>Error: Certificate validation failed: UnknownIssuer\n</code></pre> <p>Causes: - Self-signed certificate without CA trust - Certificate expired - Hostname mismatch</p> <p>Resolution:</p> <pre><code>// Development: skip verification (NEVER in production!)\nlet config = ClientConfig {\n    tls_skip_verify: true,\n    ..Default::default()\n};\n\n// Production: provide CA certificate\nlet config = ClientConfig {\n    tls_ca_cert_path: Some(\"/path/to/ca.crt\"),\n    ..Default::default()\n};\n</code></pre> <p>Flow control deadlock:</p> <pre><code>Warning: Stream blocked on flow control for &gt;1s\n</code></pre> <p>Causes: - Receiver not consuming data fast enough - Window sizes too small for workload - Application not reading from stream</p> <p>Resolution: - Increase <code>stream_recv_window</code> - Ensure subscription loop is not blocked - Check for application-level backpressure</p>"},{"location":"features/quic-transport/#best-practices","title":"Best Practices","text":""},{"location":"features/quic-transport/#connection-management","title":"Connection Management","text":"<ol> <li>Reuse connections: Connection establishment is expensive</li> <li>Pool appropriately: Balance memory vs parallelism</li> <li>Monitor health: Track connection failures and latency</li> <li>Handle disconnections: Implement automatic reconnection</li> </ol>"},{"location":"features/quic-transport/#stream-management","title":"Stream Management","text":"<ol> <li>Close unused streams: Free resources when done</li> <li>Avoid stream exhaustion: QUIC has stream limits (configurable)</li> <li>Use unidirectional streams: When only one-way data flow needed</li> <li>Multiplex on same stream: For cache operations, reuse streams</li> </ol>"},{"location":"features/quic-transport/#security","title":"Security","text":"<ol> <li>Always validate certificates: Never skip verification in production</li> <li>Use strong cipher suites: AES-256-GCM or ChaCha20-Poly1305</li> <li>Rotate certificates: Before expiration</li> <li>Monitor for TLS errors: May indicate security issues</li> </ol>"},{"location":"features/quic-transport/#performance","title":"Performance","text":"<ol> <li>Tune flow control windows: Match your workload burst characteristics</li> <li>Enable 0-RTT: For latency-sensitive resumption (when available)</li> <li>Use connection pooling: Scale parallelism with multiple connections</li> <li>Monitor packet loss: High loss indicates network issues</li> </ol>"},{"location":"features/quic-transport/#comparison-with-other-transports","title":"Comparison with Other Transports","text":"Feature QUIC TCP + TLS gRPC (HTTP/2) Encryption Built-in Separate TLS Separate TLS Multiplexing Yes, no HOL blocking No Yes, but with HOL blocking Connection migration Yes No No 0-RTT resumption Yes Partial (TLS 1.3) Partial (TLS 1.3) Flow control Connection + Stream Connection only Connection + Stream Congestion control Modern (BBR) CUBIC CUBIC Handshake RTTs 1 (0 with resumption) 2-3 2-3 UDP firewall issues Possible No No"},{"location":"features/quic-transport/#future-enhancements","title":"Future Enhancements","text":""},{"location":"features/quic-transport/#planned-quic-features","title":"Planned QUIC Features","text":"<p>Unreliable datagram extension (RFC 9221): - Send unreliable messages over QUIC - Use case: Real-time gaming, video streaming - Lower latency than reliable streams</p> <p>Multipath QUIC: - Use multiple network paths simultaneously - Aggregate bandwidth - Improve reliability</p> <p>Connection migration enhancements: - Seamless broker failover - Zero-downtime client mobility</p>"},{"location":"features/quic-transport/#felix-specific-improvements","title":"Felix-Specific Improvements","text":"<p>Adaptive flow control: - Automatically tune windows based on measured RTT and throughput - Reduce configuration burden</p> <p>Quality of Service (QoS): - Priority streams for critical messages - Bandwidth allocation per tenant</p> <p>Connection affinity: - Route specific tenants/streams to dedicated connections - Better isolation and resource management</p> <p>QUIC is the Future</p> <p>Major platforms (Google, Facebook, Cloudflare) have moved to QUIC. HTTP/3 is built on QUIC. Felix is positioned to benefit from continued QUIC ecosystem improvements.</p>"},{"location":"features/security/","title":"Security Features","text":"<p>Felix is designed with security as a foundational principle, not an afterthought. This document covers current security features, planned enhancements, and best practices for secure deployments.</p>"},{"location":"features/security/#security-philosophy","title":"Security Philosophy","text":"<p>Felix's security model is built on three pillars:</p> <ol> <li>Encryption by default: All network communication is encrypted via QUIC/TLS</li> <li>Explicit boundaries: Tenant isolation, namespace scoping, region boundaries</li> <li>Auditable operations: All actions logged and traceable</li> </ol> <p>Security Maturity</p> <p>Felix is in early development. Core transport security is implemented. Authorization, encryption-at-rest, and advanced features are planned. This document describes both current and planned security features.</p>"},{"location":"features/security/#transport-security","title":"Transport Security","text":""},{"location":"features/security/#quic-and-tls-13","title":"QUIC and TLS 1.3","text":"<p>Felix uses QUIC, which integrates TLS 1.3 natively:</p> <p>Current implementation:</p> <ul> <li>TLS 1.3 mandatory: No fallback to older TLS versions</li> <li>Encrypted by default: All connections are encrypted</li> <li>Modern cipher suites: ChaCha20-Poly1305, AES-128-GCM, AES-256-GCM</li> <li>Perfect forward secrecy: Ephemeral key exchange (ECDHE)</li> <li>Certificate validation: X.509 certificates validated by default</li> </ul> <p>Protocol security:</p> <pre><code>graph TB\n    subgraph \"QUIC Security Layers\"\n        A[Application Data]\n        E[QUIC Encryption Layer]\n        P[UDP Packets]\n    end\n\n    A --&gt;|Encrypt| E\n    E --&gt;|Protected| P\n\n    style E fill:#ffeb3b</code></pre>"},{"location":"features/security/#tls-configuration","title":"TLS Configuration","text":"<p>Server-side (broker):</p> <pre><code># Broker TLS config\nquic_bind: \"0.0.0.0:5000\"\ntls_cert_path: \"/etc/felix/tls/server.crt\"\ntls_key_path: \"/etc/felix/tls/server.key\"\ntls_ca_cert_path: \"/etc/felix/tls/ca.crt\"      # For mTLS (future)\n</code></pre> <p>Client-side:</p> <pre><code>use felix_client::ClientConfig;\n\n// Production: validate certificates\nlet config = ClientConfig {\n    tls_skip_verify: false,\n    tls_ca_cert_path: Some(\"/path/to/ca.crt\"),\n    ..Default::default()\n};\n\n// Development only: skip validation\nlet config = ClientConfig {\n    tls_skip_verify: true,                      // NEVER in production!\n    ..Default::default()\n};\n</code></pre>"},{"location":"features/security/#certificate-management","title":"Certificate Management","text":"<p>Generating self-signed certificates (development):</p> <pre><code># Generate CA\nopenssl req -x509 -newkey rsa:4096 -keyout ca.key -out ca.crt -days 365 -nodes \\\n  -subj \"/CN=Felix Test CA\"\n\n# Generate server certificate\nopenssl req -newkey rsa:4096 -keyout server.key -out server.csr -nodes \\\n  -subj \"/CN=broker.example.com\"\n\nopenssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial \\\n  -out server.crt -days 365\n\n# Client trusts ca.crt\n</code></pre> <p>Production certificates:</p> <p>Use certificates from trusted CA (Let's Encrypt, corporate PKI):</p> <pre><code># Let's Encrypt with certbot\ncertbot certonly --standalone -d broker.example.com\n\n# Felix broker config\ntls_cert_path: \"/etc/letsencrypt/live/broker.example.com/fullchain.pem\"\ntls_key_path: \"/etc/letsencrypt/live/broker.example.com/privkey.pem\"\n</code></pre> <p>Certificate rotation:</p> <pre><code># Broker monitors certificate changes and reloads automatically (future)\n# For now, restart broker after certificate renewal\n\n# Kubernetes secret for automatic rotation\nkubectl create secret tls felix-tls \\\n  --cert=server.crt \\\n  --key=server.key\n</code></pre>"},{"location":"features/security/#mutual-tls-mtls","title":"Mutual TLS (mTLS)","text":"<p>Planned for broker-to-broker communication:</p> <pre><code># Broker config\nmtls_enabled: true\nmtls_client_cert_path: /certs/broker-client.crt\nmtls_client_key_path: /certs/broker-client.key\nmtls_ca_cert_path: /certs/broker-ca.crt\n\n# Verify peer certificates\nmtls_verify_peer: true\nmtls_allowed_common_names:\n  - broker-1.internal\n  - broker-2.internal\n  - broker-3.internal\n</code></pre> <p>Use cases: - Broker-to-broker replication - Control plane to broker communication - Cross-region bridges</p>"},{"location":"features/security/#data-isolation","title":"Data Isolation","text":""},{"location":"features/security/#multi-tenancy-model","title":"Multi-Tenancy Model","text":"<p>Felix enforces tenant isolation at the protocol level:</p> <pre><code>Scope hierarchy:\n  tenant_id \u2192 namespace \u2192 stream/cache \u2192 key\n\nExample:\n  acme-corp \u2192 production \u2192 orders \u2192 order-123\n</code></pre> <p>Isolation guarantees (current):</p> <ol> <li>Wire protocol enforcement: All operations require tenant_id</li> <li>Broker validation: Unknown tenants rejected</li> <li>Namespace scoping: Namespaces independent per tenant</li> <li>Stream isolation: Streams cannot cross tenant boundaries</li> <li>Cache isolation: Cache entries scoped to tenant</li> </ol> <p>Isolation guarantees (planned):</p> <ol> <li>Resource quotas: Per-tenant CPU, memory, bandwidth limits</li> <li>Rate limiting: Per-tenant publish/subscribe rate limits</li> <li>Authorization: RBAC per tenant/namespace/stream</li> <li>Audit logging: All tenant operations logged</li> </ol>"},{"location":"features/security/#namespace-isolation","title":"Namespace Isolation","text":"<p>Within a tenant, namespaces provide further isolation:</p> <pre><code>// These are completely independent\nclient.publish(\"acme\", \"production\", \"orders\", data).await?;\nclient.publish(\"acme\", \"staging\", \"orders\", data).await?;\nclient.publish(\"acme\", \"development\", \"orders\", data).await?;\n</code></pre> <p>Use cases:</p> <ul> <li>Environment isolation: production, staging, development</li> <li>Team isolation: team-a, team-b, team-c</li> <li>Application isolation: app-1, app-2, app-3</li> </ul>"},{"location":"features/security/#authorization-planned","title":"Authorization (Planned)","text":"<p>Not Yet Implemented</p> <p>Authorization is planned but not implemented in the MVP. Currently, any client with network access can perform any operation.</p>"},{"location":"features/security/#role-based-access-control-rbac","title":"Role-Based Access Control (RBAC)","text":"<p>Planned authorization model:</p> <pre><code>apiVersion: felix.io/v1\nkind: ACL\nmetadata:\n  tenant: acme-corp\n  namespace: production\nspec:\n  rules:\n    - principal: \"service-account-publisher\"\n      resource: \"stream:orders\"\n      permissions:\n        - publish\n\n    - principal: \"service-account-consumer\"\n      resource: \"stream:orders\"\n      permissions:\n        - subscribe\n\n    - principal: \"service-account-admin\"\n      resource: \"*\"\n      permissions:\n        - publish\n        - subscribe\n        - cache_read\n        - cache_write\n        - admin\n</code></pre>"},{"location":"features/security/#authentication-methods","title":"Authentication Methods","text":"<p>Planned authentication mechanisms:</p> <ol> <li>API keys: Simple token-based authentication</li> <li>mTLS: Certificate-based authentication</li> <li>JWT tokens: OAuth2/OIDC integration</li> <li>Kubernetes ServiceAccounts: Native K8s identity</li> </ol> <p>Example with API keys (future):</p> <pre><code>let config = ClientConfig {\n    api_key: Some(\"felix_api_key_abc123xyz\".to_string()),\n    ..Default::default()\n};\n\nlet client = Client::connect(\"https://broker:5000\", config).await?;\n</code></pre>"},{"location":"features/security/#permission-model","title":"Permission Model","text":"<p>Resource types:</p> <ul> <li><code>stream:{name}</code>: Specific stream</li> <li><code>stream:*</code>: All streams in namespace</li> <li><code>cache:{name}</code>: Specific cache</li> <li><code>cache:*</code>: All caches in namespace</li> </ul> <p>Permissions:</p> <ul> <li><code>publish</code>: Publish messages to stream</li> <li><code>subscribe</code>: Subscribe to stream</li> <li><code>cache_read</code>: Read from cache</li> <li><code>cache_write</code>: Write to cache</li> <li><code>admin</code>: Administrative operations (create/delete streams, etc.)</li> </ul> <p>Enforcement points:</p> <pre><code>sequenceDiagram\n    participant C as Client\n    participant A as Auth Layer\n    participant B as Broker Core\n\n    C-&gt;&gt;A: publish (with credentials)\n    A-&gt;&gt;A: Validate credentials\n    A-&gt;&gt;A: Check permissions\n    alt Authorized\n        A-&gt;&gt;B: Forward request\n        B--&gt;&gt;C: Success\n    else Unauthorized\n        A--&gt;&gt;C: Error: Forbidden\n    end</code></pre>"},{"location":"features/security/#encryption-at-rest-planned","title":"Encryption at Rest (Planned)","text":"<p>Planned encryption for durable storage:</p>"},{"location":"features/security/#envelope-encryption","title":"Envelope Encryption","text":"<pre><code>encryption:\n  enabled: true\n  provider: kms                         # or local\n  master_key_id: \"arn:aws:kms:us-west-2:123456789012:key/abc-123\"\n  key_rotation_days: 90\n</code></pre> <p>Architecture:</p> <pre><code>graph LR\n    MK[Master Key&lt;br/&gt;KMS]\n    DEK[Data Encryption Key&lt;br/&gt;Per stream/tenant]\n    Data[Stream Data&lt;br/&gt;Encrypted]\n\n    MK --&gt;|Encrypts| DEK\n    DEK --&gt;|Encrypts| Data\n\n    style MK fill:#ffeb3b\n    style DEK fill:#fff3e0\n    style Data fill:#e3f2fd</code></pre> <p>Benefits:</p> <ul> <li>Master key never leaves KMS</li> <li>Data encryption keys rotatable</li> <li>Per-tenant or per-stream encryption</li> <li>Key audit trail in KMS</li> </ul>"},{"location":"features/security/#end-to-end-encryption-planned","title":"End-to-End Encryption (Planned)","text":"<p>Optional E2EE for sensitive data:</p> <pre><code>stream:\n  name: sensitive-data\n  encryption: end_to_end\n  key_id: stream-key-v1\n</code></pre> <p>E2EE flow:</p> <pre><code>sequenceDiagram\n    participant P as Publisher\n    participant B as Broker\n    participant S as Subscriber\n\n    Note over P: Encrypt with stream key\n    P-&gt;&gt;B: Publish (ciphertext)\n    Note over B: Routes ciphertext&lt;br/&gt;(cannot decrypt)\n    B-&gt;&gt;S: Deliver (ciphertext)\n    Note over S: Decrypt with stream key</code></pre> <p>Properties:</p> <ul> <li>Publisher encrypts before sending</li> <li>Broker routes ciphertext (zero-knowledge)</li> <li>Subscriber decrypts after receiving</li> <li>Key management separate from broker</li> </ul>"},{"location":"features/security/#network-security","title":"Network Security","text":""},{"location":"features/security/#firewall-configuration","title":"Firewall Configuration","text":"<p>Inbound rules:</p> <pre><code># Broker QUIC port\nallow UDP 5000 from clients\n\n# Metrics endpoint\nallow TCP 8080 from monitoring\n\n# Control plane (future)\nallow TCP 9000 from control-plane\n\n# Deny all other inbound\ndeny all\n</code></pre> <p>Outbound rules:</p> <pre><code># Control plane sync (future)\nallow TCP 9000 to control-plane\n\n# External dependencies (KMS, etc.)\nallow TCP 443 to kms.amazonaws.com\n\n# Deny all other outbound\ndeny all\n</code></pre>"},{"location":"features/security/#ddos-protection","title":"DDoS Protection","text":"<p>QUIC amplification prevention:</p> <p>QUIC includes built-in protections:</p> <ol> <li>Address validation: Clients must prove IP ownership</li> <li>Stateless retry: Challenge-response before resource allocation</li> <li>Rate limiting: Per-source-IP connection limits</li> </ol> <p>Application-level protection:</p> <pre><code># Planned DoS protection config\nprotection:\n  max_connections_per_ip: 100\n  connection_rate_limit: 10/sec\n  publish_rate_limit: 1000/sec\n  burst_tolerance: 2x\n</code></pre>"},{"location":"features/security/#network-segmentation","title":"Network Segmentation","text":"<p>Kubernetes network policies:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: felix-broker\nspec:\n  podSelector:\n    matchLabels:\n      app: felix-broker\n  policyTypes:\n    - Ingress\n    - Egress\n  ingress:\n    - from:\n        - namespaceSelector:\n            matchLabels:\n              name: application-namespace\n      ports:\n        - protocol: UDP\n          port: 5000\n  egress:\n    - to:\n        - namespaceSelector:\n            matchLabels:\n              name: control-plane-namespace\n      ports:\n        - protocol: TCP\n          port: 9000\n</code></pre>"},{"location":"features/security/#audit-logging-planned","title":"Audit Logging (Planned)","text":"<p>Comprehensive audit trail:</p> <pre><code>{\n  \"timestamp\": \"2026-01-15T10:30:45.123Z\",\n  \"event_type\": \"stream.create\",\n  \"principal\": \"admin@acme.com\",\n  \"principal_type\": \"user\",\n  \"tenant_id\": \"acme-corp\",\n  \"namespace\": \"production\",\n  \"resource\": \"stream:orders\",\n  \"action\": \"create\",\n  \"result\": \"success\",\n  \"metadata\": {\n    \"shards\": 4,\n    \"retention\": \"7d\"\n  },\n  \"source_ip\": \"10.0.1.45\",\n  \"user_agent\": \"felix-cli/0.1.0\"\n}\n</code></pre> <p>Audited events:</p> <ul> <li>Authentication attempts (success/failure)</li> <li>Authorization decisions (allow/deny)</li> <li>Resource creation/deletion</li> <li>Configuration changes</li> <li>Administrative operations</li> <li>Data access (optional, performance impact)</li> </ul> <p>Audit log storage:</p> <ul> <li>Write-ahead append-only log</li> <li>Immutable after write</li> <li>Cryptographically signed (future)</li> <li>Long-term retention (years)</li> <li>Compliance-ready format</li> </ul>"},{"location":"features/security/#compliance-features-planned","title":"Compliance Features (Planned)","text":""},{"location":"features/security/#data-residency","title":"Data Residency","text":"<p>Regional constraints:</p> <pre><code>cluster:\n  region: eu-central-1\n  data_residency:\n    allow_cross_region: false\n    allowed_regions:\n      - eu-central-1\n      - eu-west-1\n</code></pre> <p>Enforcement:</p> <ul> <li>Data never leaves configured region</li> <li>Cross-region bridges require explicit configuration</li> <li>Audit trail for any cross-region data movement</li> </ul>"},{"location":"features/security/#gdpr-compliance","title":"GDPR Compliance","text":"<p>Right to erasure:</p> <pre><code>// Future API for GDPR right to erasure\nclient.delete_user_data(\"tenant\", \"user-id\").await?;\n</code></pre> <p>Data processing agreement:</p> <ul> <li>Tenant controls where data is processed</li> <li>Explicit consent for cross-region bridges</li> <li>Data retention policies enforced</li> <li>Audit trail for data access</li> </ul>"},{"location":"features/security/#hipaa-compliance","title":"HIPAA Compliance","text":"<p>Requirements (planned):</p> <ul> <li>\u2713 Encryption in transit (TLS 1.3)</li> <li> Encryption at rest (planned)</li> <li> Access controls (RBAC planned)</li> <li> Audit logging (planned)</li> <li> Business associate agreement</li> <li> Physical security (infrastructure-dependent)</li> </ul>"},{"location":"features/security/#security-best-practices","title":"Security Best Practices","text":""},{"location":"features/security/#deployment-security","title":"Deployment Security","text":"<ol> <li>Use TLS certificates from trusted CA: Don't use self-signed in production</li> <li>Enable certificate verification: Never set <code>tls_skip_verify: true</code> in production</li> <li>Rotate certificates regularly: Before expiration, ideally every 90 days</li> <li>Use network policies: Restrict network access to broker</li> <li>Isolate broker pods: Dedicated node pool or namespace</li> <li>Enable audit logging: Track all administrative operations</li> <li>Monitor for anomalies: Unusual access patterns, failed auth attempts</li> <li>Principle of least privilege: Grant minimal necessary permissions</li> <li>Secure credential storage: Use secrets management (Vault, K8s secrets)</li> <li>Regular security updates: Keep Felix and dependencies up-to-date</li> </ol>"},{"location":"features/security/#operational-security","title":"Operational Security","text":"<p>Secure configuration:</p> <pre><code># Good: explicit configuration\ntls_cert_path: \"/etc/felix/tls/server.crt\"\ntls_key_path: \"/etc/felix/tls/server.key\"\napi_key_hash: \"$2b$12$...\"                     # Bcrypt hash, not plaintext\n\n# Bad: insecure configuration\ntls_skip_verify: true                          # NEVER\ndebug_mode: true                               # Not in production\nlog_payloads: true                             # Exposes sensitive data\n</code></pre> <p>Secrets management:</p> <pre><code># Kubernetes secrets\nkubectl create secret tls felix-tls \\\n  --cert=server.crt \\\n  --key=server.key\n\nkubectl create secret generic felix-api-keys \\\n  --from-literal=admin-key=felix_admin_key_xxx\n</code></pre> <p>Access control:</p> <pre><code># Restrict who can deploy Felix\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: felix-deployers\nsubjects:\n  - kind: User\n    name: ops-team@acme.com\nroleRef:\n  kind: Role\n  name: felix-deployer\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"features/security/#application-security","title":"Application Security","text":"<p>Client-side security:</p> <pre><code>// 1. Validate broker certificate\nlet config = ClientConfig {\n    tls_ca_cert_path: Some(\"/etc/ca-bundle.crt\"),\n    ..Default::default()\n};\n\n// 2. Use credentials\nlet config = ClientConfig {\n    api_key: Some(env::var(\"FELIX_API_KEY\")?),\n    ..Default::default()\n};\n\n// 3. Handle errors securely\nmatch client.publish(\"tenant\", \"ns\", \"stream\", data).await {\n    Ok(()) =&gt; {},\n    Err(e) =&gt; {\n        // Don't log sensitive data in errors\n        error!(\"Publish failed: {}\", e);\n        // Sanitize error before returning to user\n        return Err(\"Publish failed\");\n    }\n}\n\n// 4. Don't log credentials or sensitive payloads\n// Bad:\ninfo!(\"Publishing: api_key={}, payload={:?}\", api_key, data);\n\n// Good:\ninfo!(\"Publishing to stream={}\", stream_name);\n</code></pre>"},{"location":"features/security/#vulnerability-disclosure","title":"Vulnerability Disclosure","text":"<p>Security issues: Report to <code>security@felix.example.com</code> (update with actual contact)</p> <p>PGP key: [Link to PGP key for encrypted communication]</p> <p>Response timeline:</p> <ul> <li>Acknowledgement: Within 24 hours</li> <li>Initial assessment: Within 72 hours</li> <li>Resolution target: Within 30 days for critical issues</li> </ul> <p>CVE process: Security vulnerabilities will be assigned CVE identifiers and published after fixes are available.</p>"},{"location":"features/security/#security-roadmap","title":"Security Roadmap","text":"<p>Short-term (next 6 months):</p> <ul> <li> Authorization framework (RBAC)</li> <li> API key authentication</li> <li> Audit logging</li> <li> Per-tenant rate limiting</li> </ul> <p>Medium-term (6-12 months):</p> <ul> <li> Encryption at rest</li> <li> JWT/OIDC integration</li> <li> mTLS for broker-to-broker</li> <li> Advanced audit features</li> </ul> <p>Long-term (12+ months):</p> <ul> <li> End-to-end encryption</li> <li> Hardware security module (HSM) integration</li> <li> FIPS 140-2 compliance</li> <li> Security certification (SOC 2, ISO 27001)</li> </ul>"},{"location":"features/security/#threat-model","title":"Threat Model","text":"<p>Threats Felix protects against:</p> <ul> <li>\u2713 Eavesdropping: TLS 1.3 encryption</li> <li>\u2713 Man-in-the-middle: Certificate validation</li> <li>\u2713 Connection hijacking: QUIC connection IDs</li> <li>\u2713 Replay attacks: TLS 1.3 anti-replay</li> <li> Unauthorized access: Authorization (planned)</li> <li> Data tampering: Integrity checks (planned)</li> <li> Denial of service: Rate limiting (planned)</li> </ul> <p>Threats outside Felix's scope:</p> <ul> <li>Physical security (infrastructure responsibility)</li> <li>Client-side malware</li> <li>Social engineering</li> <li>DNS hijacking (use DNSSEC)</li> <li>BGP hijacking (infrastructure)</li> </ul>"},{"location":"features/security/#security-contacts-and-resources","title":"Security Contacts and Resources","text":"<p>Security team: <code>security@felix.example.com</code> Bug bounty: (Planned) Security advisories: GitHub Security Advisories Security policy: SECURITY.md</p> <p>Security is Shared Responsibility</p> <p>Felix provides security features, but secure deployments require proper configuration, network security, access controls, and operational practices. Review this guide regularly and apply defense-in-depth principles.</p>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This guide covers building Felix from source and verifying your installation.</p>"},{"location":"getting-started/installation/#system-requirements","title":"System Requirements","text":"<ul> <li>Operating System: Linux, macOS, or Windows (WSL2 recommended)</li> <li>Rust: 1.92.0 or later</li> <li>Memory: 4 GB minimum, 8 GB recommended for development</li> <li>Disk: 2 GB for build artifacts</li> <li>Network: For QUIC, ensure UDP traffic is allowed on your firewall</li> </ul>"},{"location":"getting-started/installation/#install-rust","title":"Install Rust","text":"<p>Felix requires Rust 1.92.0 or later. Install using rustup:</p> <pre><code>curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n</code></pre> <p>Follow the prompts to complete installation. Then verify:</p> <pre><code>rustc --version\ncargo --version\n</code></pre> <p>Expected output:</p> <pre><code>rustc 1.92.0 (or later)\ncargo 1.92.0 (or later)\n</code></pre>"},{"location":"getting-started/installation/#clone-the-repository","title":"Clone the Repository","text":"<pre><code>git clone https://github.com/gabloe/felix.git\ncd felix\n</code></pre>"},{"location":"getting-started/installation/#build-from-source","title":"Build from Source","text":""},{"location":"getting-started/installation/#development-build","title":"Development Build","text":"<p>For development and debugging with full error information:</p> <pre><code>cargo build --workspace\n</code></pre> <p>Binaries will be in <code>target/debug/</code>.</p>"},{"location":"getting-started/installation/#release-build","title":"Release Build","text":"<p>For performance testing and production use:</p> <pre><code>cargo build --workspace --release\n</code></pre> <p>Binaries will be in <code>target/release/</code>.</p> <p>Performance Difference</p> <p>Release builds are significantly faster than debug builds. Always use <code>--release</code> for any performance testing or benchmarking.</p>"},{"location":"getting-started/installation/#build-specific-crates","title":"Build Specific Crates","text":"<p>Build only the broker service:</p> <pre><code>cargo build -p broker --release\n</code></pre> <p>Build only the client library:</p> <pre><code>cargo build -p felix-client --release\n</code></pre>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":""},{"location":"getting-started/installation/#run-tests","title":"Run Tests","text":"<p>Verify everything is working:</p> <pre><code>cargo test --workspace\n</code></pre> <p>You should see all tests passing:</p> <pre><code>running 150 tests\n...\ntest result: ok. 150 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out\n</code></pre>"},{"location":"getting-started/installation/#run-the-conformance-suite","title":"Run the Conformance Suite","text":"<p>Felix includes a wire protocol conformance runner to validate correct framing and message encoding:</p> <pre><code>cargo run -p felix-conformance\n</code></pre> <p>Expected output:</p> <pre><code>Running wire protocol conformance tests...\n\u2713 Frame envelope encoding\n\u2713 Publish message encoding\n\u2713 Subscribe message encoding\n\u2713 Event message encoding\n\u2713 Cache operations encoding\nAll conformance tests passed!\n</code></pre>"},{"location":"getting-started/installation/#start-the-broker","title":"Start the Broker","text":"<p>Run the broker service:</p> <pre><code>cargo run --release -p broker\n</code></pre> <p>You should see startup logs:</p> <pre><code>2026-01-25T10:00:00.000Z INFO felix_broker: Starting Felix broker\n2026-01-25T10:00:00.001Z INFO felix_broker: QUIC listening on 0.0.0.0:5000\n2026-01-25T10:00:00.001Z INFO felix_broker: Metrics server on 0.0.0.0:8080\n</code></pre> <p>Press <code>Ctrl+C</code> to stop the broker.</p>"},{"location":"getting-started/installation/#run-a-demo","title":"Run a Demo","text":"<p>Verify end-to-end functionality with the pub/sub demo:</p> <pre><code># Start the broker in one terminal\ncargo run --release -p broker\n\n# In another terminal, run the demo\ncargo run --release -p broker --bin pubsubdemo\n</code></pre> <p>The demo should complete successfully with message delivery confirmation.</p>"},{"location":"getting-started/installation/#optional-tools","title":"Optional Tools","text":""},{"location":"getting-started/installation/#task-runner","title":"Task Runner","text":"<p>Install Task for convenient commands:</p> <p>macOS/Linux:</p> <pre><code>sh -c \"$(curl --location https://taskfile.dev/install.sh)\" -- -d -b /usr/local/bin\n</code></pre> <p>Using Homebrew:</p> <pre><code>brew install go-task/tap/go-task\n</code></pre> <p>Then you can use:</p> <pre><code>task build      # Build everything\ntask test       # Run tests\ntask fmt        # Format code\ntask lint       # Run linters\n</code></pre>"},{"location":"getting-started/installation/#cargo-tools","title":"Cargo Tools","text":"<p>Install additional cargo extensions for development:</p> <pre><code># Code coverage\ncargo install cargo-llvm-cov\n\n# Security auditing\ncargo install cargo-deny --version 0.19.0 --locked\n\n# Benchmarking\ncargo install cargo-criterion\n</code></pre>"},{"location":"getting-started/installation/#build-customization","title":"Build Customization","text":""},{"location":"getting-started/installation/#feature-flags","title":"Feature Flags","text":"<p>Felix supports optional feature flags:</p>"},{"location":"getting-started/installation/#telemetry","title":"Telemetry","text":"<p>Enable detailed per-stage timing instrumentation:</p> <pre><code>cargo build --release --features telemetry\n</code></pre> <p>Performance Impact</p> <p>Telemetry adds instrumentation overhead. Validate on your workload\u2014high fanout and batching can amplify tail latency effects. Disabled by default for production.</p>"},{"location":"getting-started/installation/#environment-specific-builds","title":"Environment-Specific Builds","text":""},{"location":"getting-started/installation/#minimal-build","title":"Minimal Build","text":"<p>Build only what you need:</p> <pre><code># Just the broker\ncargo build --release -p broker\n\n# Just the client library\ncargo build --release -p felix-client\n</code></pre>"},{"location":"getting-started/installation/#all-demos","title":"All Demos","text":"<p>Build all demonstration binaries:</p> <pre><code>cargo build --release --bins\n</code></pre>"},{"location":"getting-started/installation/#platform-specific-notes","title":"Platform-Specific Notes","text":""},{"location":"getting-started/installation/#linux","title":"Linux","text":"<p>Felix works best on Linux with modern kernel support for QUIC/UDP optimization:</p> <ul> <li>Kernel 5.8+ recommended</li> <li>Increase UDP buffer sizes for high throughput:</li> </ul> <pre><code>sudo sysctl -w net.core.rmem_max=26214400\nsudo sysctl -w net.core.wmem_max=26214400\n</code></pre>"},{"location":"getting-started/installation/#macos","title":"macOS","text":"<p>Works well on macOS 11 (Big Sur) and later. No special configuration needed.</p>"},{"location":"getting-started/installation/#windows-wsl2","title":"Windows (WSL2)","text":"<p>Use WSL2 for best compatibility:</p> <ol> <li>Install WSL2: Microsoft Guide</li> <li>Install Ubuntu or Debian</li> <li>Follow Linux instructions inside WSL2</li> </ol> <p>Native Windows support is not currently tested.</p>"},{"location":"getting-started/installation/#docker-alternative","title":"Docker (Alternative)","text":"<p>A Docker image is available for quick testing (not recommended for production):</p> <pre><code># Build the image\ndocker build -t felix-broker -f docker/Dockerfile .\n\n# Run the broker\ndocker run -p 5000:5000/udp -p 8080:8080 felix-broker\n</code></pre> <p>See Docker Compose Guide for orchestrated deployments.</p>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#openssl-errors-linux","title":"OpenSSL Errors (Linux)","text":"<p>If you see OpenSSL-related build errors:</p> <pre><code># Ubuntu/Debian\nsudo apt-get install pkg-config libssl-dev\n\n# RHEL/CentOS/Fedora\nsudo yum install pkg-config openssl-devel\n</code></pre>"},{"location":"getting-started/installation/#linker-errors","title":"Linker Errors","text":"<p>Use <code>lld</code> for faster linking (optional):</p> <pre><code># Install lld\nsudo apt-get install lld  # Debian/Ubuntu\nbrew install llvm         # macOS\n\n# Configure Rust to use it\nmkdir -p .cargo\ncat &gt; .cargo/config.toml &lt;&lt; EOF\n[target.x86_64-unknown-linux-gnu]\nlinker = \"clang\"\nrustflags = [\"-C\", \"link-arg=-fuse-ld=lld\"]\nEOF\n</code></pre>"},{"location":"getting-started/installation/#out-of-memory","title":"Out of Memory","text":"<p>If the build runs out of memory:</p> <pre><code># Reduce parallel jobs\ncargo build --release -j 2\n</code></pre>"},{"location":"getting-started/installation/#slow-builds","title":"Slow Builds","text":"<p>Enable incremental compilation for development:</p> <pre><code>export CARGO_INCREMENTAL=1\ncargo build\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quickstart Guide - Run your first Felix deployment</li> <li>Building &amp; Testing - Development workflow</li> <li>Configuration - Customize Felix behavior</li> </ul>"},{"location":"getting-started/overview/","title":"Overview","text":"<p>Felix is a low-latency, QUIC-based distributed data backend that unifies three critical patterns into a single system:</p> <ul> <li>Event Streaming (Pub/Sub): High-fanout message delivery with isolation and backpressure</li> <li>Message Queues: Shared consumer groups with acknowledgements</li> <li>Distributed Cache: Key-value storage with TTL support</li> </ul>"},{"location":"getting-started/overview/#design-philosophy","title":"Design Philosophy","text":"<p>Felix is built around core principles that differentiate it from traditional message brokers and caches:</p>"},{"location":"getting-started/overview/#1-sovereignty-by-default","title":"1. Sovereignty by Default","text":"<p>Each Felix cluster represents a single sovereign region. Data cannot leave the region unless an explicit, configured bridge exists. This isn't just a deployment suggestion\u2014it's enforced in routing, metadata, and encryption boundaries.</p> <p>This design is critical for:</p> <ul> <li>Financial services with regional data regulations</li> <li>Healthcare systems with patient data residency requirements</li> <li>Government systems with strict data sovereignty rules</li> <li>Multi-tenant SaaS platforms with customer-specific compliance needs</li> </ul>"},{"location":"getting-started/overview/#2-low-latency-first","title":"2. Low Latency First","text":"<p>Felix prioritizes predictable low latency over maximum batch throughput:</p> <ul> <li>QUIC transport eliminates head-of-line blocking</li> <li>Optional ephemeral streams with no disk on the hot path</li> <li>Aggressive backpressure prevents cascade failures</li> <li>Bounded memory everywhere to maintain predictable behavior</li> <li>Explicit performance knobs for latency/throughput trade-offs</li> </ul> <p>Real-world results (single-node localhost):</p> <ul> <li>Pub/Sub: p50 ~40-50\u03bcs, p99 ~300-500\u03bcs (varies by payload and fanout)</li> <li>Cache: p50 ~160-180\u03bcs, p99 ~350-450\u03bcs at concurrency=32</li> </ul>"},{"location":"getting-started/overview/#3-one-core-log-many-semantics","title":"3. One Core Log, Many Semantics","text":"<p>Internally, Felix uses a single append-only log abstraction. Different external semantics are projections over this core:</p> <ul> <li>Streams: fanout cursors per subscription</li> <li>Queues: shared consumer-group cursors with acks</li> <li>Cache: key \u2192 latest value with TTL</li> </ul> <p>This eliminates the operational complexity and consistency bugs from running multiple systems (Kafka + Redis + RabbitMQ) side-by-side.</p>"},{"location":"getting-started/overview/#4-kubernetes-native","title":"4. Kubernetes-Native","text":"<p>Felix assumes Kubernetes for:</p> <ul> <li>Process lifecycle management</li> <li>Identity (ServiceAccounts for mTLS)</li> <li>Networking and service discovery</li> <li>Failure detection and orchestration</li> </ul> <p>Felix does not reimplement scheduling or node membership\u2014it leverages what Kubernetes already provides.</p>"},{"location":"getting-started/overview/#core-components","title":"Core Components","text":""},{"location":"getting-started/overview/#felix-wire-protocol-felix-wire","title":"Felix Wire Protocol (<code>felix-wire</code>)","text":"<p>Language-neutral framed protocol over QUIC:</p> <ul> <li>Fixed header with magic number, version, and flags</li> <li>JSON payloads for control plane (v1)</li> <li>Binary batch format for high-throughput data plane</li> <li>Forward-compatible versioning scheme</li> </ul> <p>See the Wire Protocol documentation for full specification.</p>"},{"location":"getting-started/overview/#transport-layer-felix-transport","title":"Transport Layer (<code>felix-transport</code>)","text":"<p>QUIC abstraction layer providing:</p> <ul> <li>Client and server connection management</li> <li>Connection pooling with configurable size</li> <li>Stream lifecycle management</li> <li>Flow control window configuration</li> <li>TLS 1.3 encryption by default</li> </ul>"},{"location":"getting-started/overview/#broker-felix-broker","title":"Broker (<code>felix-broker</code>)","text":"<p>The core data plane implementation:</p> <ul> <li>Pub/sub logic with fanout and batching</li> <li>Cache storage with TTL and lazy expiration</li> <li>Stream registry and routing</li> <li>Backpressure and isolation enforcement</li> </ul>"},{"location":"getting-started/overview/#client-sdk-felix-client","title":"Client SDK (<code>felix-client</code>)","text":"<p>Rust client SDK with:</p> <ul> <li>Publisher/subscriber/cache APIs</li> <li>Connection and stream pooling</li> <li>Automatic reconnection</li> <li>Configurable batching and flow control</li> </ul> <p>Planned: Thin adapters for Python, Go, and other languages.</p>"},{"location":"getting-started/overview/#control-plane-planned","title":"Control Plane (Planned)","text":"<p>Metadata and coordination layer (future):</p> <ul> <li>RAFT-based consensus for cluster metadata</li> <li>Stream definitions and placement</li> <li>Tenant/namespace management</li> <li>Quota and retention policies</li> <li>Health monitoring and metrics aggregation</li> </ul>"},{"location":"getting-started/overview/#consistency-delivery-guarantees","title":"Consistency &amp; Delivery Guarantees","text":"<p>Felix provides tunable consistency configured per stream:</p>"},{"location":"getting-started/overview/#current-mvp-single-node","title":"Current MVP (Single-Node)","text":"<ul> <li>Delivery: At-most-once (best-effort)</li> <li>Ordering: Per-stream ordering preserved for each subscriber</li> <li>Acknowledgements: Broker acknowledges receipt, not delivery to subscribers</li> </ul>"},{"location":"getting-started/overview/#planned-multi-node","title":"Planned Multi-Node","text":"<ul> <li>Leader-only acks: Low latency, no replication wait</li> <li>Quorum acks: Higher durability, waits for replica confirmation</li> <li>At-least-once: With durable storage and replay</li> <li>Exactly-once: (future) via idempotent producers and transactions</li> </ul>"},{"location":"getting-started/overview/#security-architecture","title":"Security Architecture","text":""},{"location":"getting-started/overview/#current","title":"Current","text":"<ul> <li>TLS 1.3 for all QUIC connections</li> <li>Transport-level encryption by default</li> </ul>"},{"location":"getting-started/overview/#planned","title":"Planned","text":"<ul> <li>mTLS: Mutual authentication between brokers and clients</li> <li>RBAC: Tenant/namespace/stream-level authorization</li> <li>Envelope Encryption: Per-region and per-tenant key isolation</li> <li>End-to-End Encryption: Optional client-to-client encryption</li> <li>Audit Logging: Complete audit trail for compliance</li> </ul>"},{"location":"getting-started/overview/#deployment-models","title":"Deployment Models","text":""},{"location":"getting-started/overview/#single-node-mvp","title":"Single-Node (MVP)","text":"<p>Current implementation for development and testing:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Broker    \u2502\n\u2502  (in-proc)  \u2502\n\u2502             \u2502\n\u2502 \u2022 Pub/Sub   \u2502\n\u2502 \u2022 Cache     \u2502\n\u2502 \u2022 Ephemeral \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"getting-started/overview/#multi-node-cluster-planned","title":"Multi-Node Cluster (Planned)","text":"<pre><code>     Control Plane          Data Plane\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 RAFT Quorum  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2502 Broker A \u2502\n    \u2502              \u2502      \u2502 Broker B \u2502\n    \u2502 \u2022 Metadata   \u2502      \u2502 Broker C \u2502\n    \u2502 \u2022 Placement  \u2502      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2502 \u2022 Health     \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>See Deployment Guides for detailed instructions.</p>"},{"location":"getting-started/overview/#performance-characteristics","title":"Performance Characteristics","text":"<p>Felix is designed for workloads where:</p> <ul> <li>Latency matters more than maximum throughput</li> <li>Predictable p99/p999 is critical</li> <li>High fanout is common (1:N message delivery)</li> <li>Mixed workloads (streams + cache) share infrastructure</li> </ul>"},{"location":"getting-started/overview/#when-felix-excels","title":"When Felix Excels","text":"<p>\u2705 Real-time event streaming with tight latency SLAs \u2705 Microservice communication with low overhead \u2705 Regional data isolation requirements \u2705 Cache + stream unification to reduce system count  </p>"},{"location":"getting-started/overview/#when-to-use-something-else","title":"When to Use Something Else","text":"<p>\u274c Maximum historical batch processing throughput (use Kafka) \u274c Complex stream processing / transformations (use Kafka Streams, Flink) \u274c Mature ecosystem with hundreds of connectors required \u274c Multi-petabyte data warehouse workloads  </p>"},{"location":"getting-started/overview/#whats-next","title":"What's Next?","text":"<ul> <li>Quickstart Guide - Get Felix running in minutes</li> <li>Installation - Build from source</li> <li>Architecture - Deep dive into system design</li> <li>API Documentation - Learn the APIs</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quickstart","text":"<p>Get Felix up and running in under 5 minutes.</p>"},{"location":"getting-started/quickstart/#prerequisites","title":"Prerequisites","text":"<ul> <li>Rust: 1.92.0 or later (install rustup)</li> <li>Git: For cloning the repository</li> <li>Optional: Task for convenience commands</li> </ul>"},{"location":"getting-started/quickstart/#clone-and-build","title":"Clone and Build","text":"<pre><code># Clone the repository\ngit clone https://github.com/gabloe/felix.git\ncd felix\n\n# Build the entire workspace in release mode\ncargo build --workspace --release\n</code></pre> <p>The release build is recommended for performance testing. Development builds have significantly higher overhead.</p>"},{"location":"getting-started/quickstart/#start-the-broker","title":"Start the Broker","text":"<p>Run the Felix broker in a terminal:</p> <pre><code>cargo run --release -p broker\n</code></pre> <p>You should see structured log output:</p> <pre><code>2026-01-25T10:00:00.000Z INFO felix_broker: Starting Felix broker\n2026-01-25T10:00:00.001Z INFO felix_broker: QUIC listening on 0.0.0.0:5000\n2026-01-25T10:00:00.001Z INFO felix_broker: Metrics server on 0.0.0.0:8080\n</code></pre> <p>The broker is now ready to accept connections!</p> <p>Default ports:</p> <ul> <li><code>5000</code>: QUIC data plane (publish, subscribe, cache)</li> <li><code>8080</code>: Metrics/health endpoint</li> </ul>"},{"location":"getting-started/quickstart/#run-a-demo","title":"Run a Demo","text":"<p>Felix includes several demonstration programs. Open a new terminal and try the pub/sub demo:</p> <pre><code>cargo run --release -p broker --bin pubsubdemo\n</code></pre> <p>This demo:</p> <ol> <li>Creates a client connection to the broker</li> <li>Subscribes to a test stream</li> <li>Publishes messages to that stream</li> <li>Displays received events</li> </ol> <p>Sample output:</p> <pre><code>Subscriber task started\nPublished 100 messages\nReceived event: payload #0\nReceived event: payload #1\nReceived event: payload #2\n...\nDemo completed: 100/100 messages delivered\n</code></pre>"},{"location":"getting-started/quickstart/#try-the-cache","title":"Try the Cache","text":"<p>Run the cache demonstration:</p> <pre><code>cargo run --release -p broker --bin cachedemo\n</code></pre> <p>This benchmarks cache operations (put, get_hit, get_miss) across various payload sizes and measures latency/throughput.</p>"},{"location":"getting-started/quickstart/#using-the-client-sdk","title":"Using the Client SDK","text":"<p>Here's a minimal example of using the Felix Rust client:</p>"},{"location":"getting-started/quickstart/#publish-and-subscribe","title":"Publish and Subscribe","text":"<pre><code>use felix_client::{ClientConfig, FelixClient};\n\n#[tokio::main]\nasync fn main() -&gt; anyhow::Result&lt;()&gt; {\n    // Configure client\n    let config = ClientConfig {\n        broker_addr: \"127.0.0.1:5000\".parse()?,\n        ..Default::default()\n    };\n\n    // Connect to broker\n    let client = FelixClient::connect(config).await?;\n\n    // Subscribe to a stream\n    let mut subscription = client\n        .subscribe(\"my-tenant\", \"my-namespace\", \"my-stream\")\n        .await?;\n\n    // Spawn a task to receive events\n    tokio::spawn(async move {\n        while let Some(event) = subscription.recv().await {\n            println!(\"Received: {:?}\", event);\n        }\n    });\n\n    // Publish messages\n    for i in 0..10 {\n        let payload = format!(\"Message {}\", i);\n        client\n            .publish(\"my-tenant\", \"my-namespace\", \"my-stream\", payload.as_bytes())\n            .await?;\n    }\n\n    Ok(())\n}\n</code></pre>"},{"location":"getting-started/quickstart/#cache-operations","title":"Cache Operations","text":"<pre><code>use felix_client::{ClientConfig, FelixClient};\n\n#[tokio::main]\nasync fn main() -&gt; anyhow::Result&lt;()&gt; {\n    let config = ClientConfig {\n        broker_addr: \"127.0.0.1:5000\".parse()?,\n        ..Default::default()\n    };\n\n    let client = FelixClient::connect(config).await?;\n\n    // Put a value with 60-second TTL\n    client\n        .cache_put(\"user:123\", b\"alice\", Some(60_000))\n        .await?;\n\n    // Get the value\n    if let Some(value) = client.cache_get(\"user:123\").await? {\n        println!(\"Cached value: {:?}\", value);\n    }\n\n    Ok(())\n}\n</code></pre> <p>API Surface</p> <p>The exact client API is evolving. Check <code>crates/felix-client/src/</code> for the current implementation. The examples above represent the intended ergonomics.</p>"},{"location":"getting-started/quickstart/#performance-testing","title":"Performance Testing","text":""},{"location":"getting-started/quickstart/#latency-benchmark","title":"Latency Benchmark","text":"<p>Run the latency demo with various configurations:</p> <pre><code># Basic run with defaults\ncargo run --release -p broker --bin latencydemo\n\n# Custom configuration\ncargo run --release -p broker --bin latencydemo -- \\\n    --binary \\\n    --fanout 10 \\\n    --batch 64 \\\n    --payload 4096 \\\n    --total 10000 \\\n    --warmup 500\n</code></pre> <p>Parameters:</p> <ul> <li><code>--binary</code>: Use binary batch format (higher throughput)</li> <li><code>--fanout N</code>: Number of concurrent subscribers</li> <li><code>--batch N</code>: Batch size for publishing</li> <li><code>--payload N</code>: Payload size in bytes</li> <li><code>--total N</code>: Total messages to send</li> <li><code>--warmup N</code>: Warmup messages before measurement</li> </ul>"},{"location":"getting-started/quickstart/#cache-benchmark","title":"Cache Benchmark","text":"<pre><code>cargo run --release -p broker --bin cachedemo\n</code></pre> <p>Measures cache operations at various payload sizes with configurable concurrency.</p>"},{"location":"getting-started/quickstart/#configuration","title":"Configuration","text":"<p>Felix can be configured via environment variables or a YAML config file.</p>"},{"location":"getting-started/quickstart/#environment-variables","title":"Environment Variables","text":"<p>Key performance tuning variables:</p> <pre><code># Event delivery (pub/sub)\nexport FELIX_EVENT_CONN_POOL=8\nexport FELIX_EVENT_BATCH_MAX_DELAY_US=250\n\n# Cache operations\nexport FELIX_CACHE_CONN_POOL=8\nexport FELIX_CACHE_STREAMS_PER_CONN=4\n\n# Publishing\nexport FELIX_PUBLISH_CHUNK_BYTES=16384\n</code></pre>"},{"location":"getting-started/quickstart/#config-file","title":"Config File","text":"<p>Create <code>/tmp/felix-config.yml</code>:</p> <pre><code>quic_bind: \"0.0.0.0:5000\"\nmetrics_bind: \"0.0.0.0:8080\"\nevent_batch_max_events: 64\nevent_batch_max_delay_us: 250\ncache_conn_recv_window: 268435456\n</code></pre> <p>Run with custom config:</p> <pre><code>FELIX_BROKER_CONFIG=/tmp/felix-config.yml cargo run --release -p broker\n</code></pre> <p>See Configuration Reference for all options.</p>"},{"location":"getting-started/quickstart/#using-task","title":"Using Task","text":"<p>If you have Task installed, you can use convenience commands:</p> <pre><code># Build\ntask build\n\n# Run tests\ntask test\n\n# Format code\ntask fmt\n\n# Run linter\ntask lint\n\n# Run demos\ntask demo-pubsub\ntask demo-cache\ntask demo-latency\n</code></pre> <p>See <code>Taskfile.yml</code> in the repository root for all available tasks.</p>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<p>Now that you have Felix running:</p> <ul> <li>Explore the Architecture: System Design</li> <li>Learn the APIs: Broker API</li> <li>Tune Performance: Performance Guide</li> <li>Deploy Properly: Deployment Guides</li> <li>Contribute: Development Guide</li> </ul>"},{"location":"getting-started/quickstart/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/quickstart/#port-already-in-use","title":"Port Already in Use","text":"<p>If port 5000 or 8080 is in use:</p> <pre><code># Change broker port\nexport FELIX_QUIC_BIND=\"0.0.0.0:5001\"\nexport FELIX_METRICS_BIND=\"0.0.0.0:8081\"\n\ncargo run --release -p broker\n</code></pre>"},{"location":"getting-started/quickstart/#build-errors","title":"Build Errors","text":"<p>Ensure you have Rust 1.92.0 or later:</p> <pre><code>rustc --version\n# Should show: rustc 1.92.0 or higher\n</code></pre> <p>Update if needed:</p> <pre><code>rustup update\n</code></pre>"},{"location":"getting-started/quickstart/#connection-refused","title":"Connection Refused","text":"<p>Make sure the broker is running and listening:</p> <pre><code># Check if broker is running\nlsof -i :5000\n\n# Check broker logs for errors\n</code></pre> <p>See Troubleshooting Guide for more help.</p>"},{"location":"reference/configuration/","title":"Configuration Reference","text":"<p>Complete reference for all Felix broker configuration options.</p>"},{"location":"reference/configuration/#configuration-methods","title":"Configuration Methods","text":"<p>Felix supports three configuration methods, applied in order (later sources override earlier):</p> <ol> <li>Built-in defaults: Sensible defaults for development</li> <li>Environment variables: <code>FELIX_*</code> variables for quick overrides</li> <li>YAML config file: Structured configuration for production</li> </ol>"},{"location":"reference/configuration/#precedence-example","title":"Precedence Example","text":"<pre><code># Default: quic_bind = 0.0.0.0:5000\n# Environment: FELIX_QUIC_BIND=127.0.0.1:5001\n# YAML: quic_bind: \"0.0.0.0:6000\"\n# Result: 0.0.0.0:6000 (YAML wins)\n</code></pre>"},{"location":"reference/configuration/#configuration-structure","title":"Configuration Structure","text":""},{"location":"reference/configuration/#yaml-config-file","title":"YAML Config File","text":"<p>Location priority:</p> <ol> <li><code>$FELIX_BROKER_CONFIG</code> (explicit path)</li> <li><code>/usr/local/felix/config.yml</code> (default, optional)</li> </ol> <p>Example:</p> <pre><code>quic_bind: \"0.0.0.0:5000\"\nmetrics_bind: \"0.0.0.0:8080\"\ncontrolplane_url: \"http://controlplane:8443\"\ncontrolplane_sync_interval_ms: 2000\nack_on_commit: false\nmax_frame_bytes: 16777216\npublish_queue_wait_timeout_ms: 2000\nack_wait_timeout_ms: 2000\ndisable_timings: false\ncontrol_stream_drain_timeout_ms: 50\ncache_conn_recv_window: 268435456\ncache_stream_recv_window: 67108864\ncache_send_window: 268435456\nevent_batch_max_events: 64\nevent_batch_max_bytes: 262144\nevent_batch_max_delay_us: 250\nfanout_batch_size: 64\npub_workers_per_conn: 4\npub_queue_depth: 1024\nevent_queue_depth: 1024\nevent_single_binary_enabled: false\nevent_single_binary_min_bytes: 512\n</code></pre>"},{"location":"reference/configuration/#network-configuration","title":"Network Configuration","text":""},{"location":"reference/configuration/#quic_bind","title":"<code>quic_bind</code>","text":"<p>Description: QUIC listener bind address and port.</p> <p>Type: <code>SocketAddr</code> (IP:Port)</p> <p>Default: <code>0.0.0.0:5000</code></p> <p>Environment: <code>FELIX_QUIC_BIND</code></p> <p>Example: <pre><code>quic_bind: \"0.0.0.0:5000\"\n</code></pre></p> <p>Notes: - UDP port for QUIC transport - Use <code>0.0.0.0</code> to listen on all interfaces - Use <code>127.0.0.1</code> for localhost only</p>"},{"location":"reference/configuration/#metrics_bind","title":"<code>metrics_bind</code>","text":"<p>Description: HTTP metrics and health endpoint bind address.</p> <p>Type: <code>SocketAddr</code> (IP:Port)</p> <p>Default: <code>0.0.0.0:8080</code></p> <p>Environment: <code>FELIX_BROKER_METRICS_BIND</code></p> <p>Example: <pre><code>metrics_bind: \"0.0.0.0:8080\"\n</code></pre></p> <p>Endpoints: - <code>/healthz</code>: Health check - <code>/metrics</code>: Prometheus metrics (if enabled)</p>"},{"location":"reference/configuration/#control-plane-configuration","title":"Control Plane Configuration","text":""},{"location":"reference/configuration/#controlplane_url","title":"<code>controlplane_url</code>","text":"<p>Description: Optional control plane base URL for metadata sync.</p> <p>Type: <code>String</code> (URL)</p> <p>Default: <code>None</code></p> <p>Environment: <code>FELIX_CP_URL</code></p> <p>Example: <pre><code>controlplane_url: \"http://felix-controlplane:8443\"\n</code></pre></p> <p>Notes: - Optional for single-node deployments - Required for multi-node clusters - Should include scheme (<code>http://</code> or <code>https://</code>)</p>"},{"location":"reference/configuration/#controlplane_sync_interval_ms","title":"<code>controlplane_sync_interval_ms</code>","text":"<p>Description: Interval for polling control plane changes.</p> <p>Type: <code>u64</code> (milliseconds)</p> <p>Default: <code>2000</code></p> <p>Environment: <code>FELIX_CP_SYNC_INTERVAL_MS</code></p> <p>Example: <pre><code>controlplane_sync_interval_ms: 2000\n</code></pre></p> <p>Recommendations: - Fast changes: <code>500-1000ms</code> - Normal operation: <code>2000-5000ms</code> - Stable clusters: <code>5000-10000ms</code></p>"},{"location":"reference/configuration/#publishing-configuration","title":"Publishing Configuration","text":""},{"location":"reference/configuration/#ack_on_commit","title":"<code>ack_on_commit</code>","text":"<p>Description: Send acknowledgements after message commit.</p> <p>Type: <code>bool</code></p> <p>Default: <code>false</code></p> <p>Environment: <code>FELIX_ACK_ON_COMMIT</code> (<code>1</code>, <code>true</code>, <code>yes</code> = enabled)</p> <p>Example: <pre><code>ack_on_commit: true\n</code></pre></p> <p>Trade-offs: - <code>false</code>: Lower latency, fire-and-forget semantics - <code>true</code>: Higher latency, explicit acknowledgement</p>"},{"location":"reference/configuration/#max_frame_bytes","title":"<code>max_frame_bytes</code>","text":"<p>Description: Maximum frame size accepted on QUIC streams.</p> <p>Type: <code>usize</code> (bytes)</p> <p>Default: <code>16777216</code> (16 MiB)</p> <p>Environment: <code>FELIX_MAX_FRAME_BYTES</code></p> <p>Example: <pre><code>max_frame_bytes: 16777216\n</code></pre></p> <p>Notes: - Limits individual message size - Affects memory usage per stream - Must match client expectations</p>"},{"location":"reference/configuration/#publish_queue_wait_timeout_ms","title":"<code>publish_queue_wait_timeout_ms</code>","text":"<p>Description: Maximum time to wait when backpressuring publish enqueue.</p> <p>Type: <code>u64</code> (milliseconds)</p> <p>Default: <code>2000</code></p> <p>Environment: <code>FELIX_PUBLISH_QUEUE_WAIT_MS</code></p> <p>Example: <pre><code>publish_queue_wait_timeout_ms: 2000\n</code></pre></p> <p>Behavior: - Publish blocks if queue is full - Returns error after timeout - Prevents unbounded memory growth</p>"},{"location":"reference/configuration/#ack_wait_timeout_ms","title":"<code>ack_wait_timeout_ms</code>","text":"<p>Description: Maximum time to wait for ack-on-commit completion.</p> <p>Type: <code>u64</code> (milliseconds)</p> <p>Default: <code>2000</code></p> <p>Environment: <code>FELIX_ACK_WAIT_TIMEOUT_MS</code></p> <p>Example: <pre><code>ack_wait_timeout_ms: 2000\n</code></pre></p> <p>Notes: - Only applies when <code>ack_on_commit: true</code> - Publisher receives error if exceeded</p>"},{"location":"reference/configuration/#event-delivery-configuration","title":"Event Delivery Configuration","text":""},{"location":"reference/configuration/#event_batch_max_events","title":"<code>event_batch_max_events</code>","text":"<p>Description: Maximum events per batched subscription frame.</p> <p>Type: <code>usize</code> (count)</p> <p>Default: <code>64</code></p> <p>Environment: <code>FELIX_EVENT_BATCH_MAX_EVENTS</code></p> <p>Example: <pre><code>event_batch_max_events: 64\n</code></pre></p> <p>Tuning: - Low latency: <code>1-16</code> - Balanced: <code>32-64</code> - High throughput: <code>128-256</code></p>"},{"location":"reference/configuration/#event_batch_max_bytes","title":"<code>event_batch_max_bytes</code>","text":"<p>Description: Maximum bytes per batched subscription frame.</p> <p>Type: <code>usize</code> (bytes)</p> <p>Default: <code>262144</code> (256 KiB)</p> <p>Environment: <code>FELIX_EVENT_BATCH_MAX_BYTES</code></p> <p>Example: <pre><code>event_batch_max_bytes: 262144\n</code></pre></p> <p>Notes: - Whichever limit hits first triggers batch send - Consider payload size when tuning</p>"},{"location":"reference/configuration/#event_batch_max_delay_us","title":"<code>event_batch_max_delay_us</code>","text":"<p>Description: Maximum delay before flushing a subscription batch.</p> <p>Type: <code>u64</code> (microseconds)</p> <p>Default: <code>250</code></p> <p>Environment: <code>FELIX_EVENT_BATCH_MAX_DELAY_US</code></p> <p>Example: <pre><code>event_batch_max_delay_us: 250\n</code></pre></p> <p>Tuning: - Ultra-low latency: <code>50-100us</code> - Balanced: <code>250-500us</code> - High throughput: <code>1000-5000us</code></p> <p>Latency Impact</p> <p>Lower values reduce latency but may decrease throughput. Higher values improve batching efficiency but increase tail latency.</p>"},{"location":"reference/configuration/#fanout_batch_size","title":"<code>fanout_batch_size</code>","text":"<p>Description: Number of subscribers to send to in parallel during fanout.</p> <p>Type: <code>usize</code> (count)</p> <p>Default: <code>64</code></p> <p>Environment: <code>FELIX_FANOUT_BATCH</code></p> <p>Example: <pre><code>fanout_batch_size: 64\n</code></pre></p> <p>Recommendations: - Low fanout (1-10): <code>16-32</code> - Medium fanout (10-100): <code>64-128</code> - High fanout (100+): <code>128-256</code></p>"},{"location":"reference/configuration/#event_single_binary_enabled","title":"<code>event_single_binary_enabled</code>","text":"<p>Description: Use binary encoding for single events (non-batched).</p> <p>Type: <code>bool</code></p> <p>Default: <code>false</code></p> <p>Environment: <code>FELIX_BINARY_SINGLE_EVENT</code> (<code>1</code>, <code>true</code>, <code>yes</code>, <code>TRUE</code>, <code>YES</code> = enabled)</p> <p>Example: <pre><code>event_single_binary_enabled: true\n</code></pre></p> <p>Benefits: - Lower serialization overhead - Higher throughput for large payloads - Reduced latency when payload &gt; threshold</p>"},{"location":"reference/configuration/#event_single_binary_min_bytes","title":"<code>event_single_binary_min_bytes</code>","text":"<p>Description: Minimum payload size to use binary encoding for single events.</p> <p>Type: <code>usize</code> (bytes)</p> <p>Default: <code>512</code></p> <p>Environment: <code>FELIX_BINARY_SINGLE_EVENT_MIN_BYTES</code></p> <p>Example: <pre><code>event_single_binary_min_bytes: 512\n</code></pre></p> <p>Tuning: - Small messages benefit less from binary encoding - Recommended: <code>256-1024</code> bytes</p>"},{"location":"reference/configuration/#cache-configuration","title":"Cache Configuration","text":""},{"location":"reference/configuration/#cache_conn_recv_window","title":"<code>cache_conn_recv_window</code>","text":"<p>Description: Cache connection flow-control receive window.</p> <p>Type: <code>u64</code> (bytes)</p> <p>Default: <code>268435456</code> (256 MiB)</p> <p>Environment: <code>FELIX_CACHE_CONN_RECV_WINDOW</code></p> <p>Example: <pre><code>cache_conn_recv_window: 268435456\n</code></pre></p> <p>Notes: - Per-connection receive credit - Multiplied by connection pool size - Affects burst tolerance</p>"},{"location":"reference/configuration/#cache_stream_recv_window","title":"<code>cache_stream_recv_window</code>","text":"<p>Description: Cache stream flow-control receive window.</p> <p>Type: <code>u64</code> (bytes)</p> <p>Default: <code>67108864</code> (64 MiB)</p> <p>Environment: <code>FELIX_CACHE_STREAM_RECV_WINDOW</code></p> <p>Example: <pre><code>cache_stream_recv_window: 67108864\n</code></pre></p> <p>Notes: - Per-stream receive credit - Multiplied by streams per connection - Total credit = <code>stream_window \u00d7 streams_per_conn \u00d7 conn_pool</code></p>"},{"location":"reference/configuration/#cache_send_window","title":"<code>cache_send_window</code>","text":"<p>Description: Cache connection send window.</p> <p>Type: <code>u64</code> (bytes)</p> <p>Default: <code>268435456</code> (256 MiB)</p> <p>Environment: <code>FELIX_CACHE_SEND_WINDOW</code></p> <p>Example: <pre><code>cache_send_window: 268435456\n</code></pre></p> <p>Notes: - Per-connection send credit - Affects concurrent request throughput</p>"},{"location":"reference/configuration/#worker-and-queue-configuration","title":"Worker and Queue Configuration","text":""},{"location":"reference/configuration/#pub_workers_per_conn","title":"<code>pub_workers_per_conn</code>","text":"<p>Description: Publish worker count per QUIC connection.</p> <p>Type: <code>usize</code> (count)</p> <p>Default: <code>4</code></p> <p>Environment: <code>FELIX_BROKER_PUB_WORKERS_PER_CONN</code></p> <p>Example: <pre><code>pub_workers_per_conn: 4\n</code></pre></p> <p>Recommendations: - Low concurrency: <code>2-4</code> - High concurrency: <code>8-16</code> - Match to expected concurrent publishers per connection</p>"},{"location":"reference/configuration/#pub_queue_depth","title":"<code>pub_queue_depth</code>","text":"<p>Description: Per-worker publish queue depth.</p> <p>Type: <code>usize</code> (count)</p> <p>Default: <code>1024</code></p> <p>Environment: <code>FELIX_BROKER_PUB_QUEUE_DEPTH</code></p> <p>Example: <pre><code>pub_queue_depth: 1024\n</code></pre></p> <p>Tuning: - Larger values allow more buffering under burst - Affects memory usage per worker - Consider with <code>publish_queue_wait_timeout_ms</code></p>"},{"location":"reference/configuration/#event_queue_depth","title":"<code>event_queue_depth</code>","text":"<p>Description: Subscription event queue depth.</p> <p>Type: <code>usize</code> (count)</p> <p>Default: <code>1024</code></p> <p>Environment: <code>FELIX_EVENT_QUEUE_DEPTH</code></p> <p>Example: <pre><code>event_queue_depth: 1024\n</code></pre></p> <p>Recommendations: - Sufficient to absorb bursts without blocking fanout - Larger values for high-fanout scenarios - Balance with memory constraints</p>"},{"location":"reference/configuration/#performance-configuration","title":"Performance Configuration","text":""},{"location":"reference/configuration/#disable_timings","title":"<code>disable_timings</code>","text":"<p>Description: Disable per-stage timing collection for lower overhead.</p> <p>Type: <code>bool</code></p> <p>Default: <code>false</code></p> <p>Environment: <code>FELIX_DISABLE_TIMINGS</code> (<code>1</code>, <code>true</code>, <code>yes</code> = disabled)</p> <p>Example: <pre><code>disable_timings: true\n</code></pre></p> <p>Trade-offs: - <code>false</code>: Detailed latency metrics, slight overhead - <code>true</code>: Maximum performance, no per-stage timings</p> <p>Recommendations: - Development: <code>false</code> (debug performance) - Production low-load: <code>false</code> (observability) - Production high-load: <code>true</code> (reduce overhead)</p>"},{"location":"reference/configuration/#control_stream_drain_timeout_ms","title":"<code>control_stream_drain_timeout_ms</code>","text":"<p>Description: Maximum time to wait for control-stream writer to drain.</p> <p>Type: <code>u64</code> (milliseconds)</p> <p>Default: <code>50</code></p> <p>Environment: <code>FELIX_CONTROL_STREAM_DRAIN_TIMEOUT_MS</code></p> <p>Example: <pre><code>control_stream_drain_timeout_ms: 50\n</code></pre></p> <p>Notes: - Affects graceful connection shutdown - Balance between responsiveness and reliability</p>"},{"location":"reference/configuration/#client-side-configuration","title":"Client-Side Configuration","text":"<p>While this reference covers broker configuration, clients also have tunable parameters:</p>"},{"location":"reference/configuration/#event-connection-pool","title":"Event Connection Pool","text":"<p>Environment: <code>FELIX_EVENT_CONN_POOL</code></p> <p>Default: <code>8</code></p> <p>Description: Number of QUIC connections in the event pool.</p>"},{"location":"reference/configuration/#cache-connection-pool","title":"Cache Connection Pool","text":"<p>Environment: <code>FELIX_CACHE_CONN_POOL</code></p> <p>Default: <code>8</code></p> <p>Description: Number of QUIC connections for cache operations.</p>"},{"location":"reference/configuration/#cache-streams-per-connection","title":"Cache Streams Per Connection","text":"<p>Environment: <code>FELIX_CACHE_STREAMS_PER_CONN</code></p> <p>Default: <code>4</code></p> <p>Description: Concurrent cache streams per connection.</p>"},{"location":"reference/configuration/#publish-chunk-bytes","title":"Publish Chunk Bytes","text":"<p>Environment: <code>FELIX_PUBLISH_CHUNK_BYTES</code></p> <p>Default: <code>16384</code> (16 KiB)</p> <p>Description: Chunk size for publishing large messages.</p>"},{"location":"reference/configuration/#configuration-validation","title":"Configuration Validation","text":"<p>Felix validates configuration at startup:</p> <pre><code># Test configuration\ncargo run --release -p broker -- --dry-run\n\n# Explicit config file\nFELIX_BROKER_CONFIG=/path/to/config.yml cargo run --release -p broker\n</code></pre> <p>Common validation errors:</p> <ul> <li>Invalid socket address format</li> <li>Negative or zero values where positive required</li> <li>Conflicting settings</li> </ul>"},{"location":"reference/configuration/#performance-profiles","title":"Performance Profiles","text":""},{"location":"reference/configuration/#low-latency-p50-optimized","title":"Low Latency (p50-optimized)","text":"<pre><code>event_batch_max_events: 1\nevent_batch_max_delay_us: 50\nfanout_batch_size: 16\ndisable_timings: true\nevent_single_binary_enabled: false\n</code></pre>"},{"location":"reference/configuration/#balanced-recommended","title":"Balanced (recommended)","text":"<pre><code>event_batch_max_events: 64\nevent_batch_max_delay_us: 250\nfanout_batch_size: 64\ndisable_timings: false\ncache_conn_recv_window: 268435456\n</code></pre>"},{"location":"reference/configuration/#high-throughput-batch-optimized","title":"High Throughput (batch-optimized)","text":"<pre><code>event_batch_max_events: 256\nevent_batch_max_bytes: 1048576\nevent_batch_max_delay_us: 1000\nfanout_batch_size: 128\nevent_single_binary_enabled: true\ndisable_timings: true\n</code></pre>"},{"location":"reference/configuration/#high-memory-burst-tolerant","title":"High Memory (burst-tolerant)","text":"<pre><code>cache_conn_recv_window: 536870912\ncache_stream_recv_window: 134217728\ncache_send_window: 536870912\nevent_queue_depth: 2048\npub_queue_depth: 2048\n</code></pre>"},{"location":"reference/configuration/#configuration-examples","title":"Configuration Examples","text":""},{"location":"reference/configuration/#development","title":"Development","text":"<pre><code>quic_bind: \"127.0.0.1:5000\"\nmetrics_bind: \"127.0.0.1:8080\"\ndisable_timings: false\nevent_batch_max_events: 32\n</code></pre>"},{"location":"reference/configuration/#production-single-node","title":"Production Single-Node","text":"<pre><code>quic_bind: \"0.0.0.0:5000\"\nmetrics_bind: \"0.0.0.0:8080\"\nack_on_commit: true\ndisable_timings: true\nevent_batch_max_events: 64\nevent_batch_max_delay_us: 250\ncache_conn_recv_window: 268435456\n</code></pre>"},{"location":"reference/configuration/#production-cluster","title":"Production Cluster","text":"<pre><code>quic_bind: \"0.0.0.0:5000\"\nmetrics_bind: \"0.0.0.0:8080\"\ncontrolplane_url: \"http://felix-controlplane:8443\"\ncontrolplane_sync_interval_ms: 2000\nack_on_commit: true\ndisable_timings: true\nevent_batch_max_events: 128\nevent_batch_max_bytes: 524288\nfanout_batch_size: 128\n</code></pre>"},{"location":"reference/configuration/#next-steps","title":"Next Steps","text":"<ul> <li>Environment variables reference: Environment Variables</li> <li>Troubleshooting issues: Troubleshooting Guide</li> <li>Performance tuning: Performance Guide</li> </ul>"},{"location":"reference/environment-variables/","title":"Environment Variables Reference","text":"<p>Complete reference for all Felix environment variables, organized by category.</p>"},{"location":"reference/environment-variables/#overview","title":"Overview","text":"<p>Felix uses environment variables prefixed with <code>FELIX_</code> for configuration. These variables provide quick overrides without modifying config files.</p> <p>Priority: Environment variables override built-in defaults but are overridden by YAML config files.</p>"},{"location":"reference/environment-variables/#network-and-binding","title":"Network and Binding","text":""},{"location":"reference/environment-variables/#felix_quic_bind","title":"<code>FELIX_QUIC_BIND</code>","text":"<p>Description: QUIC listener bind address and port (UDP).</p> <p>Type: <code>SocketAddr</code> format</p> <p>Default: <code>0.0.0.0:5000</code></p> <p>Example: <pre><code>export FELIX_QUIC_BIND=\"0.0.0.0:5000\"\nexport FELIX_QUIC_BIND=\"127.0.0.1:5001\"  # Localhost only\nexport FELIX_QUIC_BIND=\"10.0.1.5:5000\"   # Specific interface\n</code></pre></p> <p>Notes: - Must be a valid IP:Port combination - UDP port for QUIC transport - Use <code>0.0.0.0</code> to bind all interfaces</p>"},{"location":"reference/environment-variables/#felix_broker_metrics_bind","title":"<code>FELIX_BROKER_METRICS_BIND</code>","text":"<p>Description: HTTP metrics and health endpoint bind address.</p> <p>Type: <code>SocketAddr</code> format</p> <p>Default: <code>0.0.0.0:8080</code></p> <p>Example: <pre><code>export FELIX_BROKER_METRICS_BIND=\"0.0.0.0:8080\"\n</code></pre></p> <p>Exposed endpoints: - <code>/healthz</code>: Health check - <code>/metrics</code>: Prometheus metrics (when telemetry enabled)</p>"},{"location":"reference/environment-variables/#control-plane","title":"Control Plane","text":""},{"location":"reference/environment-variables/#felix_cp_url","title":"<code>FELIX_CP_URL</code>","text":"<p>Description: Control plane base URL for metadata synchronization.</p> <p>Type: String (URL)</p> <p>Default: None</p> <p>Example: <pre><code>export FELIX_CP_URL=\"http://felix-controlplane:8443\"\nexport FELIX_CP_URL=\"https://cp.example.com:8443\"\n</code></pre></p> <p>Usage: - Optional for single-node deployments - Required for multi-broker clusters - Include scheme (<code>http://</code> or <code>https://</code>)</p>"},{"location":"reference/environment-variables/#felix_cp_sync_interval_ms","title":"<code>FELIX_CP_SYNC_INTERVAL_MS</code>","text":"<p>Description: Control plane polling interval in milliseconds.</p> <p>Type: Unsigned integer</p> <p>Default: <code>2000</code></p> <p>Example: <pre><code>export FELIX_CP_SYNC_INTERVAL_MS=\"2000\"\nexport FELIX_CP_SYNC_INTERVAL_MS=\"500\"   # Fast polling\nexport FELIX_CP_SYNC_INTERVAL_MS=\"10000\" # Slow polling\n</code></pre></p>"},{"location":"reference/environment-variables/#publishing-configuration","title":"Publishing Configuration","text":""},{"location":"reference/environment-variables/#felix_ack_on_commit","title":"<code>FELIX_ACK_ON_COMMIT</code>","text":"<p>Description: Enable publish acknowledgements after commit.</p> <p>Type: Boolean</p> <p>Default: <code>false</code></p> <p>Accepted values: <code>1</code>, <code>true</code>, <code>yes</code> (case-insensitive) = enabled</p> <p>Example: <pre><code>export FELIX_ACK_ON_COMMIT=\"true\"\nexport FELIX_ACK_ON_COMMIT=\"1\"\nexport FELIX_ACK_ON_COMMIT=\"yes\"\n</code></pre></p> <p>Trade-off: - <code>false</code>: Fire-and-forget, lower latency - <code>true</code>: Explicit acks, higher latency guarantee</p>"},{"location":"reference/environment-variables/#felix_max_frame_bytes","title":"<code>FELIX_MAX_FRAME_BYTES</code>","text":"<p>Description: Maximum frame size accepted on QUIC streams.</p> <p>Type: Positive integer (bytes)</p> <p>Default: <code>16777216</code> (16 MiB)</p> <p>Example: <pre><code>export FELIX_MAX_FRAME_BYTES=\"16777216\"    # 16 MiB\nexport FELIX_MAX_FRAME_BYTES=\"33554432\"    # 32 MiB\nexport FELIX_MAX_FRAME_BYTES=\"8388608\"     # 8 MiB\n</code></pre></p> <p>Notes: - Value of <code>0</code> uses default - Affects max message size - Must align with client configuration</p>"},{"location":"reference/environment-variables/#felix_publish_queue_wait_ms","title":"<code>FELIX_PUBLISH_QUEUE_WAIT_MS</code>","text":"<p>Description: Maximum wait time when publish queue is full.</p> <p>Type: Positive integer (milliseconds)</p> <p>Default: <code>2000</code></p> <p>Example: <pre><code>export FELIX_PUBLISH_QUEUE_WAIT_MS=\"2000\"\nexport FELIX_PUBLISH_QUEUE_WAIT_MS=\"5000\"  # More patient\nexport FELIX_PUBLISH_QUEUE_WAIT_MS=\"500\"   # Fail fast\n</code></pre></p> <p>Behavior: - Publisher blocks if queue full - Returns error after timeout - Backpressure mechanism</p>"},{"location":"reference/environment-variables/#felix_ack_wait_timeout_ms","title":"<code>FELIX_ACK_WAIT_TIMEOUT_MS</code>","text":"<p>Description: Maximum wait time for ack-on-commit completion.</p> <p>Type: Positive integer (milliseconds)</p> <p>Default: <code>2000</code></p> <p>Example: <pre><code>export FELIX_ACK_WAIT_TIMEOUT_MS=\"2000\"\n</code></pre></p> <p>Notes: - Only relevant when <code>FELIX_ACK_ON_COMMIT=true</code> - Publisher gets error if timeout exceeded</p>"},{"location":"reference/environment-variables/#event-batching-and-delivery","title":"Event Batching and Delivery","text":""},{"location":"reference/environment-variables/#felix_event_batch_max_events","title":"<code>FELIX_EVENT_BATCH_MAX_EVENTS</code>","text":"<p>Description: Maximum events per subscription batch frame.</p> <p>Type: Positive integer (count)</p> <p>Default: <code>64</code></p> <p>Example: <pre><code>export FELIX_EVENT_BATCH_MAX_EVENTS=\"64\"\nexport FELIX_EVENT_BATCH_MAX_EVENTS=\"1\"    # No batching\nexport FELIX_EVENT_BATCH_MAX_EVENTS=\"256\"  # Large batches\n</code></pre></p> <p>Tuning: - Small values (1-16): Low latency - Medium values (32-64): Balanced - Large values (128-256): High throughput</p>"},{"location":"reference/environment-variables/#felix_event_batch_max_bytes","title":"<code>FELIX_EVENT_BATCH_MAX_BYTES</code>","text":"<p>Description: Maximum bytes per subscription batch frame.</p> <p>Type: Positive integer (bytes)</p> <p>Default: <code>262144</code> (256 KiB)</p> <p>Example: <pre><code>export FELIX_EVENT_BATCH_MAX_BYTES=\"262144\"   # 256 KiB\nexport FELIX_EVENT_BATCH_MAX_BYTES=\"524288\"   # 512 KiB\nexport FELIX_EVENT_BATCH_MAX_BYTES=\"1048576\"  # 1 MiB\n</code></pre></p> <p>Notes: - Batch sent when event count OR byte limit reached - Adjust based on typical message size</p>"},{"location":"reference/environment-variables/#felix_event_batch_max_delay_us","title":"<code>FELIX_EVENT_BATCH_MAX_DELAY_US</code>","text":"<p>Description: Maximum delay before flushing batch (microseconds).</p> <p>Type: Unsigned integer</p> <p>Default: <code>250</code></p> <p>Example: <pre><code>export FELIX_EVENT_BATCH_MAX_DELAY_US=\"250\"\nexport FELIX_EVENT_BATCH_MAX_DELAY_US=\"50\"    # Ultra-low latency\nexport FELIX_EVENT_BATCH_MAX_DELAY_US=\"1000\"  # Prioritize batching\nexport FELIX_EVENT_BATCH_MAX_DELAY_US=\"5000\"  # Maximum batching\n</code></pre></p> <p>Critical tuning parameter: - Lower: Reduced latency, more frequent sends - Higher: Better batching, higher latency - Typical range: 50-1000 microseconds</p>"},{"location":"reference/environment-variables/#felix_fanout_batch","title":"<code>FELIX_FANOUT_BATCH</code>","text":"<p>Description: Subscribers to process in parallel during fanout.</p> <p>Type: Positive integer (count)</p> <p>Default: <code>64</code></p> <p>Example: <pre><code>export FELIX_FANOUT_BATCH=\"64\"\nexport FELIX_FANOUT_BATCH=\"128\"  # High fanout\nexport FELIX_FANOUT_BATCH=\"16\"   # Low fanout\n</code></pre></p> <p>Recommendations: - Match to typical subscriber count - Higher values for high-fanout streams - Lower values reduce concurrency overhead</p>"},{"location":"reference/environment-variables/#felix_binary_single_event","title":"<code>FELIX_BINARY_SINGLE_EVENT</code>","text":"<p>Description: Enable binary encoding for single (non-batched) events.</p> <p>Type: Boolean</p> <p>Default: <code>false</code></p> <p>Accepted values: <code>1</code>, <code>true</code>, <code>yes</code>, <code>TRUE</code>, <code>YES</code> = enabled</p> <p>Example: <pre><code>export FELIX_BINARY_SINGLE_EVENT=\"true\"\nexport FELIX_BINARY_SINGLE_EVENT=\"TRUE\"\nexport FELIX_BINARY_SINGLE_EVENT=\"1\"\n</code></pre></p> <p>Benefits: - Lower serialization overhead - Better for large payloads - Works with <code>FELIX_BINARY_SINGLE_EVENT_MIN_BYTES</code></p>"},{"location":"reference/environment-variables/#felix_binary_single_event_min_bytes","title":"<code>FELIX_BINARY_SINGLE_EVENT_MIN_BYTES</code>","text":"<p>Description: Minimum payload size for binary encoding.</p> <p>Type: Positive integer (bytes)</p> <p>Default: <code>512</code></p> <p>Example: <pre><code>export FELIX_BINARY_SINGLE_EVENT_MIN_BYTES=\"512\"\nexport FELIX_BINARY_SINGLE_EVENT_MIN_BYTES=\"256\"\nexport FELIX_BINARY_SINGLE_EVENT_MIN_BYTES=\"1024\"\n</code></pre></p> <p>Notes: - Only used when <code>FELIX_BINARY_SINGLE_EVENT=true</code> - Small messages may not benefit from binary encoding</p>"},{"location":"reference/environment-variables/#cache-configuration","title":"Cache Configuration","text":""},{"location":"reference/environment-variables/#felix_cache_conn_pool","title":"<code>FELIX_CACHE_CONN_POOL</code>","text":"<p>Description: Number of QUIC connections in cache pool (client-side).</p> <p>Type: Positive integer (count)</p> <p>Default: <code>8</code></p> <p>Example: <pre><code>export FELIX_CACHE_CONN_POOL=\"8\"\nexport FELIX_CACHE_CONN_POOL=\"16\"  # High concurrency\nexport FELIX_CACHE_CONN_POOL=\"4\"   # Low concurrency\n</code></pre></p> <p>Notes: - Client-side setting - Affects concurrent request capacity - Each connection can have multiple streams</p>"},{"location":"reference/environment-variables/#felix_cache_streams_per_conn","title":"<code>FELIX_CACHE_STREAMS_PER_CONN</code>","text":"<p>Description: Cache request streams per connection (client-side).</p> <p>Type: Positive integer (count)</p> <p>Default: <code>4</code></p> <p>Example: <pre><code>export FELIX_CACHE_STREAMS_PER_CONN=\"4\"\nexport FELIX_CACHE_STREAMS_PER_CONN=\"8\"   # More parallelism\nexport FELIX_CACHE_STREAMS_PER_CONN=\"2\"   # Less overhead\n</code></pre></p> <p>Tuning: - Total cache parallelism = <code>pool \u00d7 streams_per_conn</code> - Higher values for high-concurrency workloads</p>"},{"location":"reference/environment-variables/#felix_cache_conn_recv_window","title":"<code>FELIX_CACHE_CONN_RECV_WINDOW</code>","text":"<p>Description: Cache connection flow-control receive window (broker).</p> <p>Type: Positive integer (bytes)</p> <p>Default: <code>268435456</code> (256 MiB)</p> <p>Example: <pre><code>export FELIX_CACHE_CONN_RECV_WINDOW=\"268435456\"    # 256 MiB\nexport FELIX_CACHE_CONN_RECV_WINDOW=\"536870912\"    # 512 MiB\nexport FELIX_CACHE_CONN_RECV_WINDOW=\"134217728\"    # 128 MiB\n</code></pre></p> <p>Memory impact: - Per-connection credit - Multiplied by connection pool size - Affects burst tolerance</p>"},{"location":"reference/environment-variables/#felix_cache_stream_recv_window","title":"<code>FELIX_CACHE_STREAM_RECV_WINDOW</code>","text":"<p>Description: Cache stream flow-control receive window (broker).</p> <p>Type: Positive integer (bytes)</p> <p>Default: <code>67108864</code> (64 MiB)</p> <p>Example: <pre><code>export FELIX_CACHE_STREAM_RECV_WINDOW=\"67108864\"   # 64 MiB\nexport FELIX_CACHE_STREAM_RECV_WINDOW=\"134217728\"  # 128 MiB\nexport FELIX_CACHE_STREAM_RECV_WINDOW=\"33554432\"   # 32 MiB\n</code></pre></p> <p>Notes: - Per-stream credit - Total: <code>stream_window \u00d7 streams_per_conn \u00d7 conn_pool</code></p>"},{"location":"reference/environment-variables/#felix_cache_send_window","title":"<code>FELIX_CACHE_SEND_WINDOW</code>","text":"<p>Description: Cache connection send window (broker).</p> <p>Type: Positive integer (bytes)</p> <p>Default: <code>268435456</code> (256 MiB)</p> <p>Example: <pre><code>export FELIX_CACHE_SEND_WINDOW=\"268435456\"\n</code></pre></p>"},{"location":"reference/environment-variables/#felix_cache_bench_concurrency","title":"<code>FELIX_CACHE_BENCH_CONCURRENCY</code>","text":"<p>Description: Concurrency level for cache benchmark (demo only).</p> <p>Type: Positive integer</p> <p>Default: <code>32</code></p> <p>Example: <pre><code>export FELIX_CACHE_BENCH_CONCURRENCY=\"32\"\nexport FELIX_CACHE_BENCH_CONCURRENCY=\"64\"  # Stress test\n</code></pre></p>"},{"location":"reference/environment-variables/#felix_cache_bench_keys","title":"<code>FELIX_CACHE_BENCH_KEYS</code>","text":"<p>Description: Number of keys for cache benchmark (demo only).</p> <p>Type: Positive integer</p> <p>Default: <code>1024</code></p> <p>Example: <pre><code>export FELIX_CACHE_BENCH_KEYS=\"1024\"\n</code></pre></p>"},{"location":"reference/environment-variables/#event-connection-pool-client","title":"Event Connection Pool (Client)","text":""},{"location":"reference/environment-variables/#felix_event_conn_pool","title":"<code>FELIX_EVENT_CONN_POOL</code>","text":"<p>Description: Number of QUIC connections for event delivery (client).</p> <p>Type: Positive integer (count)</p> <p>Default: <code>8</code></p> <p>Example: <pre><code>export FELIX_EVENT_CONN_POOL=\"8\"\nexport FELIX_EVENT_CONN_POOL=\"4\"   # Lower overhead\nexport FELIX_EVENT_CONN_POOL=\"16\"  # More parallelism\n</code></pre></p>"},{"location":"reference/environment-variables/#felix_event_conn_recv_window","title":"<code>FELIX_EVENT_CONN_RECV_WINDOW</code>","text":"<p>Description: Event connection receive window (client).</p> <p>Type: Positive integer (bytes)</p> <p>Default: <code>268435456</code> (256 MiB)</p> <p>Example: <pre><code>export FELIX_EVENT_CONN_RECV_WINDOW=\"268435456\"\n</code></pre></p>"},{"location":"reference/environment-variables/#felix_event_stream_recv_window","title":"<code>FELIX_EVENT_STREAM_RECV_WINDOW</code>","text":"<p>Description: Event stream receive window (client).</p> <p>Type: Positive integer (bytes)</p> <p>Default: <code>67108864</code> (64 MiB)</p> <p>Example: <pre><code>export FELIX_EVENT_STREAM_RECV_WINDOW=\"67108864\"\n</code></pre></p>"},{"location":"reference/environment-variables/#felix_event_send_window","title":"<code>FELIX_EVENT_SEND_WINDOW</code>","text":"<p>Description: Event connection send window (client).</p> <p>Type: Positive integer (bytes)</p> <p>Default: <code>268435456</code> (256 MiB)</p> <p>Example: <pre><code>export FELIX_EVENT_SEND_WINDOW=\"268435456\"\n</code></pre></p>"},{"location":"reference/environment-variables/#publishing-pool-client","title":"Publishing Pool (Client)","text":""},{"location":"reference/environment-variables/#felix_pub_conn_pool","title":"<code>FELIX_PUB_CONN_POOL</code>","text":"<p>Description: Number of publishing QUIC connections (client).</p> <p>Type: Positive integer (count)</p> <p>Default: <code>4</code></p> <p>Example: <pre><code>export FELIX_PUB_CONN_POOL=\"4\"\nexport FELIX_PUB_CONN_POOL=\"8\"  # More publishers\n</code></pre></p>"},{"location":"reference/environment-variables/#felix_pub_streams_per_conn","title":"<code>FELIX_PUB_STREAMS_PER_CONN</code>","text":"<p>Description: Publishing streams per connection (client).</p> <p>Type: Positive integer (count)</p> <p>Default: <code>2</code></p> <p>Example: <pre><code>export FELIX_PUB_STREAMS_PER_CONN=\"2\"\nexport FELIX_PUB_STREAMS_PER_CONN=\"4\"  # More concurrency\n</code></pre></p>"},{"location":"reference/environment-variables/#felix_publish_chunk_bytes","title":"<code>FELIX_PUBLISH_CHUNK_BYTES</code>","text":"<p>Description: Chunk size for publishing large messages (client).</p> <p>Type: Positive integer (bytes)</p> <p>Default: <code>16384</code> (16 KiB)</p> <p>Example: <pre><code>export FELIX_PUBLISH_CHUNK_BYTES=\"16384\"    # 16 KiB\nexport FELIX_PUBLISH_CHUNK_BYTES=\"32768\"    # 32 KiB\nexport FELIX_PUBLISH_CHUNK_BYTES=\"8192\"     # 8 KiB\n</code></pre></p>"},{"location":"reference/environment-variables/#broker-workers-and-queues","title":"Broker Workers and Queues","text":""},{"location":"reference/environment-variables/#felix_broker_pub_workers_per_conn","title":"<code>FELIX_BROKER_PUB_WORKERS_PER_CONN</code>","text":"<p>Description: Publish workers per QUIC connection (broker).</p> <p>Type: Positive integer (count)</p> <p>Default: <code>4</code></p> <p>Example: <pre><code>export FELIX_BROKER_PUB_WORKERS_PER_CONN=\"4\"\nexport FELIX_BROKER_PUB_WORKERS_PER_CONN=\"8\"   # High concurrency\nexport FELIX_BROKER_PUB_WORKERS_PER_CONN=\"2\"   # Lower overhead\n</code></pre></p>"},{"location":"reference/environment-variables/#felix_broker_pub_queue_depth","title":"<code>FELIX_BROKER_PUB_QUEUE_DEPTH</code>","text":"<p>Description: Per-worker publish queue depth (broker).</p> <p>Type: Positive integer (count)</p> <p>Default: <code>1024</code></p> <p>Example: <pre><code>export FELIX_BROKER_PUB_QUEUE_DEPTH=\"1024\"\nexport FELIX_BROKER_PUB_QUEUE_DEPTH=\"2048\"  # More buffering\nexport FELIX_BROKER_PUB_QUEUE_DEPTH=\"512\"   # Less memory\n</code></pre></p>"},{"location":"reference/environment-variables/#felix_event_queue_depth","title":"<code>FELIX_EVENT_QUEUE_DEPTH</code>","text":"<p>Description: Subscription event queue depth (broker).</p> <p>Type: Positive integer (count)</p> <p>Default: <code>1024</code></p> <p>Example: <pre><code>export FELIX_EVENT_QUEUE_DEPTH=\"1024\"\nexport FELIX_EVENT_QUEUE_DEPTH=\"2048\"  # High fanout\nexport FELIX_EVENT_QUEUE_DEPTH=\"512\"   # Memory-constrained\n</code></pre></p>"},{"location":"reference/environment-variables/#performance-and-monitoring","title":"Performance and Monitoring","text":""},{"location":"reference/environment-variables/#felix_disable_timings","title":"<code>FELIX_DISABLE_TIMINGS</code>","text":"<p>Description: Disable per-stage timing collection.</p> <p>Type: Boolean</p> <p>Default: <code>false</code></p> <p>Accepted values: <code>1</code>, <code>true</code>, <code>yes</code> = disabled</p> <p>Example: <pre><code>export FELIX_DISABLE_TIMINGS=\"false\"  # Enable timings\nexport FELIX_DISABLE_TIMINGS=\"true\"   # Disable for performance\nexport FELIX_DISABLE_TIMINGS=\"1\"\n</code></pre></p> <p>Trade-off: - <code>false</code>: Detailed metrics, slight overhead - <code>true</code>: Maximum performance, no timing data</p>"},{"location":"reference/environment-variables/#felix_control_stream_drain_timeout_ms","title":"<code>FELIX_CONTROL_STREAM_DRAIN_TIMEOUT_MS</code>","text":"<p>Description: Timeout for control stream drain (broker).</p> <p>Type: Positive integer (milliseconds)</p> <p>Default: <code>50</code></p> <p>Example: <pre><code>export FELIX_CONTROL_STREAM_DRAIN_TIMEOUT_MS=\"50\"\nexport FELIX_CONTROL_STREAM_DRAIN_TIMEOUT_MS=\"100\"  # More graceful\nexport FELIX_CONTROL_STREAM_DRAIN_TIMEOUT_MS=\"20\"   # Faster shutdown\n</code></pre></p>"},{"location":"reference/environment-variables/#configuration-file","title":"Configuration File","text":""},{"location":"reference/environment-variables/#felix_broker_config","title":"<code>FELIX_BROKER_CONFIG</code>","text":"<p>Description: Path to YAML configuration file.</p> <p>Type: String (file path)</p> <p>Default: <code>/usr/local/felix/config.yml</code> (optional)</p> <p>Example: <pre><code>export FELIX_BROKER_CONFIG=\"/etc/felix/broker.yml\"\nexport FELIX_BROKER_CONFIG=\"/tmp/felix-dev.yml\"\n</code></pre></p> <p>Behavior: - If set and file missing: error - If not set and default missing: continue with defaults</p>"},{"location":"reference/environment-variables/#logging","title":"Logging","text":""},{"location":"reference/environment-variables/#rust_log","title":"<code>RUST_LOG</code>","text":"<p>Description: Rust logging filter (not Felix-specific but commonly used).</p> <p>Type: String (filter expression)</p> <p>Default: Varies by build</p> <p>Example: <pre><code>export RUST_LOG=\"info\"\nexport RUST_LOG=\"debug\"\nexport RUST_LOG=\"felix_broker=debug,felix_wire=trace\"\nexport RUST_LOG=\"warn\"\n</code></pre></p> <p>Levels: <code>error</code>, <code>warn</code>, <code>info</code>, <code>debug</code>, <code>trace</code></p>"},{"location":"reference/environment-variables/#performance-profiles","title":"Performance Profiles","text":""},{"location":"reference/environment-variables/#balanced-profile","title":"Balanced Profile","text":"<pre><code>export FELIX_EVENT_CONN_POOL=\"8\"\nexport FELIX_EVENT_CONN_RECV_WINDOW=\"268435456\"\nexport FELIX_EVENT_STREAM_RECV_WINDOW=\"67108864\"\nexport FELIX_EVENT_SEND_WINDOW=\"268435456\"\nexport FELIX_EVENT_BATCH_MAX_DELAY_US=\"250\"\nexport FELIX_CACHE_CONN_POOL=\"8\"\nexport FELIX_CACHE_STREAMS_PER_CONN=\"4\"\nexport FELIX_DISABLE_TIMINGS=\"0\"\n</code></pre>"},{"location":"reference/environment-variables/#high-memory-profile","title":"High Memory Profile","text":"<pre><code>export FELIX_EVENT_CONN_POOL=\"8\"\nexport FELIX_EVENT_CONN_RECV_WINDOW=\"536870912\"\nexport FELIX_EVENT_STREAM_RECV_WINDOW=\"134217728\"\nexport FELIX_EVENT_SEND_WINDOW=\"536870912\"\nexport FELIX_EVENT_BATCH_MAX_DELAY_US=\"250\"\nexport FELIX_CACHE_CONN_POOL=\"8\"\nexport FELIX_CACHE_STREAMS_PER_CONN=\"4\"\nexport FELIX_DISABLE_TIMINGS=\"1\"\n</code></pre>"},{"location":"reference/environment-variables/#low-latency-profile","title":"Low Latency Profile","text":"<pre><code>export FELIX_EVENT_BATCH_MAX_EVENTS=\"1\"\nexport FELIX_EVENT_BATCH_MAX_DELAY_US=\"50\"\nexport FELIX_FANOUT_BATCH=\"16\"\nexport FELIX_DISABLE_TIMINGS=\"1\"\n</code></pre>"},{"location":"reference/environment-variables/#high-throughput-profile","title":"High Throughput Profile","text":"<pre><code>export FELIX_EVENT_BATCH_MAX_EVENTS=\"256\"\nexport FELIX_EVENT_BATCH_MAX_BYTES=\"1048576\"\nexport FELIX_EVENT_BATCH_MAX_DELAY_US=\"1000\"\nexport FELIX_FANOUT_BATCH=\"128\"\nexport FELIX_BINARY_SINGLE_EVENT=\"TRUE\"\nexport FELIX_DISABLE_TIMINGS=\"1\"\n</code></pre>"},{"location":"reference/environment-variables/#validation","title":"Validation","text":"<p>Check current configuration:</p> <pre><code># Print effective configuration\ncargo run --release -p broker -- --dump-config\n\n# Validate without starting\ncargo run --release -p broker -- --validate-config\n</code></pre>"},{"location":"reference/environment-variables/#next-steps","title":"Next Steps","text":"<ul> <li>Full configuration details: Configuration Reference</li> <li>Troubleshooting: Troubleshooting Guide</li> <li>Performance tuning: Performance Guide</li> </ul>"},{"location":"reference/faq/","title":"Frequently Asked Questions","text":"<p>Common questions about Felix, its design, and usage.</p>"},{"location":"reference/faq/#general-questions","title":"General Questions","text":""},{"location":"reference/faq/#what-is-felix","title":"What is Felix?","text":"<p>Felix is a low-latency, QUIC-based pub/sub and distributed cache system designed for high fanout, high throughput, and predictable tail latency. It unifies event streaming (publish/subscribe) and request/response caching (put/get with TTL) over a single transport protocol.</p> <p>Key features:</p> <ul> <li>QUIC transport: Modern, multiplexed, encrypted by default</li> <li>Unified protocol: Single wire protocol for pub/sub and cache</li> <li>Predictable latency: Optimized for p99/p999, not just throughput</li> <li>Kubernetes-native: Designed for cloud-native deployments</li> <li>Region-aware: Built-in support for data sovereignty</li> </ul>"},{"location":"reference/faq/#how-is-felix-different-from-kafka","title":"How is Felix different from Kafka?","text":"<p>Felix is not a Kafka replacement but serves different use cases:</p> Feature Felix Kafka Transport QUIC (UDP) TCP Encryption Built-in (TLS 1.3) Optional (TLS/SASL) Latency focus p99/p999 optimization Throughput optimization Primitives Pub/sub + cache unified Log-based streaming Persistence Optional per stream Always durable Fanout Native high fanout Consumer groups Use case Low-latency streaming, real-time cache High-throughput log processing <p>Use Felix when: - You need ultra-low latency (sub-millisecond to low-millisecond p99) - High fanout with many concurrent subscribers - Combined pub/sub and caching requirements - QUIC transport benefits (multiplexing, better loss recovery)</p> <p>Use Kafka when: - You need guaranteed durability and replay - Processing historical data with consumer groups - Existing Kafka ecosystem integrations - Traditional log-based semantics</p>"},{"location":"reference/faq/#how-is-felix-different-from-redis","title":"How is Felix different from Redis?","text":"<p>Felix complements Redis rather than replacing it:</p> Feature Felix Redis Primary use Pub/sub + cache Cache + data structures Transport QUIC TCP (RESP protocol) Streaming First-class pub/sub Basic pub/sub Batching Native batch delivery Individual messages Persistence Optional, log-based RDB/AOF snapshots Fanout Optimized for high fanout Basic pub/sub fanout <p>Use Felix for: - High-fanout real-time event distribution - Streaming with batching and flow control - Combined streaming and caching workloads</p> <p>Use Redis for: - Rich data structures (sets, sorted sets, etc.) - Lua scripting and transactions - Existing Redis ecosystem tools</p>"},{"location":"reference/faq/#is-felix-production-ready","title":"Is Felix production-ready?","text":"<p>No, Felix is in early active development. Current status:</p> <ul> <li>\u2705 Core protocol stabilizing</li> <li>\u2705 Single-node broker working</li> <li>\u2705 Rust client SDK functional</li> <li>\u23f3 Multi-node clustering in progress</li> <li>\u23f3 Control plane under development</li> <li>\u274c Production hardening incomplete</li> <li>\u274c No official releases yet</li> </ul> <p>Use Felix for: - Research and prototyping - Performance benchmarking - Contributing to development</p> <p>Do not use Felix for: - Production workloads requiring high availability - Scenarios requiring data durability guarantees - Mission-critical applications</p>"},{"location":"reference/faq/#architecture-questions","title":"Architecture Questions","text":""},{"location":"reference/faq/#why-quic-instead-of-tcp","title":"Why QUIC instead of TCP?","text":"<p>QUIC provides several advantages for Felix's use case:</p> <p>Benefits:</p> <ol> <li>Multiplexing without head-of-line blocking: Multiple streams share one connection without one slow stream blocking others</li> <li>Built-in encryption: TLS 1.3 integrated, no separate TLS handshake</li> <li>Connection migration: Survive IP changes (mobile, load balancer updates)</li> <li>Fast connection establishment: 0-RTT for resumed connections</li> <li>Better loss recovery: Stream-level retransmits instead of connection-level</li> <li>Modern congestion control: BBR and other advanced algorithms</li> </ol> <p>Trade-offs:</p> <ul> <li>UDP may be blocked by some networks (though increasingly rare)</li> <li>Requires newer network infrastructure for optimal performance</li> <li>Limited debugging tools compared to TCP</li> </ul>"},{"location":"reference/faq/#what-is-the-wire-protocol","title":"What is the wire protocol?","text":"<p>Felix uses <code>felix-wire</code>, a framed protocol with:</p> <ul> <li>JSON control frames: Human-readable for debugging, compatibility</li> <li>Binary fast paths: Zero-copy binary frames for high-throughput data</li> <li>Versioned envelope: Forward/backward compatibility</li> <li>Type-specific framing: Different frame types for pub/sub, cache, control</li> </ul> <p>This hybrid approach balances observability with performance.</p>"},{"location":"reference/faq/#how-does-felix-handle-backpressure","title":"How does Felix handle backpressure?","text":"<p>Felix implements backpressure at multiple levels:</p> <ol> <li>QUIC flow control: Built-in connection and stream-level credit</li> <li>Publish queues: Bounded queues with timeout-based blocking</li> <li>Event queues: Per-subscription buffering with depth limits</li> <li>Batching delays: Implicit batching creates natural flow smoothing</li> <li>Subscriber isolation: Slow subscribers don't block fast ones</li> </ol> <p>When backpressure triggers: - Publishers receive timeout errors if queues full - Subscribers drop behind but don't impact others (future: disconnect slow subscribers) - Flow control credit exhaustion blocks at QUIC layer</p>"},{"location":"reference/faq/#what-is-ephemeral-vs-durable-storage","title":"What is ephemeral vs durable storage?","text":"<p>Ephemeral streams: - In-memory only - Ultra-low latency (no disk I/O) - Data lost on broker restart - Suitable for real-time data, metrics, logs</p> <p>Durable streams (planned): - WAL + segmented log on persistent storage - Survive restarts - Replay capability - Higher latency (disk writes) - Suitable for business events, audit logs</p> <p>Currently, Felix MVP supports ephemeral only. Durability is planned.</p>"},{"location":"reference/faq/#how-does-clustering-work","title":"How does clustering work?","text":"<p>Current: Single-node broker only.</p> <p>Planned: - Sharding: Streams divided into shards, distributed across brokers - Replication: Raft-based consensus for shard replicas - Leader election: One leader per shard accepts writes - Follower reads: Optional read-from-follower for scalability - Metadata service: Control plane tracks topology and routing</p> <p>See Control Plane documentation for details.</p>"},{"location":"reference/faq/#configuration-questions","title":"Configuration Questions","text":""},{"location":"reference/faq/#whats-the-most-important-configuration-parameter","title":"What's the most important configuration parameter?","text":"<p>For latency: <code>FELIX_EVENT_BATCH_MAX_DELAY_US</code></p> <p>This controls the maximum time events wait in a batch before being sent. Lower values reduce latency but may decrease throughput.</p> <pre><code># Ultra-low latency\nexport FELIX_EVENT_BATCH_MAX_DELAY_US=\"50\"\n\n# Balanced\nexport FELIX_EVENT_BATCH_MAX_DELAY_US=\"250\"\n\n# High throughput\nexport FELIX_EVENT_BATCH_MAX_DELAY_US=\"1000\"\n</code></pre> <p>For throughput: <code>FELIX_EVENT_BATCH_MAX_EVENTS</code></p> <pre><code># Small batches\nexport FELIX_EVENT_BATCH_MAX_EVENTS=\"16\"\n\n# Large batches\nexport FELIX_EVENT_BATCH_MAX_EVENTS=\"256\"\n</code></pre>"},{"location":"reference/faq/#should-i-enable-binary-encoding","title":"Should I enable binary encoding?","text":"<p>It depends on payload size:</p> <p>Binary encoding benefits: - Lower serialization overhead - Higher throughput - Reduced CPU usage</p> <p>Trade-offs: - Less human-readable - Requires client support</p> <p>Recommendation: <pre><code># Enable for payloads &gt; 512 bytes\nexport FELIX_BINARY_SINGLE_EVENT=\"TRUE\"\nexport FELIX_BINARY_SINGLE_EVENT_MIN_BYTES=\"512\"\n</code></pre></p> <p>For debugging, disable binary encoding: <pre><code>export FELIX_BINARY_SINGLE_EVENT=\"false\"\n</code></pre></p>"},{"location":"reference/faq/#how-do-i-tune-for-high-fanout","title":"How do I tune for high fanout?","text":"<p>High fanout (100+ subscribers):</p> <pre><code># Increase fanout batch size\nexport FELIX_FANOUT_BATCH=\"128\"\n\n# Increase event queue depth\nexport FELIX_EVENT_QUEUE_DEPTH=\"2048\"\n\n# Enable batching\nexport FELIX_EVENT_BATCH_MAX_EVENTS=\"128\"\nexport FELIX_EVENT_BATCH_MAX_DELAY_US=\"500\"\n\n# Consider disabling timings\nexport FELIX_DISABLE_TIMINGS=\"1\"\n</code></pre> <p>Monitor for: - CPU saturation (scale horizontally) - Memory pressure (adjust windows) - Slow subscribers (may need to disconnect)</p>"},{"location":"reference/faq/#how-much-memory-does-felix-need","title":"How much memory does Felix need?","text":"<p>Memory usage depends on configuration:</p> <p>Minimal setup: ~100-200 MB base</p> <p>Per connection memory (approximate): <pre><code>conn_memory = cache_conn_recv_window + (cache_stream_recv_window \u00d7 streams_per_conn)\n</code></pre></p> <p>Example (default config): <pre><code>256 MiB + (64 MiB \u00d7 4) = 512 MiB per connection\n\nWith FELIX_CACHE_CONN_POOL=8:\n8 \u00d7 512 MiB = 4 GiB potential max\n</code></pre></p> <p>Recommendations: - Development: 2-4 GB - Production: 4-8 GB base, adjust based on workload - High throughput: 8-16 GB</p> <p>Monitor actual RSS usage and adjust windows accordingly.</p>"},{"location":"reference/faq/#performance-questions","title":"Performance Questions","text":""},{"location":"reference/faq/#what-latency-can-i-expect","title":"What latency can I expect?","text":"<p>Localhost benchmarks (release build, timings disabled):</p> <p>Pub/sub (fanout=1, batch=1): - p50: 0.5-2 ms - p99: 2-10 ms - p999: 10-50 ms</p> <p>Pub/sub (fanout=10, batch=64): - p50: 30-50 ms - p99: 60-100 ms - Throughput: 100-200k msgs/s</p> <p>Cache operations (concurrency=32): - <code>get_hit</code> p50: 160-240 \u00b5s - <code>get_miss</code> p50: 160-180 \u00b5s - <code>put</code> p50: 160-260 \u00b5s</p> <p>Network latency adds: - Same datacenter: +0.5-2 ms - Cross-region: +20-200 ms</p> <p>These are reference points. Actual performance depends on hardware, network, configuration, and workload.</p>"},{"location":"reference/faq/#why-is-debug-build-so-slow","title":"Why is debug build so slow?","text":"<p>Debug builds include: - No optimizations - Debug assertions - Symbol information - Bounds checking</p> <p>Performance impact: 10-100x slower than release builds.</p> <p>Always use release builds for benchmarking: <pre><code>cargo build --release\ncargo run --release -p broker\n</code></pre></p>"},{"location":"reference/faq/#how-do-i-reduce-memory-usage","title":"How do I reduce memory usage?","text":"<ol> <li> <p>Reduce flow-control windows: <pre><code>export FELIX_CACHE_CONN_RECV_WINDOW=\"134217728\"    # 128 MiB\nexport FELIX_CACHE_STREAM_RECV_WINDOW=\"33554432\"   # 32 MiB\nexport FELIX_EVENT_CONN_RECV_WINDOW=\"134217728\"\n</code></pre></p> </li> <li> <p>Reduce connection pools (client-side): <pre><code>export FELIX_CACHE_CONN_POOL=\"4\"\nexport FELIX_EVENT_CONN_POOL=\"4\"\n</code></pre></p> </li> <li> <p>Reduce queue depths: <pre><code>export FELIX_BROKER_PUB_QUEUE_DEPTH=\"512\"\nexport FELIX_EVENT_QUEUE_DEPTH=\"512\"\n</code></pre></p> </li> <li> <p>Limit concurrent connections: Configure client connection limits.</p> </li> </ol>"},{"location":"reference/faq/#how-do-i-maximize-throughput","title":"How do I maximize throughput?","text":"<ol> <li> <p>Increase batch sizes: <pre><code>export FELIX_EVENT_BATCH_MAX_EVENTS=\"256\"\nexport FELIX_EVENT_BATCH_MAX_BYTES=\"1048576\"\nexport FELIX_EVENT_BATCH_MAX_DELAY_US=\"1000\"\n</code></pre></p> </li> <li> <p>Enable binary encoding: <pre><code>export FELIX_BINARY_SINGLE_EVENT=\"TRUE\"\n</code></pre></p> </li> <li> <p>Disable timings: <pre><code>export FELIX_DISABLE_TIMINGS=\"1\"\n</code></pre></p> </li> <li> <p>Increase parallelism: <pre><code>export FELIX_EVENT_CONN_POOL=\"16\"\nexport FELIX_FANOUT_BATCH=\"128\"\n</code></pre></p> </li> <li> <p>Scale horizontally: Run multiple broker instances.</p> </li> </ol>"},{"location":"reference/faq/#deployment-questions","title":"Deployment Questions","text":""},{"location":"reference/faq/#can-i-run-felix-in-docker","title":"Can I run Felix in Docker?","text":"<p>Yes! See Docker Compose guide.</p> <pre><code>docker compose up -d felix-broker\n</code></pre> <p>Pre-built images are not yet available; build from source using the provided <code>docker/broker.Dockerfile</code>.</p>"},{"location":"reference/faq/#can-i-run-felix-on-kubernetes","title":"Can I run Felix on Kubernetes?","text":"<p>Yes! Felix is designed for Kubernetes. See Kubernetes guide.</p> <p>Use StatefulSets for stable identity and persistent storage:</p> <pre><code>kubectl apply -f deploy/kubernetes/statefulset.yaml\n</code></pre>"},{"location":"reference/faq/#how-do-i-monitor-felix","title":"How do I monitor Felix?","text":"<p>Metrics endpoint: <pre><code>curl http://broker:8080/healthz\ncurl http://broker:8080/metrics  # If telemetry enabled\n</code></pre></p> <p>Structured logs: <pre><code>export RUST_LOG=\"info\"\n# Or debug for verbose logging\nexport RUST_LOG=\"felix_broker=debug\"\n</code></pre></p> <p>Prometheus (when telemetry enabled): - Scrape <code>/metrics</code> endpoint - Use provided Grafana dashboards (future)</p> <p>Observability guide: Observability</p>"},{"location":"reference/faq/#how-do-i-secure-felix","title":"How do I secure Felix?","text":"<p>Current state: Transport security only (QUIC/TLS 1.3).</p> <p>Planned: - mTLS authentication - Token-based authorization - Tenant isolation - Encryption at rest - Audit logging</p> <p>Best practices (now): - Run in private networks - Use network policies (Kubernetes) - Limit exposed ports - Monitor access logs</p> <p>See Security guide for details.</p>"},{"location":"reference/faq/#development-questions","title":"Development Questions","text":""},{"location":"reference/faq/#how-do-i-contribute","title":"How do I contribute?","text":"<p>See Contributing guide.</p> <p>Quick start: 1. Fork repository 2. Create feature branch 3. Make changes with tests 4. Run <code>task lint</code> and <code>task test</code> 5. Submit pull request</p> <p>Felix welcomes contributions!</p>"},{"location":"reference/faq/#how-do-i-run-tests","title":"How do I run tests?","text":"<pre><code># All tests\ncargo test --workspace\n\n# Specific crate\ncargo test -p felix-broker\n\n# With output\ncargo test -- --nocapture\n\n# Using Task\ntask test\n</code></pre>"},{"location":"reference/faq/#how-do-i-build-the-documentation","title":"How do I build the documentation?","text":"<pre><code># Install mkdocs\npip install mkdocs mkdocs-material\n\n# Serve locally\ncd docs-site\nmkdocs serve\n\n# Build static site\nmkdocs build\n</code></pre>"},{"location":"reference/faq/#whats-the-project-structure","title":"What's the project structure?","text":"<pre><code>crates/           # Rust crates\n  felix-broker/   # Broker core logic\n  felix-wire/     # Protocol framing\n  felix-client/   # Client SDK\n  ...\nservices/         # Runnable binaries\n  broker/         # Broker service\ndocs/             # Design docs\ndocs-site/        # User documentation (mkdocs)\n</code></pre> <p>See Project Structure for details.</p>"},{"location":"reference/faq/#roadmap-questions","title":"Roadmap Questions","text":""},{"location":"reference/faq/#when-will-felix-have-durability","title":"When will Felix have durability?","text":"<p>Durable storage is planned for Q2 2026 (tentative):</p> <ul> <li>WAL-based append log</li> <li>Segmented storage</li> <li>Retention policies</li> <li>Replay from offset</li> </ul> <p>Track progress in GitHub issues.</p>"},{"location":"reference/faq/#when-will-clustering-be-available","title":"When will clustering be available?","text":"<p>Multi-node clustering is in active development:</p> <ul> <li>Sharding: Q1 2026 (tentative)</li> <li>Replication: Q2 2026 (tentative)</li> <li>Control plane: In progress</li> </ul> <p>See Control Plane docs for design.</p>"},{"location":"reference/faq/#will-there-be-clients-for-other-languages","title":"Will there be clients for other languages?","text":"<p>Planned client SDKs:</p> <ul> <li>\u2705 Rust: Available (in progress)</li> <li>\u23f3 Go: Planned</li> <li>\u23f3 Python: Planned</li> <li>\u23f3 Java: Planned</li> <li>\u23f3 JavaScript/TypeScript: Planned</li> </ul> <p>Community contributions welcome! The wire protocol is language-agnostic.</p>"},{"location":"reference/faq/#what-about-exactly-once-semantics","title":"What about exactly-once semantics?","text":"<p>Exactly-once delivery is extremely difficult in distributed systems and often misleading. Felix focuses on at-least-once with idempotency support:</p> <p>Current: At-least-once delivery with acks (when <code>ack_on_commit=true</code>)</p> <p>Future: - Deduplication based on message IDs - Idempotent producer semantics - Transaction support (under research)</p> <p>For exactly-once processing, implement idempotent consumers.</p>"},{"location":"reference/faq/#troubleshooting-questions","title":"Troubleshooting Questions","text":""},{"location":"reference/faq/#why-wont-the-broker-start","title":"Why won't the broker start?","text":"<p>Common causes:</p> <ol> <li>Port in use: Change <code>FELIX_QUIC_BIND</code></li> <li>Invalid config: Check YAML syntax</li> <li>Missing dependencies: Run <code>cargo build</code></li> <li>Wrong Rust version: Update to 1.92.0+</li> </ol> <p>See Troubleshooting guide.</p>"},{"location":"reference/faq/#why-is-latency-so-high","title":"Why is latency so high?","text":"<p>Check:</p> <ol> <li>Debug vs release build: Use <code>--release</code></li> <li>Timings enabled: Disable with <code>FELIX_DISABLE_TIMINGS=1</code></li> <li>Batch delay: Reduce <code>FELIX_EVENT_BATCH_MAX_DELAY_US</code></li> <li>Network latency: Test localhost first</li> <li>System load: Check CPU/memory usage</li> </ol>"},{"location":"reference/faq/#how-do-i-debug-connection-issues","title":"How do I debug connection issues?","text":"<pre><code># Enable debug logging\nexport RUST_LOG=\"felix_transport=debug,felix_broker=debug\"\n\n# Check broker is listening\nlsof -i UDP:5000\n\n# Test connectivity\nnc -zvu &lt;broker-ip&gt; 5000\n\n# Capture traffic\nsudo tcpdump -i any -w felix.pcap udp port 5000\n</code></pre>"},{"location":"reference/faq/#comparison-questions","title":"Comparison Questions","text":""},{"location":"reference/faq/#felix-vs-nats","title":"Felix vs NATS?","text":"Feature Felix NATS Transport QUIC TCP Persistence Planned JetStream Maturity Early development Production-ready Language Rust Go Focus Low-latency, high fanout Lightweight messaging <p>Use NATS for production workloads today. Felix is experimental.</p>"},{"location":"reference/faq/#felix-vs-pulsar","title":"Felix vs Pulsar?","text":"Feature Felix Pulsar Transport QUIC TCP Storage Planned BookKeeper Maturity Early development Production-ready Complexity Simple Complex (multiple components) <p>Pulsar is production-ready with many features. Felix is simpler and focused on latency.</p>"},{"location":"reference/faq/#felix-vs-rabbitmq","title":"Felix vs RabbitMQ?","text":"Feature Felix RabbitMQ Protocol QUIC/felix-wire AMQP Routing Topic-based Exchange/queue patterns Persistence Planned Built-in Maturity Early development Production-ready <p>RabbitMQ is mature with rich routing. Felix focuses on simple, fast pub/sub.</p>"},{"location":"reference/faq/#next-steps","title":"Next Steps","text":"<ul> <li>Quick start: Quickstart Guide</li> <li>Detailed configuration: Configuration Reference</li> <li>Troubleshooting: Troubleshooting Guide</li> <li>Contributing: Contributing Guide</li> </ul>"},{"location":"reference/troubleshooting/","title":"Troubleshooting Guide","text":"<p>Common issues and solutions when running Felix.</p>"},{"location":"reference/troubleshooting/#build-and-compilation-issues","title":"Build and Compilation Issues","text":""},{"location":"reference/troubleshooting/#rust-version-too-old","title":"Rust Version Too Old","text":"<p>Symptom: Compilation errors mentioning unstable features or syntax errors.</p> <pre><code>error[E0658]: use of unstable library feature 'try_blocks'\n</code></pre> <p>Solution: Update Rust to 1.92.0 or later.</p> <pre><code># Check current version\nrustc --version\n\n# Update Rust\nrustup update\n\n# Set specific toolchain (if needed)\nrustup override set 1.92.0\n</code></pre>"},{"location":"reference/troubleshooting/#missing-dependencies","title":"Missing Dependencies","text":"<p>Symptom: Linker errors or missing system libraries.</p> <pre><code>error: linking with `cc` failed\n</code></pre> <p>Solution: Install required system dependencies.</p> <p>Linux (Debian/Ubuntu): <pre><code>sudo apt-get update\nsudo apt-get install build-essential pkg-config libssl-dev\n</code></pre></p> <p>Linux (Fedora/RHEL): <pre><code>sudo dnf install gcc pkg-config openssl-devel\n</code></pre></p> <p>macOS: <pre><code>xcode-select --install\nbrew install openssl pkg-config\n</code></pre></p>"},{"location":"reference/troubleshooting/#build-hangs-or-takes-forever","title":"Build Hangs or Takes Forever","text":"<p>Symptom: <code>cargo build</code> appears stuck or takes excessive time.</p> <p>Solution:</p> <ol> <li> <p>Check cargo build jobs: <pre><code># Limit parallel jobs\ncargo build --jobs 2\n</code></pre></p> </li> <li> <p>Clean build cache: <pre><code>cargo clean\ncargo build --release\n</code></pre></p> </li> <li> <p>Check disk space: <pre><code>df -h\n# Clean target directory if low\nrm -rf target\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting/#compilation-errors-after-git-pull","title":"Compilation Errors After Git Pull","text":"<p>Symptom: Build fails after pulling latest changes.</p> <p>Solution: Clean and rebuild.</p> <pre><code>cargo clean\ncargo update\ncargo build --workspace --release\n</code></pre>"},{"location":"reference/troubleshooting/#network-and-connection-issues","title":"Network and Connection Issues","text":""},{"location":"reference/troubleshooting/#port-already-in-use","title":"Port Already in Use","text":"<p>Symptom: Broker fails to start with error.</p> <pre><code>Error: Address already in use (os error 48)\n</code></pre> <p>Solution: Change ports or kill conflicting process.</p> <p>Option 1 - Change ports: <pre><code>export FELIX_QUIC_BIND=\"0.0.0.0:5001\"\nexport FELIX_BROKER_METRICS_BIND=\"0.0.0.0:8081\"\ncargo run --release -p broker\n</code></pre></p> <p>Option 2 - Find and kill process: <pre><code># Linux/Mac - find process on port 5000\nlsof -i :5000\nsudo kill -9 &lt;PID&gt;\n\n# Or use ss\nss -tulpn | grep 5000\n</code></pre></p>"},{"location":"reference/troubleshooting/#connection-refused","title":"Connection Refused","text":"<p>Symptom: Client cannot connect to broker.</p> <pre><code>Error: Connection refused (os error 111)\n</code></pre> <p>Solutions:</p> <ol> <li> <p>Verify broker is running: <pre><code>ps aux | grep broker\nlsof -i UDP:5000\n</code></pre></p> </li> <li> <p>Check bind address: <pre><code># Broker logs should show:\n# \"QUIC listening on 0.0.0.0:5000\"\n\n# If binding to 127.0.0.1, external connections won't work\nexport FELIX_QUIC_BIND=\"0.0.0.0:5000\"\n</code></pre></p> </li> <li> <p>Check firewall (Linux): <pre><code># Allow UDP 5000\nsudo ufw allow 5000/udp\n\n# Or iptables\nsudo iptables -A INPUT -p udp --dport 5000 -j ACCEPT\n</code></pre></p> </li> <li> <p>Test connectivity: <pre><code># From client machine\nnc -zvu &lt;broker-ip&gt; 5000\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting/#quic-handshake-timeout","title":"QUIC Handshake Timeout","text":"<p>Symptom: Connection hangs during QUIC handshake.</p> <pre><code>Error: HandshakeTimeout\n</code></pre> <p>Solutions:</p> <ol> <li> <p>Check network path: Ensure UDP traffic is not blocked.</p> </li> <li> <p>Verify MTU: QUIC sensitive to MTU issues. <pre><code># Test with ping\nping -M do -s 1472 &lt;broker-ip&gt;\n\n# Reduce MTU if needed (client-side)\nip link set dev eth0 mtu 1400\n</code></pre></p> </li> <li> <p>Check NAT/Load Balancer: Ensure UDP pass-through.</p> </li> </ol>"},{"location":"reference/troubleshooting/#connection-reset-by-peer","title":"Connection Reset by Peer","text":"<p>Symptom: Established connections drop unexpectedly.</p> <pre><code>Error: Connection reset by peer (os error 104)\n</code></pre> <p>Solutions:</p> <ol> <li> <p>Check broker logs for crashes or panics.</p> </li> <li> <p>Increase flow-control windows: <pre><code>export FELIX_CACHE_CONN_RECV_WINDOW=\"536870912\"\nexport FELIX_EVENT_CONN_RECV_WINDOW=\"536870912\"\n</code></pre></p> </li> <li> <p>Check resource limits: <pre><code># Increase open file limit\nulimit -n 65536\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"reference/troubleshooting/#high-latency","title":"High Latency","text":"<p>Symptom: p99/p999 latency much higher than expected.</p> <p>Solutions:</p> <ol> <li> <p>Use release builds: <pre><code># Debug builds are 10-100x slower\ncargo build --release\ncargo run --release -p broker\n</code></pre></p> </li> <li> <p>Disable timing collection: <pre><code>export FELIX_DISABLE_TIMINGS=\"1\"\n</code></pre></p> </li> <li> <p>Reduce batch delay: <pre><code>export FELIX_EVENT_BATCH_MAX_DELAY_US=\"50\"\n</code></pre></p> </li> <li> <p>Check system load: <pre><code>top\nhtop\n# Look for CPU saturation, memory pressure\n</code></pre></p> </li> <li> <p>Profile with perf (Linux): <pre><code>sudo perf record -g cargo run --release -p broker\nsudo perf report\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting/#low-throughput","title":"Low Throughput","text":"<p>Symptom: Messages/second much lower than expected.</p> <p>Solutions:</p> <ol> <li> <p>Increase batch sizes: <pre><code>export FELIX_EVENT_BATCH_MAX_EVENTS=\"256\"\nexport FELIX_EVENT_BATCH_MAX_BYTES=\"1048576\"\nexport FELIX_EVENT_BATCH_MAX_DELAY_US=\"1000\"\n</code></pre></p> </li> <li> <p>Enable binary encoding: <pre><code>export FELIX_BINARY_SINGLE_EVENT=\"TRUE\"\n</code></pre></p> </li> <li> <p>Increase connection pools: <pre><code>export FELIX_EVENT_CONN_POOL=\"16\"\nexport FELIX_CACHE_CONN_POOL=\"16\"\n</code></pre></p> </li> <li> <p>Check network bandwidth: <pre><code>iperf3 -c &lt;broker-ip&gt; -u -b 1G\n</code></pre></p> </li> <li> <p>Verify CPU affinity: <pre><code># Pin broker to specific cores\ntaskset -c 0-7 cargo run --release -p broker\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting/#high-memory-usage","title":"High Memory Usage","text":"<p>Symptom: Broker consuming excessive memory.</p> <pre><code>OOM Killed\n</code></pre> <p>Solutions:</p> <ol> <li> <p>Check actual memory usage: <pre><code>ps aux | grep broker\npmap &lt;pid&gt;\n</code></pre></p> </li> <li> <p>Reduce flow-control windows: <pre><code>export FELIX_CACHE_CONN_RECV_WINDOW=\"134217728\"   # 128 MiB\nexport FELIX_CACHE_STREAM_RECV_WINDOW=\"33554432\"  # 32 MiB\nexport FELIX_EVENT_CONN_RECV_WINDOW=\"134217728\"\n</code></pre></p> </li> <li> <p>Reduce queue depths: <pre><code>export FELIX_BROKER_PUB_QUEUE_DEPTH=\"512\"\nexport FELIX_EVENT_QUEUE_DEPTH=\"512\"\n</code></pre></p> </li> <li> <p>Limit connection pools (client-side): <pre><code>export FELIX_EVENT_CONN_POOL=\"4\"\nexport FELIX_CACHE_CONN_POOL=\"4\"\n</code></pre></p> </li> <li> <p>Check for memory leaks: <pre><code># Use valgrind (debug build)\nvalgrind --leak-check=full ./target/debug/broker\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting/#cpu-saturation","title":"CPU Saturation","text":"<p>Symptom: Broker at 100% CPU, high latency.</p> <p>Solutions:</p> <ol> <li> <p>Scale horizontally: Deploy multiple broker instances.</p> </li> <li> <p>Reduce fanout batch size: <pre><code>export FELIX_FANOUT_BATCH=\"32\"\n</code></pre></p> </li> <li> <p>Disable telemetry: <pre><code>export FELIX_DISABLE_TIMINGS=\"1\"\n# Or rebuild without telemetry feature\ncargo build --release --no-default-features\n</code></pre></p> </li> <li> <p>Profile hot paths: <pre><code>cargo flamegraph -p broker\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting/#runtime-errors","title":"Runtime Errors","text":""},{"location":"reference/troubleshooting/#panic-or-crash","title":"Panic or Crash","text":"<p>Symptom: Broker exits with panic message.</p> <pre><code>thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value'\n</code></pre> <p>Solutions:</p> <ol> <li> <p>Enable backtraces: <pre><code>export RUST_BACKTRACE=1\ncargo run --release -p broker\n</code></pre></p> </li> <li> <p>Check logs for context before panic.</p> </li> <li> <p>Run with debug symbols: <pre><code>cargo build --profile release-with-debug\n./target/release-with-debug/broker\n</code></pre></p> </li> <li> <p>Report issue with full backtrace and reproduction steps.</p> </li> </ol>"},{"location":"reference/troubleshooting/#out-of-file-descriptors","title":"Out of File Descriptors","text":"<p>Symptom: Error opening connections or files.</p> <pre><code>Error: Too many open files (os error 24)\n</code></pre> <p>Solution: Increase file descriptor limit.</p> <pre><code># Check current limit\nulimit -n\n\n# Increase temporarily\nulimit -n 65536\n\n# Increase permanently (Linux)\necho \"* soft nofile 65536\" | sudo tee -a /etc/security/limits.conf\necho \"* hard nofile 65536\" | sudo tee -a /etc/security/limits.conf\n\n# Verify\nulimit -n\n</code></pre>"},{"location":"reference/troubleshooting/#queue-full-backpressure","title":"Queue Full / Backpressure","text":"<p>Symptom: Publish operations timing out.</p> <pre><code>Error: Publish queue full, timeout after 2000ms\n</code></pre> <p>Solutions:</p> <ol> <li> <p>Increase queue depth: <pre><code>export FELIX_BROKER_PUB_QUEUE_DEPTH=\"2048\"\n</code></pre></p> </li> <li> <p>Increase timeout: <pre><code>export FELIX_PUBLISH_QUEUE_WAIT_MS=\"5000\"\n</code></pre></p> </li> <li> <p>Slow down publisher or scale broker capacity.</p> </li> <li> <p>Check subscriber health: Slow subscribers cause backpressure.</p> </li> </ol>"},{"location":"reference/troubleshooting/#docker-and-container-issues","title":"Docker and Container Issues","text":""},{"location":"reference/troubleshooting/#container-wont-start","title":"Container Won't Start","text":"<p>Symptom: Docker container exits immediately.</p> <pre><code>docker logs felix-broker\n# Check for errors\n</code></pre> <p>Solutions:</p> <ol> <li> <p>Check image build: <pre><code>docker compose build --no-cache\n</code></pre></p> </li> <li> <p>Run interactively: <pre><code>docker run -it --rm felix/broker:latest /bin/sh\n</code></pre></p> </li> <li> <p>Verify entrypoint: <pre><code>docker inspect felix/broker:latest | grep -A 5 Entrypoint\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting/#container-health-check-failing","title":"Container Health Check Failing","text":"<p>Symptom: Container marked unhealthy.</p> <pre><code>docker compose ps\n# STATUS: unhealthy\n</code></pre> <p>Solutions:</p> <ol> <li> <p>Test health endpoint: <pre><code>docker exec felix-broker wget -qO- http://localhost:8080/healthz\n</code></pre></p> </li> <li> <p>Check metrics bind: <pre><code>environment:\n  - FELIX_BROKER_METRICS_BIND=0.0.0.0:8080\n</code></pre></p> </li> <li> <p>Increase start period: <pre><code>healthcheck:\n  start_period: 30s\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting/#volume-permission-issues","title":"Volume Permission Issues","text":"<p>Symptom: Cannot write to mounted volume.</p> <pre><code>Permission denied\n</code></pre> <p>Solution: Fix volume permissions.</p> <pre><code># Check user in container\ndocker exec felix-broker id\n\n# Fix ownership\ndocker exec -u root felix-broker chown -R 10001:nogroup /data\n\n# Or in Dockerfile\nRUN chown -R 10001:nogroup /data\n</code></pre>"},{"location":"reference/troubleshooting/#kubernetes-issues","title":"Kubernetes Issues","text":""},{"location":"reference/troubleshooting/#pod-stuck-in-pending","title":"Pod Stuck in Pending","text":"<p>Symptom: Pod never schedules.</p> <pre><code>kubectl describe pod felix-broker-0 -n felix\n# Events: FailedScheduling\n</code></pre> <p>Solutions:</p> <ol> <li> <p>Check node resources: <pre><code>kubectl describe nodes\nkubectl top nodes\n</code></pre></p> </li> <li> <p>Check PVC binding: <pre><code>kubectl get pvc -n felix\n# Look for Pending PVCs\n</code></pre></p> </li> <li> <p>Check pod affinity: <pre><code>kubectl get pods -n felix -o wide\n# Verify anti-affinity not blocking\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting/#crashloopbackoff","title":"CrashLoopBackOff","text":"<p>Symptom: Pod repeatedly crashes.</p> <pre><code>kubectl get pods -n felix\n# STATUS: CrashLoopBackOff\n</code></pre> <p>Solutions:</p> <ol> <li> <p>Check logs: <pre><code>kubectl logs felix-broker-0 -n felix\nkubectl logs felix-broker-0 -n felix --previous\n</code></pre></p> </li> <li> <p>Check events: <pre><code>kubectl describe pod felix-broker-0 -n felix\n</code></pre></p> </li> <li> <p>Increase resources: <pre><code>resources:\n  limits:\n    memory: \"8Gi\"\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting/#service-not-reachable","title":"Service Not Reachable","text":"<p>Symptom: Cannot connect to service.</p> <p>Solutions:</p> <ol> <li> <p>Test from within cluster: <pre><code>kubectl run -it --rm debug --image=busybox -n felix -- sh\nnc -zvu felix-broker-headless 5000\n</code></pre></p> </li> <li> <p>Check service endpoints: <pre><code>kubectl get endpoints -n felix\n</code></pre></p> </li> <li> <p>Verify service selector: <pre><code>kubectl get svc felix-broker -n felix -o yaml\nkubectl get pods -n felix --show-labels\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting/#statefulset-not-scaling","title":"StatefulSet Not Scaling","text":"<p>Symptom: Replicas not increasing.</p> <p>Solutions:</p> <ol> <li> <p>Check PVC provisioning: <pre><code>kubectl get pvc -n felix\n</code></pre></p> </li> <li> <p>Check storage class: <pre><code>kubectl get storageclass\nkubectl describe storageclass fast-ssd\n</code></pre></p> </li> <li> <p>Check events: <pre><code>kubectl get events -n felix --sort-by='.lastTimestamp'\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting/#client-sdk-issues","title":"Client SDK Issues","text":""},{"location":"reference/troubleshooting/#connection-pool-exhaustion","title":"Connection Pool Exhaustion","text":"<p>Symptom: Client operations hang or timeout.</p> <p>Solution: Increase pool sizes.</p> <pre><code>export FELIX_EVENT_CONN_POOL=\"16\"\nexport FELIX_CACHE_CONN_POOL=\"16\"\nexport FELIX_CACHE_STREAMS_PER_CONN=\"8\"\n</code></pre>"},{"location":"reference/troubleshooting/#stream-errors","title":"Stream Errors","text":"<p>Symptom: Stream operations fail unexpectedly.</p> <p>Solutions:</p> <ol> <li> <p>Check broker logs for corresponding errors.</p> </li> <li> <p>Verify stream exists: <pre><code># Use broker API or control plane\ncurl http://broker:8080/streams\n</code></pre></p> </li> <li> <p>Increase timeouts (implementation-dependent).</p> </li> </ol>"},{"location":"reference/troubleshooting/#debugging-tools","title":"Debugging Tools","text":""},{"location":"reference/troubleshooting/#enable-verbose-logging","title":"Enable Verbose Logging","text":"<pre><code># Debug all Felix crates\nexport RUST_LOG=\"felix=debug\"\n\n# Trace specific crate\nexport RUST_LOG=\"felix_broker=trace\"\n\n# Multiple filters\nexport RUST_LOG=\"felix_broker=debug,felix_wire=trace,felix_transport=debug\"\n</code></pre>"},{"location":"reference/troubleshooting/#capture-network-traffic","title":"Capture Network Traffic","text":"<pre><code># Capture QUIC traffic\nsudo tcpdump -i any -w felix.pcap udp port 5000\n\n# Analyze with Wireshark\nwireshark felix.pcap\n</code></pre>"},{"location":"reference/troubleshooting/#profile-performance","title":"Profile Performance","text":"<p>Linux perf: <pre><code>sudo perf record -g --call-graph dwarf cargo run --release -p broker\nsudo perf report\n</code></pre></p> <p>flamegraph: <pre><code>cargo install flamegraph\ncargo flamegraph -p broker -- --custom-args\n</code></pre></p> <p>Memory profiling: <pre><code>cargo install --locked cargo-profdata\ncargo profdata run -p broker\n</code></pre></p>"},{"location":"reference/troubleshooting/#test-latency-locally","title":"Test Latency Locally","text":"<pre><code># Run broker\ncargo run --release -p broker\n\n# In another terminal, run latency demo\ncargo run --release -p broker --bin latencydemo -- \\\n  --binary \\\n  --fanout 1 \\\n  --batch 1 \\\n  --payload 1024 \\\n  --total 5000\n</code></pre>"},{"location":"reference/troubleshooting/#check-system-limits","title":"Check System Limits","text":"<pre><code># File descriptors\nulimit -n\n\n# Max user processes\nulimit -u\n\n# Memory locked\nulimit -l\n\n# See all limits\nulimit -a\n</code></pre>"},{"location":"reference/troubleshooting/#common-configuration-mistakes","title":"Common Configuration Mistakes","text":""},{"location":"reference/troubleshooting/#mismatched-window-sizes","title":"Mismatched Window Sizes","text":"<p>Issue: Client/broker window mismatch causes stalls.</p> <p>Solution: Ensure consistent configuration.</p> <pre><code># Broker\nexport FELIX_CACHE_CONN_RECV_WINDOW=\"268435456\"\n\n# Client (matching)\nexport FELIX_CACHE_SEND_WINDOW=\"268435456\"\n</code></pre>"},{"location":"reference/troubleshooting/#wrong-binary-format-settings","title":"Wrong Binary Format Settings","text":"<p>Issue: Client/broker disagree on binary encoding.</p> <p>Solution: Ensure both enable or disable together.</p> <pre><code># Enable on both client and broker\nexport FELIX_BINARY_SINGLE_EVENT=\"TRUE\"\n</code></pre>"},{"location":"reference/troubleshooting/#insufficient-resources","title":"Insufficient Resources","text":"<p>Issue: Resource limits too low for workload.</p> <p>Solution: Profile and adjust limits.</p> <pre><code># Monitor resources\ndocker stats\nkubectl top pods -n felix\n\n# Adjust based on observations\n</code></pre>"},{"location":"reference/troubleshooting/#getting-help","title":"Getting Help","text":"<p>If you're still stuck:</p> <ol> <li> <p>Check GitHub Issues: https://github.com/gabloe/felix/issues</p> </li> <li> <p>Search documentation: Use site search or <code>grep</code> docs directory</p> </li> <li> <p>Collect diagnostic info: <pre><code># Broker version\ncargo run --release -p broker -- --version\n\n# System info\nuname -a\nrustc --version\ndocker version\nkubectl version\n\n# Configuration\nenv | grep FELIX_\n\n# Logs (last 100 lines)\njournalctl -u felix-broker -n 100\n</code></pre></p> </li> <li> <p>Create minimal reproduction: Simplify to smallest failing case</p> </li> <li> <p>Open an issue with:</p> </li> <li>Felix version</li> <li>Operating system</li> <li>Rust version</li> <li>Configuration</li> <li>Full error message</li> <li>Steps to reproduce</li> </ol>"},{"location":"reference/troubleshooting/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration reference: Configuration Reference</li> <li>Environment variables: Environment Variables</li> <li>FAQ: Frequently Asked Questions</li> </ul>"}]}